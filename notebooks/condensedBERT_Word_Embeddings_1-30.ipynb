{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBw5u4on4tk8"
   },
   "source": [
    "### Load Poetry Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5PQLebu34szB",
    "outputId": "2c3356da-9374-48f7-bc37-97271976a2b9",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Text': 'согревает этот смертный грех\\nзнать о всех молчать о всех стихами\\nтяжело разделывать орех\\nв бычьей буче и ее рогани\\n \\nзатянули люди пояса\\nи пробили дырочку металлом\\nвыходили так на полчаса\\nтолько навсегда уже не стало\\n \\nстало быть у выживших детей\\nкак в матрешке будет по ребенку\\nумирают люди без затей\\nпробивают жизни перепонку\\n \\nулетают чтобы не смотреть\\nна свои расхристанные плоти\\nпусть другие переходят в смерть\\nобрываясь на высокой ноте\\n \\nна высокой\\n \\nнизкие уйдут\\nпропадут истлеют без остатка\\nно оставят по себе редут\\nда рубец\\nнавроде отпечатка',\n",
       " 'Author': 'Алексей Мишуков',\n",
       " 'Before or after': 'After',\n",
       " 'Source': 'No War Poetry',\n",
       " 'Date posted': 'None',\n",
       " 'UniqueIndex': 2013}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load excel data\n",
    "df = pd.read_excel('../Excel_files/Full_Poem_Dataset_12-17.xlsx')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "records = df.to_dict('records')\n",
    "random.choice(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RfUN_KolV-f",
    "outputId": "177ce662-8e78-4ad7-8b70-378071ebc4c7"
   },
   "outputs": [],
   "source": [
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lJEnBJ3gHTsQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pg0P9rFxJwwp",
    "outputId": "7b133608-bb30-4f8a-ce2f-20f18f9c8e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "что могут слова сегодня\n",
      "['[CLS]', 'что', 'могут', 'слова', 'сегодня', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "text = random.choice(random.choice(records)['Text'].split('\\n'))\n",
    "print(text)\n",
    "\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Tokenize our sentence with the BERT tokenizer.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Print out the tokens.\n",
    "print (tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1z1SzuTrqx-7",
    "outputId": "9018432c-fd15-4603-9f65-433af389bbbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Александровская',\n",
       " '섭',\n",
       " 'Уставом',\n",
       " 'Визант',\n",
       " '铁',\n",
       " 'Кэмер',\n",
       " 'резервную',\n",
       " 'Гош',\n",
       " 'жизни',\n",
       " 'заплатив']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(list(tokenizer.vocab.keys()),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XYjcYJuXoAQx",
    "outputId": "9d51a714-95ef-4c45-cd01-b11bce5f9ed9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "воды солёной вслушайся,\n",
      "[CLS]           101\n",
      "воды         12,240\n",
      "солё         46,590\n",
      "##ной         1,700\n",
      "всл          72,498\n",
      "##уша        29,991\n",
      "##й             860\n",
      "##ся          1,523\n",
      ",               128\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
    "text = random.choice(random.choice(records)['Text'].split('\\n'))\n",
    "print(text)\n",
    "\n",
    "# Add the special tokens.\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Display the words with their indeces.\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u_jEkVKxJMc0",
    "outputId": "7013263a-ac3a-4ce4-fa43-24ab26a6a570"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Mark each of the 22 tokens as belonging to sentence \"1\".\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "print (segments_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 29761, 102], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('следовательно')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy \n",
    "# !python -m spacy download ru_core_news_lg\n",
    "nlp = spacy.load(\"ru_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "E_t4cM6KLc98",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 3222/3222 [08:01<00:00,  6.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "lemmaCts = dict()\n",
    "data = []\n",
    "for rec in tqdm(records):\n",
    "    lines = rec['Text'].split('\\n')\n",
    "    for line in lines:\n",
    "        lemmas = [l.lemma_ for l in nlp(line)]\n",
    "        for l in lemmas:\n",
    "            lemmaCts.setdefault(l, 0)\n",
    "            lemmaCts[l] += 1\n",
    "        \n",
    "        if len(line.split(' ')) < 5:\n",
    "            continue\n",
    "            \n",
    "        lemmatized_line = ' '.join(lemmas)\n",
    "        doc = tokenizer.encode_plus(lemmatized_line)\n",
    "\n",
    "        data.append({\n",
    "            'doc' : doc,\n",
    "            'tokens' : tokenizer.convert_ids_to_tokens(doc['input_ids']),\n",
    "            'text' : line,\n",
    "            'lemmatized_text' : lemmatized_line,\n",
    "            'rec' : rec\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc': {'input_ids': [101, 104713, 21547, 1469, 10226, 851, 24034, 1516, 40165, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]},\n",
       " 'tokens': ['[CLS]',\n",
       "  'расколот',\n",
       "  '##ься',\n",
       "  'на',\n",
       "  'свет',\n",
       "  'и',\n",
       "  'шум',\n",
       "  'по',\n",
       "  'рука',\n",
       "  '[SEP]'],\n",
       " 'text': 'раскололись на свет и шумы по рукам',\n",
       " 'lemmatized_text': 'расколоться на свет и шум по рука',\n",
       " 'rec': {'Text': 'вот что\\nбывшие вещи мои закатились пропали по швам\\nраскололись на свет и шумы по рукам\\nразошлись по шкафам истлевают в дали\\nзалегают в песке непорочные платья мои\\nу чужих заседают непрочные книги мои\\nразвеваются в реках\\nподобные травам чулки\\nпереплавлены в рельсы коньки транспортиры вязального детства крючки\\nи какая по счёту петля хоть убей\\nне припомню молекул самих по себе\\nиз себя состоящих поток\\nиз каракуль кометы мелком\\nпо стеклу неподвижного зрения в мире другом',\n",
       "  'Author': 'Хельга Ольшванг',\n",
       "  'Before or after': 'Before',\n",
       "  'Source': 'essentialpoetry',\n",
       "  'Date posted': datetime.datetime(2020, 1, 22, 0, 0),\n",
       "  'UniqueIndex': 2743}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../../records4RuBerta1-30.pickle', 'wb') as handle:\n",
    "    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pickle5 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (0.0.12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'doc': {'input_ids': [101, 13164, 55456, 130, 96377, 93258, 13661, 128, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]},\n",
       " 'tokens': ['[CLS]',\n",
       "  'главный',\n",
       "  'выигрыш',\n",
       "  '-',\n",
       "  'уметь',\n",
       "  'обмануть',\n",
       "  'правило',\n",
       "  ',',\n",
       "  '[SEP]'],\n",
       " 'text': 'Главный выигрыш - уметь обмануть правила,',\n",
       " 'lemmatized_text': 'главный выигрыш - уметь обмануть правило ,',\n",
       " 'rec': {'Text': 'ПАМЯТИ НИКОЛАЯ АБАЕВА**\\n**\\nСиликоновые импланты, яхты миллиардеров,\\nЗагар актеров на фоне прибоя,\\nСтатистика короновируса, статистика футбольных матчей,\\nКокорин, забивающий первый гол за Спартак,\\nИ рядом разлагающийся труп тенгрианца Николая Абаева,\\nАвтора монографии о психологических аспектах дзен буддизма,\\nУдивительной по чистоте мысли и ясности слога.\\nТираж этой книги навсегда остался в рюкзаках 80 х,\\nНа перегонах между Ялтой и Марракешем,\\nМежду Кяхтой и Джорданвиллем.\\nВероятно, Абаев покончил с собой в день своего рождения,\\nКогда ему исполнился 71 год,\\nВ съемной улан-удэнской квартире на Карла Маркса.\\nОн болел, не мог толком ходить, почти не ел, пил одну лишь воду,\\nГоворят, у него не было ни копейки,\\nЧто, по меньшей мере, странно\\nПри профессорской зарплате двух, правда, далеких от Стэнфорда, университетов,\\nТувинского и Бурятского.\\nОднако все деньги снимал банк,\\nТам был просроченный кредит,\\nЧто-то не так с финансовыми решениями.\\nОт трупа шел мерзкий сладковато-гнилостный запах,\\nНашли его почти случайно.\\nТолько не надо в конце этого текста смайлика со слезой,\\nИбо некое пространственно-временное единство,\\nОбозначенное значком Николай Абаев\\nВ лучших местах и в лучшие минуты\\nВ полноте являло пустотность существования,\\nИ это было так заразительно, так ликующе-прекрасно,\\nДавало такую свободу и такую надежду,\\nЧто иное не имеет значения.\\n \\nКогда мир - симуляция,\\nОн - роскошная игра,\\nГлавный выигрыш - уметь обмануть правила,\\nРазорвать сеть.\\nЧистое зеркало повисло в воздухе\\nИ колеблется на ветру.\\nНикакой подставки не предусмотрено.\\n \\n[Источник: Периферия. Симуляция (внутри). Стихи июня-октября 2020 года](http://www.russianpoems.ru/news/a-269.html)\\n \\n#выбор_Павла_Банникова',\n",
       "  'Author': 'Андрей Полонский',\n",
       "  'Before or after': 'Before',\n",
       "  'Source': 'metajournal',\n",
       "  'Date posted': datetime.datetime(2020, 11, 23, 0, 0)}}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip3 install pickle5\n",
    "import pickle5 as pickle\n",
    "\n",
    "with open('../../records4RuBerta1-30.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "    \n",
    "random.choice(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "87f6881696954d68800dbb82c525a601",
      "cbdccc6e24fa4dda8eeeb9da378f36b0",
      "d22add4eef6045cf95e4a72f7428ac9d",
      "4b3be7b64c9e4d79b6b0ce55daade852",
      "4849073628e2430a952fa97d1ec101e6",
      "a5175108f4e24b68a0c37e6e495df625",
      "03a5280fd1824ad4b9ee0ae1ef93e96a",
      "af9fc23c333b45d3ba6e0987ba608814",
      "407824ffad4749758b27200149e731f0",
      "43eda06351504eff8deb8204cece4119",
      "6b29f70530354c8a813b99dcbb0d721d"
     ]
    },
    "collapsed": true,
    "id": "Mq2PKplWfbFv",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "12b77a5b-b75f-461f-cba8-20d341dd64e2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('DeepPavlov/rubert-base-cased',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4Qa5KkkM2Aq"
   },
   "source": [
    "Next, let's evaluate BERT on our example text, and fetch the hidden states of the network!\n",
    "\n",
    "*Side note: `torch.no_grad` tells PyTorch not to construct the compute graph during this forward pass (since we won't be running backprop here)--this just reduces memory consumption and speeds things up a little.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [50,100,200]\n",
    "thresholdedLists = dict()\n",
    "for n in ns:\n",
    "    thresholdedLists[n] = []\n",
    "    \n",
    "for l in lemmaCts:\n",
    "    for n in ns:\n",
    "        if lemmaCts[l] > n:\n",
    "            thresholdedLists[n].append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thresholdedLists[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "мир\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "509"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword = random.choice(thresholdedLists[200])\n",
    "keyword = 'мир'\n",
    "print(keyword)\n",
    "sample = [d for d in data if keyword in d['lemmatized_text'].split(' ')]\n",
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "nN0QTZwiMzeq",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 509/509 [01:52<00:00,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 45s, sys: 2.57 s, total: 1min 48s\n",
      "Wall time: 1min 52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run the text through BERT, and collect all of the hidden states produced from all 12 layers. \n",
    "hidden_state_list = []\n",
    "with torch.no_grad():\n",
    "    for d in tqdm(sample):\n",
    "\n",
    "        tokens_tensor = torch.tensor([d['doc']['input_ids']])\n",
    "        segments_tensor = torch.tensor([d['doc']['attention_mask']])\n",
    "        \n",
    "        outputs = model(tokens_tensor, segments_tensor)\n",
    "\n",
    "        # Evaluating the model will return a different number of objects based on \n",
    "        # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "        # becase we set `output_hidden_states = True`, the third item will be the \n",
    "        # hidden states from all layers. See the documentation for more details:\n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "        hidden_states = outputs[2]\n",
    "        hidden_state_list.append(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 768])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(random.choice(hidden_state_list)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc': {'input_ids': [101, 15726, 58513, 869, 6913, 869, 84309, 64979, 128, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]},\n",
       " 'tokens': ['[CLS]',\n",
       "  'играть',\n",
       "  'мышь',\n",
       "  'с',\n",
       "  'мир',\n",
       "  'с',\n",
       "  'давний',\n",
       "  'пора',\n",
       "  ',',\n",
       "  '[SEP]'],\n",
       " 'text': 'играют мыши с миром с давних пор,',\n",
       " 'lemmatized_text': 'играть мышь с мир с давний пора ,',\n",
       " 'rec': {'Text': 'Смотри, сестра: вот мир на волоске,\\nвот ручка Паркер в пляшущей руке\\n(пусть не десница – но боготворят),\\nвот росчерк, как полёт нетопыря,\\nвот смятый лист под гербовой печатью,\\nвот кабинет, в котором не заплачут\\nнад миром, что повис на волоске.\\n \\nСмотри, сестра, у шахматной доски\\nсвиваются клубками червяки.\\nФигуры вот, что вскорости сожрут.\\nСмерть некрасива даже на миру,\\nно им опять про то сказать забыли,\\nи потому лежат под слоем пыли\\nте пешки, что уже снесли с доски.\\n \\nСмотри, сестра, вот мышь, а вот гора.\\nМышь голодна, её кормить пора,\\nно скоро у горы щедрот не станет\\nкормить всю тьмищу ртов мышиной стаи,\\nи, чтоб отсрочить страшный приговор,\\nиграют мыши с миром с давних пор,\\nи верит до последнего гора.\\n \\nСмотри, сестра, она уже идёт.\\nГорька её усмешка, скошен рот,\\nи лязгают полоски стылой стали –\\nони по тёплой нити заскучали,\\nно кто же точно скажет, по какой?\\nРастут слова под нервною рукой,\\nи нить дрожит, и Атропос и…\\n \\nЩёлк.',\n",
       "  'Author': 'Ирина Валерина',\n",
       "  'Before or after': 'After',\n",
       "  'Source': 'No War Poetry',\n",
       "  'Date posted': 'None',\n",
       "  'UniqueIndex': 1654}}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "мир\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "509it [00:05, 89.37it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# generate hidden states\n",
    "print(keyword)\n",
    "forjson = []\n",
    "verbose = False\n",
    "badsamples = []\n",
    "\n",
    "for d_i, d in tqdm(enumerate(sample)):\n",
    "    hidden_states = hidden_state_list[d_i]\n",
    "    # create a new dimension in the tensor\n",
    "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "    if verbose:\n",
    "        print(token_embeddings.size())\n",
    "    # Remove dimension 1, the \"batches\"\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "    if verbose:\n",
    "        print(token_embeddings.size())\n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "    if verbose:\n",
    "        print(token_embeddings.size())\n",
    "        \n",
    "    keywordFound = False\n",
    "    for t_i, token_str in enumerate(d['tokens']):\n",
    "        if token_str == keyword:\n",
    "            index = t_i\n",
    "            keywordFound = True\n",
    "            \n",
    "    if not keywordFound:\n",
    "        badsamples.append(d)\n",
    "        continue\n",
    "    \n",
    "    # hiddenDict = dict()\n",
    "    eachLayerDict = dict()\n",
    "    for n in range(0,13):\n",
    "        token_vecs_sum = []\n",
    "        one_layer_only = []\n",
    "        for token in token_embeddings:\n",
    "            sum_vec = torch.sum(token[-n:], dim=0)\n",
    "            token_vecs_sum.append(sum_vec)\n",
    "            one_layer_only.append(token[n])\n",
    "        # hiddenDict[n] = token_vecs_sum[index].tolist()\n",
    "        eachLayerDict[n] = token_embeddings[index][n].tolist()\n",
    "\n",
    "    forjson.append({\n",
    "        'linetext' : d['text'],\n",
    "        'lemmatized_text' : d['lemmatized_text'],\n",
    "        'Author' : d['rec']['Author'],\n",
    "        'fulltext' : d['rec']['Text'],\n",
    "        'Before or after' : d['rec']['Before or after'],\n",
    "        'Source' : d['rec']['Source'],\n",
    "        'eachLayer' : eachLayerDict,\n",
    "        # 'hiddenStates' : hiddenDict\n",
    "    })\n",
    "    \n",
    "print(len(forjson))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.21235522627830505,\n",
       " -0.2960023283958435,\n",
       " 0.36839088797569275,\n",
       " -0.0356932207942009,\n",
       " 0.3543468415737152,\n",
       " 0.4621066749095917,\n",
       " -0.46916061639785767,\n",
       " -1.1899771690368652,\n",
       " 0.41594475507736206,\n",
       " 1.336857795715332]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(forjson)['eachLayer'][12][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('мир-1-30layers.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(forjson, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert using PCA and TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(509, 768)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get last layer for all \n",
    "Xs = np.array([d['eachLayer'][12] for d in forjson])\n",
    "Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=50)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert from 728 to 50\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "pca.fit(Xs.T)\n",
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_PCA = pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 50 to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_embedded = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=3).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "tsne.fit(Xs_PCA)\n",
    "Xs_TSNE = tsne.embedding_\n",
    "Xs_TSNE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are a couple additional resources for exploring this topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BERT Authors**\n",
    "\n",
    "The BERT authors tested word-embedding strategies by feeding different vector combinations as input features to a BiLSTM used on a named entity recognition task and observing the resulting F1 scores.\n",
    "\n",
    "(Image from [Jay Allamar](http://jalammar.github.io/illustrated-bert/)'s blog)\n",
    "\n",
    "\n",
    "![alt text](http://jalammar.github.io/images/bert-feature-extraction-contextualized-embeddings.png)\n",
    "\n",
    "While concatenation of the last four layers produced the best results on this specific task, many of the other methods come in a close second and in general it is advisable to test different versions for your specific application: results may vary.\n",
    "\n",
    "This is partially demonstrated by noting that the different layers of BERT encode very different kinds of information, so the appropriate pooling strategy will change depending on the application because different layers encode different kinds of information. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Han Xiao's BERT-as-service**\n",
    "\n",
    "Han Xiao created an open-source project named [bert-as-service](https://github.com/hanxiao/bert-as-service) on GitHub which is intended to create word embeddings for your text using BERT. Han experimented with different approaches to combining these embeddings, and shared some conclusions and rationale on the [FAQ page](https://github.com/hanxiao/bert-as-service#speech_balloon-faq) of the project. \n",
    "\n",
    "`bert-as-service`, by default, uses the outputs from the **second-to-last layer** of the model. \n",
    "\n",
    "I would summarize Han's perspective by the following:\n",
    "\n",
    "1. The embeddings start out in the first layer as having no contextual information (i.e., the meaning of the initial 'bank' embedding isn't specific to river bank or financial bank).\n",
    "2. As the embeddings move deeper into the network, they pick up more and more contextual information with each layer.\n",
    "3. As you approach the final layer, however, you start picking up information that is specific to BERT's pre-training tasks (the \"Masked Language Model\" (MLM) and \"Next Sentence Prediction\" (NSP)). \n",
    "    * What we want is embeddings that encode the word meaning well... \n",
    "    * BERT is motivated to do this, but it is also motivated to encode anything else that would help it determine what a missing word is (MLM), or whether the second sentence came after the first (NSP). \n",
    "4. The second-to-last layer is what Han settled on as a reasonable sweet-spot.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cite\n",
    "Chris McCormick and Nick Ryan. (2019, May 14). *BERT Word Embeddings Tutorial*. Retrieved from http://www.mccormickml.com\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03a5280fd1824ad4b9ee0ae1ef93e96a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "407824ffad4749758b27200149e731f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "43eda06351504eff8deb8204cece4119": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4849073628e2430a952fa97d1ec101e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b3be7b64c9e4d79b6b0ce55daade852": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43eda06351504eff8deb8204cece4119",
      "placeholder": "​",
      "style": "IPY_MODEL_6b29f70530354c8a813b99dcbb0d721d",
      "value": " 714M/714M [00:16&lt;00:00, 53.1MB/s]"
     }
    },
    "6b29f70530354c8a813b99dcbb0d721d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "87f6881696954d68800dbb82c525a601": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cbdccc6e24fa4dda8eeeb9da378f36b0",
       "IPY_MODEL_d22add4eef6045cf95e4a72f7428ac9d",
       "IPY_MODEL_4b3be7b64c9e4d79b6b0ce55daade852"
      ],
      "layout": "IPY_MODEL_4849073628e2430a952fa97d1ec101e6"
     }
    },
    "a5175108f4e24b68a0c37e6e495df625": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af9fc23c333b45d3ba6e0987ba608814": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbdccc6e24fa4dda8eeeb9da378f36b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5175108f4e24b68a0c37e6e495df625",
      "placeholder": "​",
      "style": "IPY_MODEL_03a5280fd1824ad4b9ee0ae1ef93e96a",
      "value": "Downloading: 100%"
     }
    },
    "d22add4eef6045cf95e4a72f7428ac9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af9fc23c333b45d3ba6e0987ba608814",
      "max": 714314041,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_407824ffad4749758b27200149e731f0",
      "value": 714314041
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
