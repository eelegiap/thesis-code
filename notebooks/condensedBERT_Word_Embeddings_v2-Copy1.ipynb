{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBw5u4on4tk8"
   },
   "source": [
    "### Load Poetry Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5PQLebu34szB",
    "outputId": "2c3356da-9374-48f7-bc37-97271976a2b9",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Text': '**Варежка\\n \\n**Весомое, двуручное тепло – цветная память о\\nпрошедшем лете – ты дунешь на ладонь,\\nкак на стекло, и звон, хрустальный\\nзвон, пойдёт повсюду: в нём\\n \\nпара рыб и праздничное блюдо, и дерево, что\\nв дерево вросло. Вся эта близость, схожая\\nс родством, есть непременно холод\\nи комета, звезда зажжённая\\n \\nнад ёлкой в Рождество – дверной глазок плюс\\nбезвозмездный дар – рука пятиконечная\\nодета, а в ней пожар. В ней иволга,\\nпоющая навзрыд, нечаянная\\n \\nдетская пропажа – спохватишься,\\nну а она всё там – фигуркой\\nподвесного пилотажа\\nс резиночкой,\\n \\n–––\\nпришитой\\nк рукавам.\\n \\nВиталий Шатовкин',\n",
       " 'Author': 'Виталий Шатовкин',\n",
       " 'Before or after': 'Before',\n",
       " 'Source': 'essentialpoetry',\n",
       " 'Date posted': datetime.datetime(2020, 12, 9, 0, 0)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load excel data\n",
    "df = pd.read_excel('../Excel_files/Full_Poem_Dataset_10-23_3.xlsx')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "records = df.to_dict('records')\n",
    "random.choice(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RfUN_KolV-f",
    "outputId": "177ce662-8e78-4ad7-8b70-378071ebc4c7"
   },
   "outputs": [],
   "source": [
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lJEnBJ3gHTsQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|███████████████████████████████████████████| 1.57M/1.57M [00:00<00:00, 5.73MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████| 112/112 [00:00<00:00, 19.7kB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████| 24.0/24.0 [00:00<00:00, 5.05kB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████| 642/642 [00:00<00:00, 141kB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pg0P9rFxJwwp",
    "outputId": "7b133608-bb30-4f8a-ce2f-20f18f9c8e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['[CLS]', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "text = random.choice(random.choice(records)['Text'].split('\\n'))\n",
    "print(text)\n",
    "\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Tokenize our sentence with the BERT tokenizer.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Print out the tokens.\n",
    "print (tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1z1SzuTrqx-7",
    "outputId": "9018432c-fd15-4603-9f65-433af389bbbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Чемпионов',\n",
       " '##uga',\n",
       " 'Рожер',\n",
       " 'именной',\n",
       " 'Milan',\n",
       " '##ящиеся',\n",
       " '##вам',\n",
       " '##ладзе',\n",
       " 'смонтированы',\n",
       " 'Горно']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(list(tokenizer.vocab.keys()),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XYjcYJuXoAQx",
    "outputId": "9d51a714-95ef-4c45-cd01-b11bce5f9ed9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "воды солёной вслушайся,\n",
      "[CLS]           101\n",
      "воды         12,240\n",
      "солё         46,590\n",
      "##ной         1,700\n",
      "всл          72,498\n",
      "##уша        29,991\n",
      "##й             860\n",
      "##ся          1,523\n",
      ",               128\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
    "text = random.choice(random.choice(records)['Text'].split('\\n'))\n",
    "print(text)\n",
    "\n",
    "# Add the special tokens.\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Display the words with their indeces.\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u_jEkVKxJMc0",
    "outputId": "7013263a-ac3a-4ce4-fa43-24ab26a6a570"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Mark each of the 22 tokens as belonging to sentence \"1\".\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "print (segments_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 29761, 102], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('следовательно')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ru-core-news-lg==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_lg-3.4.0/ru_core_news_lg-3.4.0-py3-none-any.whl (513.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m513.4/513.4 MB\u001b[0m \u001b[31m575.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting pymorphy2>=0.9\n",
      "  Using cached pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from ru-core-news-lg==3.4.0) (3.4.2)\n",
      "Collecting docopt>=0.6\n",
      "  Using cached docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pymorphy2-dicts-ru<3.0,>=2.4\n",
      "  Using cached pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "Collecting dawg-python>=0.7.1\n",
      "  Using cached DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (3.1.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (3.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (21.3)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (8.1.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (2.0.7)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (4.1.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (1.10.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (1.21.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (1.0.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (0.4.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (4.64.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (2.28.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (2.4.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: setuptools in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (63.4.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (3.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (0.0.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (2.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->ru-core-news-lg==3.4.0) (4.11.3)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=8f4b6df7f2a4a1e60d58801ac94b0c386c788d4a71bd7a88d4c3f67a6b02f78e\n",
      "  Stored in directory: /Users/paigelee/Library/Caches/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
      "Successfully built docopt\n",
      "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2, ru-core-news-lg\n",
      "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 ru-core-news-lg-3.4.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ru_core_news_lg')\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "!python -m spacy download ru_core_news_lg\n",
    "nlp = spacy.load(\"ru_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "id": "E_t4cM6KLc98",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/3502 recs done.\n",
      "250/3502 recs done.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hw/y9yj9shs7jq4jhp2rg5gb3jh0000gn/T/ipykernel_25420/1681720542.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlemmatized_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatized_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         data.append({\n",
      "\u001b[0;32m~/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2564\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2565\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2566\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2567\u001b[0m         )\n\u001b[1;32m   2568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0mreturn_special_tokens_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_special_tokens_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m         )\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mprepare_for_model\u001b[0;34m(self, ids, pair_ids, add_special_tokens, padding, truncation, max_length, stride, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[1;32m   3018\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3019\u001b[0m                 \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3020\u001b[0;31m                 \u001b[0mreturn_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3021\u001b[0m             )\n\u001b[1;32m   3022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   2825\u001b[0m                 \u001b[0mreturn_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m             )\n\u001b[0;32m-> 2827\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBatchEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2829\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequired_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "data = []\n",
    "for i, rec in enumerate(records):\n",
    "    if i%250 == 0:\n",
    "        print(f'{i}/{len(records)} recs done.')\n",
    "    if not isinstance(rec['Text'],str):\n",
    "        continue\n",
    "    lines = rec['Text'].split('\\n')\n",
    "    for line in lines:\n",
    "        if len(line.split(' ')) < 5:\n",
    "            continue\n",
    "        lemmatized_line = ' '.join([l.lemma_ for l in nlp(line)])\n",
    "        doc = tokenizer.encode_plus(lemmatized_line)\n",
    "\n",
    "        data.append({\n",
    "            'doc' : doc,\n",
    "            'tokens' : tokenizer.convert_ids_to_tokens(doc['input_ids']),\n",
    "            'text' : line,\n",
    "            'lemmatized_text' : lemmatized_line,\n",
    "            'rec' : rec\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "data = []\n",
    "for i, rec in enumerate(records):\n",
    "    if i%250 == 0:\n",
    "        print(f'{i}/{len(records)} recs done.')\n",
    "    if not isinstance(rec['Text'],str):\n",
    "        continue\n",
    "    lines = rec['Text'].split('\\n')\n",
    "    for line in lines:\n",
    "        if len(line.split(' ')) < 5:\n",
    "            continue\n",
    "        lemmatized_line = ' '.join([l.lemma_ for l in nlp(line)])\n",
    "        doc = tokenizer.encode_plus(lemmatized_line)\n",
    "\n",
    "        data.append({\n",
    "            'doc' : doc,\n",
    "            'tokens' : tokenizer.convert_ids_to_tokens(doc['input_ids']),\n",
    "            'text' : line,\n",
    "            'lemmatized_text' : lemmatized_line,\n",
    "            'rec' : rec\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('records4RuBertaFull.pickle', 'wb') as handle:\n",
    "    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pickle5 in /Users/paigelee/opt/anaconda3/envs/oldpy/lib/python3.7/site-packages (0.0.12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'doc': {'input_ids': [101, 13164, 55456, 130, 96377, 93258, 13661, 128, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]},\n",
       " 'tokens': ['[CLS]',\n",
       "  'главный',\n",
       "  'выигрыш',\n",
       "  '-',\n",
       "  'уметь',\n",
       "  'обмануть',\n",
       "  'правило',\n",
       "  ',',\n",
       "  '[SEP]'],\n",
       " 'text': 'Главный выигрыш - уметь обмануть правила,',\n",
       " 'lemmatized_text': 'главный выигрыш - уметь обмануть правило ,',\n",
       " 'rec': {'Text': 'ПАМЯТИ НИКОЛАЯ АБАЕВА**\\n**\\nСиликоновые импланты, яхты миллиардеров,\\nЗагар актеров на фоне прибоя,\\nСтатистика короновируса, статистика футбольных матчей,\\nКокорин, забивающий первый гол за Спартак,\\nИ рядом разлагающийся труп тенгрианца Николая Абаева,\\nАвтора монографии о психологических аспектах дзен буддизма,\\nУдивительной по чистоте мысли и ясности слога.\\nТираж этой книги навсегда остался в рюкзаках 80 х,\\nНа перегонах между Ялтой и Марракешем,\\nМежду Кяхтой и Джорданвиллем.\\nВероятно, Абаев покончил с собой в день своего рождения,\\nКогда ему исполнился 71 год,\\nВ съемной улан-удэнской квартире на Карла Маркса.\\nОн болел, не мог толком ходить, почти не ел, пил одну лишь воду,\\nГоворят, у него не было ни копейки,\\nЧто, по меньшей мере, странно\\nПри профессорской зарплате двух, правда, далеких от Стэнфорда, университетов,\\nТувинского и Бурятского.\\nОднако все деньги снимал банк,\\nТам был просроченный кредит,\\nЧто-то не так с финансовыми решениями.\\nОт трупа шел мерзкий сладковато-гнилостный запах,\\nНашли его почти случайно.\\nТолько не надо в конце этого текста смайлика со слезой,\\nИбо некое пространственно-временное единство,\\nОбозначенное значком Николай Абаев\\nВ лучших местах и в лучшие минуты\\nВ полноте являло пустотность существования,\\nИ это было так заразительно, так ликующе-прекрасно,\\nДавало такую свободу и такую надежду,\\nЧто иное не имеет значения.\\n \\nКогда мир - симуляция,\\nОн - роскошная игра,\\nГлавный выигрыш - уметь обмануть правила,\\nРазорвать сеть.\\nЧистое зеркало повисло в воздухе\\nИ колеблется на ветру.\\nНикакой подставки не предусмотрено.\\n \\n[Источник: Периферия. Симуляция (внутри). Стихи июня-октября 2020 года](http://www.russianpoems.ru/news/a-269.html)\\n \\n#выбор_Павла_Банникова',\n",
       "  'Author': 'Андрей Полонский',\n",
       "  'Before or after': 'Before',\n",
       "  'Source': 'metajournal',\n",
       "  'Date posted': datetime.datetime(2020, 11, 23, 0, 0)}}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip3 install pickle5\n",
    "import pickle5 as pickle\n",
    "\n",
    "with open('records4RuBerta.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "    \n",
    "random.choice(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "87f6881696954d68800dbb82c525a601",
      "cbdccc6e24fa4dda8eeeb9da378f36b0",
      "d22add4eef6045cf95e4a72f7428ac9d",
      "4b3be7b64c9e4d79b6b0ce55daade852",
      "4849073628e2430a952fa97d1ec101e6",
      "a5175108f4e24b68a0c37e6e495df625",
      "03a5280fd1824ad4b9ee0ae1ef93e96a",
      "af9fc23c333b45d3ba6e0987ba608814",
      "407824ffad4749758b27200149e731f0",
      "43eda06351504eff8deb8204cece4119",
      "6b29f70530354c8a813b99dcbb0d721d"
     ]
    },
    "collapsed": true,
    "id": "Mq2PKplWfbFv",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "12b77a5b-b75f-461f-cba8-20d341dd64e2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('DeepPavlov/rubert-base-cased',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4Qa5KkkM2Aq"
   },
   "source": [
    "Next, let's evaluate BERT on our example text, and fetch the hidden states of the network!\n",
    "\n",
    "*Side note: `torch.no_grad` tells PyTorch not to construct the compute graph during this forward pass (since we won't be running backprop here)--this just reduces memory consumption and speeds things up a little.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword = 'русский'\n",
    "sample = [d for d in data if keyword in d['lemmatized_text']]\n",
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "nN0QTZwiMzeq",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/173 recs done.\n",
      "25/173 recs done.\n",
      "50/173 recs done.\n",
      "75/173 recs done.\n",
      "100/173 recs done.\n",
      "125/173 recs done.\n",
      "150/173 recs done.\n",
      "CPU times: user 48 s, sys: 2.24 s, total: 50.2 s\n",
      "Wall time: 50.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run the text through BERT, and collect all of the hidden states produced from all 12 layers. \n",
    "hidden_state_list = []\n",
    "with torch.no_grad():\n",
    "    for i, d in enumerate(sample):\n",
    "        if i%25 == 0:\n",
    "            print(f'{i}/{len(sample)} recs done.')\n",
    "\n",
    "        tokens_tensor = torch.tensor([d['doc']['input_ids']])\n",
    "        segments_tensor = torch.tensor([d['doc']['attention_mask']])\n",
    "        \n",
    "        outputs = model(tokens_tensor, segments_tensor)\n",
    "\n",
    "        # Evaluating the model will return a different number of objects based on \n",
    "        # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "        # becase we set `output_hidden_states = True`, the third item will be the \n",
    "        # hidden states from all layers. See the documentation for more details:\n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "        hidden_states = outputs[2]\n",
    "        hidden_state_list.append(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173\n"
     ]
    }
   ],
   "source": [
    "# generate hidden states\n",
    "forjson = []\n",
    "for i, d in enumerate(sample):\n",
    "    \n",
    "    hidden_states = hidden_state_list[i]\n",
    "    \n",
    "    # last_n_layers = 2\n",
    "    # create a new dimension in the tensor\n",
    "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "    # print(token_embeddings.size())\n",
    "\n",
    "    # Remove dimension 1, the \"batches\"\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "    # print(token_embeddings.size())\n",
    "\n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "    # print(token_embeddings.size())\n",
    "\n",
    "    index = 0\n",
    "    for i, token_str in enumerate(d['tokens']):\n",
    "        if token_str == 'война':\n",
    "            index = i\n",
    "    \n",
    "    hiddenDict = dict()\n",
    "    eachLayerDict = dict()\n",
    "    for n in range(1,13):\n",
    "        token_vecs_sum = []\n",
    "        one_layer_only = []\n",
    "        for token in token_embeddings:\n",
    "            sum_vec = torch.sum(token[-n:], dim=0)\n",
    "            token_vecs_sum.append(sum_vec)\n",
    "            one_layer_only.append(token[n])\n",
    "            \n",
    "        hiddenDict[n] = token_vecs_sum[index].tolist()\n",
    "        eachLayerDict[n] = one_layer_only[index].tolist()\n",
    "        \n",
    "    # d['hidden_states']\n",
    "    forjson.append({\n",
    "        'linetext' : d['text'],\n",
    "        'lemmatized_text' : d['lemmatized_text'],\n",
    "        'Author' : d['rec']['Author'],\n",
    "        'fulltext' : d['rec']['Text'],\n",
    "        'Before or after' : d['rec']['Before or after'],\n",
    "        'Source' : d['rec']['Source'],\n",
    "        'eachLayer' : eachLayerDict,\n",
    "        # 'hiddenStates' : hiddenDict\n",
    "    })\n",
    "    \n",
    "print(len(forjson))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('russian-10-26layers.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(forjson, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "simtexts = []\n",
    "for tup in itertools.combinations(vecs, 2):\n",
    "    v1, v2 = tup\n",
    "    if v1['text'] != v2['text']:\n",
    "        vec1 = v1['vec']\n",
    "        vec2 = v2['vec']\n",
    "        sim = 1 - cosine(vec1, vec2)\n",
    "        simtexts.append({\n",
    "            'sim' : sim,\n",
    "            'text1' : v1['text'],\n",
    "            'text2' : v2['text']\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedtexts = sorted(simtexts, key=lambda x: x['sim'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sim': 1,\n",
       " 'text1': 'ВОЙНА ВОЙНА ВОЙНА ВОЙНА ВОЙНА ВОЙНА ВОЙНА ВОЙНА ВОЙНА ВОЙНА',\n",
       " 'text2': 'ВОЙНА ВОЙНА ВОЙНА ВОЙНА ВОЙНА ВОЙНА ВОЙНА ВОЙНА ВОЙНА ВОЙНА '}"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedtexts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sim': 0.14227454364299774,\n",
       " 'text1': 'ВОЙНА ВОЙНА ВОЙНА ВОЙНА ВОЙНА ВОЙНА ВОЙНА ВОЙНА ВОЙНА ВОЙНА ',\n",
       " 'text2': 'Война обнажает запах открытых ран,'}"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedtexts[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector similarity for  *similar*  meanings:  0.54\n",
      "Vector similarity for *different* meanings:  0.62\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Calculate the cosine similarity between the word bank \n",
    "# in \"bank robber\" vs \"river bank\" (different meanings).\n",
    "diff_bank = 1 - cosine(token_vecs_cat[1], token_vecs_cat[3])\n",
    "\n",
    "# Calculate the cosine similarity between the word bank\n",
    "# in \"bank robber\" vs \"bank vault\" (same meaning).\n",
    "same_bank = 1 - cosine(token_vecs_cat[3], token_vecs_cat[5])\n",
    "\n",
    "print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\n",
    "print('Vector similarity for *different* meanings:  %.2f' % diff_bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('First 5 vector values for each instance of \"игра-\".')\n",
    "# print('')\n",
    "# print(\"флейте   \", str(token_vecs_sum[2][:5]))\n",
    "# print(\"футбол  \", str(token_vecs_sum[11][:5]))\n",
    "# print(\"тубе   \", str(token_vecs_sum[20][:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ca2TCQ_G7SM3"
   },
   "source": [
    "We can see that the values differ, but let's calculate the cosine similarity between the vectors to make a more precise comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))\n",
    "# `hidden_states` is a Python list.\n",
    "print('      Type of hidden_states: ', type(hidden_states))\n",
    "\n",
    "# Each layer in the list is a torch tensor.\n",
    "print('Tensor shape for each layer: ', hidden_states[0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7jroXfKspe_"
   },
   "source": [
    "This looks pretty good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orjhWUJgmxo5",
    "tags": []
   },
   "source": [
    "## 3.5. Pooling Strategy & Layer Choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1CI97kNn8dD"
   },
   "source": [
    "Below are a couple additional resources for exploring this topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3D5qnRNmq5_"
   },
   "source": [
    "**BERT Authors**\n",
    "\n",
    "The BERT authors tested word-embedding strategies by feeding different vector combinations as input features to a BiLSTM used on a named entity recognition task and observing the resulting F1 scores.\n",
    "\n",
    "(Image from [Jay Allamar](http://jalammar.github.io/illustrated-bert/)'s blog)\n",
    "\n",
    "\n",
    "![alt text](http://jalammar.github.io/images/bert-feature-extraction-contextualized-embeddings.png)\n",
    "\n",
    "While concatenation of the last four layers produced the best results on this specific task, many of the other methods come in a close second and in general it is advisable to test different versions for your specific application: results may vary.\n",
    "\n",
    "This is partially demonstrated by noting that the different layers of BERT encode very different kinds of information, so the appropriate pooling strategy will change depending on the application because different layers encode different kinds of information. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7_CVgejm5pr"
   },
   "source": [
    "**Han Xiao's BERT-as-service**\n",
    "\n",
    "Han Xiao created an open-source project named [bert-as-service](https://github.com/hanxiao/bert-as-service) on GitHub which is intended to create word embeddings for your text using BERT. Han experimented with different approaches to combining these embeddings, and shared some conclusions and rationale on the [FAQ page](https://github.com/hanxiao/bert-as-service#speech_balloon-faq) of the project. \n",
    "\n",
    "`bert-as-service`, by default, uses the outputs from the **second-to-last layer** of the model. \n",
    "\n",
    "I would summarize Han's perspective by the following:\n",
    "\n",
    "1. The embeddings start out in the first layer as having no contextual information (i.e., the meaning of the initial 'bank' embedding isn't specific to river bank or financial bank).\n",
    "2. As the embeddings move deeper into the network, they pick up more and more contextual information with each layer.\n",
    "3. As you approach the final layer, however, you start picking up information that is specific to BERT's pre-training tasks (the \"Masked Language Model\" (MLM) and \"Next Sentence Prediction\" (NSP)). \n",
    "    * What we want is embeddings that encode the word meaning well... \n",
    "    * BERT is motivated to do this, but it is also motivated to encode anything else that would help it determine what a missing word is (MLM), or whether the second sentence came after the first (NSP). \n",
    "4. The second-to-last layer is what Han settled on as a reasonable sweet-spot.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0unZ2xh4QDap"
   },
   "source": [
    "## 4.4. Implementations\n",
    "\n",
    "You can use the code in this notebook as the foundation of your own application to extract BERT features from text. However, official [tensorflow](https://github.com/google-research/bert/blob/master/extract_features.py) and well-regarded [pytorch](https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/extract_features.py) implementations already exist that do this for you.  Additionally, [bert-as-a-service](https://github.com/hanxiao/bert-as-service) is an excellent tool designed specifically for running this task with high performance, and is the one I would recommend for production applications. The author has taken great care in the tool's implementation and provides excellent documentation (some of which was used to help create this tutorial) to help users understand the more nuanced details the user faces, like resource management and pooling strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhbZxbKRxMvM",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Cite\n",
    "Chris McCormick and Nick Ryan. (2019, May 14). *BERT Word Embeddings Tutorial*. Retrieved from http://www.mccormickml.com\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03a5280fd1824ad4b9ee0ae1ef93e96a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "407824ffad4749758b27200149e731f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "43eda06351504eff8deb8204cece4119": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4849073628e2430a952fa97d1ec101e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b3be7b64c9e4d79b6b0ce55daade852": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43eda06351504eff8deb8204cece4119",
      "placeholder": "​",
      "style": "IPY_MODEL_6b29f70530354c8a813b99dcbb0d721d",
      "value": " 714M/714M [00:16&lt;00:00, 53.1MB/s]"
     }
    },
    "6b29f70530354c8a813b99dcbb0d721d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "87f6881696954d68800dbb82c525a601": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cbdccc6e24fa4dda8eeeb9da378f36b0",
       "IPY_MODEL_d22add4eef6045cf95e4a72f7428ac9d",
       "IPY_MODEL_4b3be7b64c9e4d79b6b0ce55daade852"
      ],
      "layout": "IPY_MODEL_4849073628e2430a952fa97d1ec101e6"
     }
    },
    "a5175108f4e24b68a0c37e6e495df625": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af9fc23c333b45d3ba6e0987ba608814": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbdccc6e24fa4dda8eeeb9da378f36b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5175108f4e24b68a0c37e6e495df625",
      "placeholder": "​",
      "style": "IPY_MODEL_03a5280fd1824ad4b9ee0ae1ef93e96a",
      "value": "Downloading: 100%"
     }
    },
    "d22add4eef6045cf95e4a72f7428ac9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af9fc23c333b45d3ba6e0987ba608814",
      "max": 714314041,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_407824ffad4749758b27200149e731f0",
      "value": 714314041
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
