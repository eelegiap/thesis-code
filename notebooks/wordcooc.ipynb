{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5c1f973-8e3c-42fb-beb2-8eae75e46db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import csv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d9e97f2-a55b-4a46-98ba-f6dcdfd86baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Text': 'Снился мне странный дом, где говорила: не уходи. Ты мне отец и мать, ты мне огонь в груди. Что тут не вынимать из меня самой. Только вот не пизди, много тут не пизди. Я говорю: вернись, но вроде не уходил. Только вернись, мой друг, с плачем проснусь во тьме, будто бы на твоем плече, будто бы с сердцем твоим я расстаюсь навек. Только вернись как мой, только приди как сам. Как я за нас боюсь, как я за нас боюсь, ссыкотно небесам. Новое кабаре в мире живых калек. Слава чёрным чулкам, победа высоким трусам, красной помаде в видео шорт. В мире, где ждут войну Я запрошу антр ну, будешь ли ты со мной, любишь ли ты меня до ледяного дна, любишь ли как Христа? Всё что я раньше мог, всё, чем я раньше жил, я создавал с тобой. Ныне же кровь сворачивается из жил, язык примерзает ко льду. Надо идти до Ада, значит, что я иду.\\nБоженька, посмотри, как мы делаем это, как цирковые, какой это адский, невероятный труд. Да и Ты бы взглянул, как Правитель падшего мира, кому ужасен, а нам смешон, в просторечии Чорт. Ты не ставил на лучшее в людях, обычно проигрывал в крупном, по-мелкому побеждал. Я у Тебя, признай, с пацанами и девками кое-что отжал. Человек моей профессии умеет накладывать жгут. Давний спор между нами так и не разрешён. В старом контексте я бы сказала, как Фауст: я понял, и данке шён. Отдыхай, проспись, навсегда прощай. Но Ты же настойчив, навязчив, как никогда. Как Ты меня выбешиваешь, как и твои адепты, мелкие смрадные русские господа. \\nВернись поскорее, любовь моя, немедля, иначе этого не снесу. Шире открой глаза, посмотри на всех. Если я не смогу, другие лучше меня в огне. Если не видел письма: Я почти не могу сама, но поделаю всё сама. Снег засыпает нас, это лучший во всей истории, это почти безупречный снег.',\n",
       " 'Author': 'Елена Фанаилова',\n",
       " 'Before or after': 'Before',\n",
       " 'Source': 'Facebook',\n",
       " 'Date posted': datetime.datetime(2022, 4, 6, 0, 0),\n",
       " 'UniqueIndex': 693}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../Excel_files/Full_Poem_Dataset_12-17.xlsx')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "records = df.to_dict('records')\n",
    "random.choice(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ced3d3b6-b2e5-4199-b6f3-4470c9793a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3222"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542dae66-7ddd-45fe-9f9f-614d819b0983",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Toponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e690bb5b-658b-4c8f-aa78-a5664d9ef1b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oblasts = '''Черниговская область\n",
    "Черкасская область\n",
    "Хмельницкая область\n",
    "Херсонская область\n",
    "Харьковская область\n",
    "Тернопольская область\n",
    "Сумская область\n",
    "Севастополь\n",
    "Ровненская область\n",
    "Полтавская область\n",
    "Одесская область\n",
    "Николаевская область\n",
    "Львовская область\n",
    "Луганская область\n",
    "Кировоградская область\n",
    "Киевская область\n",
    "Киев\n",
    "Ивано-Франковская область\n",
    "Запорожская область\n",
    "Закарпатская область\n",
    "Житомирская область\n",
    "Донецкая область\n",
    "Днепропетровская область\n",
    "Волынская область\n",
    "Винницкая область\n",
    "Крым'''\n",
    "tabNames = '''Черниговщина\tЧернігівщина\tЧернигов\tЧернігів\n",
    "Черкасщина\tЧеркащина\tЧеркассы\tЧеркаси\n",
    "Хмельнитчина\tХмельниччина\tХмельницкий\tХмельницький\n",
    "Херсонщина\tХерсонщина\tХерсон\tХерсон\n",
    "Харьковщина\tХарківщина\tХарьков\tХарків\n",
    "Тернопольщина\tТернопільщина\tТернополь\tТернопіль\n",
    "Сумщина\tСумщина\tСумы\tСуми\n",
    "\t\tСевастополь\t\n",
    "Ровненщина\tРівненщина\tРівне\n",
    "Полтавщина\tПолтавщина\tПолтава\tПолтава\n",
    "Одесщина\tОдещина\tОдесса\tОдеса\n",
    "Николаевщина\tМиколаївщина\tНиколаев\tМиколаїв\n",
    "Львовщина\tЛьвівщина\tЛьвов\tЛьвів\n",
    "Луганщина\tЛуганщина\tЛуганск\tЛуганськ\n",
    "Кировоградщина\tКіровоградщина\tКропивницкий\tКропивницький\n",
    "Киевщина\tКиївщина\tКиев\tКиїв\n",
    "Ивано-Франковщина\tІвано-Франківщина\tИвано-Франковск\tІвано-Франківськ\n",
    "Запорожье\tЗапоріжжя\tЗапорожье\tЗапоріжжя\n",
    "Закарпатье\tЗакарпаття\tУжгород\tУжгород\n",
    "Житомирщина\tЖитомирщина\tЖитомир\tЖитомир\n",
    "Донетчина\tДонеччина\tДонецк\tДонецьк\n",
    "Днепропетровщина\tДніпропетровщина\tДнепр\tДніпро\n",
    "Волынщина\tВолинщина\tЛуцк\tЛуцьк\n",
    "Виннитчина\tВінниччина\tВинница\tВінниця'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3b3d8acb-8bcb-4eef-99c0-c1810b7cf11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "otherCities = '''Киев\n",
    "Харьков\n",
    "Одесса\n",
    "Днепр\n",
    "Донецк\n",
    "Львов\n",
    "Запорожье\n",
    "Кривой Рог\n",
    "Севастополь\n",
    "Николаев\n",
    "Мариуполь\n",
    "Луганск\n",
    "Винница\n",
    "Макеевка\n",
    "Симферополь\n",
    "Чернигов\n",
    "Полтава\n",
    "Херсон\n",
    "Хмельницкий\n",
    "Черкассы\n",
    "Черновцы\n",
    "Житомир\n",
    "Сумы\n",
    "Горловка\n",
    "Ивано-Франковск\n",
    "Каменское\n",
    "Тернополь\n",
    "Кропивницкий\n",
    "Луцк\n",
    "Кременчуг\n",
    "Белая Церковь\n",
    "Керчь\n",
    "Мелитополь\n",
    "Краматорск\n",
    "Ужгород\n",
    "Бровары\n",
    "Евпатория\n",
    "Бердянск\n",
    "Алчевск\n",
    "Никополь\n",
    "Славянск\n",
    "Павлоград\n",
    "Северодонецк\n",
    "Каменец-Подольский\n",
    "Лисичанск\n",
    "Красный Луч\n",
    "Енакиево\n",
    "Александрия\n",
    "Стаханов\n",
    "Кадиевка\n",
    "Константиновка'''.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8cbbc030-bc02-44b7-bb09-451e2caa7e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "oblasts = [d.replace(' область','') for d in oblasts.split('\\n')]\n",
    "cityNames = []\n",
    "centerNames = [[cityNames.append(t) for t in l.split('\\t') if t != ''] for l in tabNames.split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c4239ea0-b7d7-4dd2-aa76-6fc952f069c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoNames = otherCities + oblasts + cityNames + 'Донбас Винница, Буча, Ирпень, Киев, Мариуполь, Одесса, Крым, Луганск, Донецк, Днепр, Запорожье, Львов, Харьков, Херсон, Симферополь, чернигов, Черновцы, житомир, Полтава, Николаев, Гостомель, Краматорск'.split(', ')\n",
    "geoNames = list(set(geoNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fb9d124c-d070-4761-979d-9e5adbcd5570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 3222/3222 [00:07<00:00, 413.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Before': 53, 'After': 460}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'крым': {'Before': 16, 'After': 10},\n",
       " 'донбасс': {'Before': 5, 'After': 14},\n",
       " 'мариуполь': {'Before': 2, 'After': 63},\n",
       " 'харьков': {'Before': 3, 'After': 59},\n",
       " 'киев': {'Before': 4, 'After': 80},\n",
       " 'буча': {'Before': 0, 'After': 64},\n",
       " 'винница': {'Before': 1, 'After': 11},\n",
       " 'одесса': {'Before': 10, 'After': 21},\n",
       " 'запорожье': {'Before': 1, 'After': 3},\n",
       " 'херсон': {'Before': 2, 'After': 18},\n",
       " 'николаев': {'Before': 0, 'After': 3},\n",
       " 'лисичанск': {'Before': 0, 'After': 2},\n",
       " 'мелитополь': {'Before': 0, 'After': 2},\n",
       " 'северодонецк': {'Before': 0, 'After': 3},\n",
       " 'полтава': {'Before': 0, 'After': 3},\n",
       " 'донецк': {'Before': 3, 'After': 4},\n",
       " 'днепр': {'Before': 3, 'After': 19},\n",
       " 'чернигов': {'Before': 0, 'After': 13},\n",
       " 'львов': {'Before': 1, 'After': 9},\n",
       " 'сумы': {'Before': 0, 'After': 2},\n",
       " 'ирпень': {'Before': 0, 'After': 20},\n",
       " 'гостомель': {'Before': 0, 'After': 6},\n",
       " 'керчь': {'Before': 1, 'After': 0},\n",
       " 'кременчуг': {'Before': 0, 'After': 2},\n",
       " 'кропивницкий': {'Before': 0, 'After': 1},\n",
       " 'славянск': {'Before': 0, 'After': 1},\n",
       " 'черновцы': {'Before': 0, 'After': 1},\n",
       " 'харків': {'Before': 0, 'After': 1},\n",
       " 'київ': {'Before': 0, 'After': 1},\n",
       " 'краматорск': {'Before': 0, 'After': 8},\n",
       " 'луганск': {'Before': 0, 'After': 1},\n",
       " 'бердянск': {'Before': 0, 'After': 2},\n",
       " 'житомир': {'Before': 0, 'After': 1},\n",
       " 'горловка': {'Before': 1, 'After': 0},\n",
       " 'луцк': {'Before': 0, 'After': 9},\n",
       " 'никополь': {'Before': 0, 'After': 1},\n",
       " 'киевская': {'Before': 0, 'After': 1},\n",
       " 'закарпатье': {'Before': 0, 'After': 1}}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### how manyc ity names?\n",
    "cities = [d.lower() for d in geoNames+ ['Донбасс']]\n",
    "cityDict = dict()\n",
    "allMentions = {'Before' : 0,'After' : 0}\n",
    "for rec in tqdm(records):\n",
    "    p = rec['Before or after']\n",
    "    for t in rec['spacydoc']:\n",
    "        if t.lemma_.lower() in cities:\n",
    "            cityDict.setdefault(t.lemma_, {'Before' : 0, 'After' : 0})\n",
    "            cityDict[t.lemma_][p] += 1\n",
    "            allMentions[p] += 1\n",
    "print(allMentions)\n",
    "cityDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3d72cca8-3735-4dc5-b560-2e427cb3a745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['украина', 'крым', 'мариуполь', 'харьков', 'киев', 'буча', 'винница', 'одесса', 'запорожье', 'херсон', 'николаев', 'лисичанск', 'мелитополь', 'северодонецк', 'полтава', 'донецк', 'днепр', 'чернигов', 'львов', 'сумы', 'ирпень', 'гостомель', 'керчь', 'кременчуг', 'кропивницкий', 'славянск', 'черновцы', 'харків', 'київ', 'краматорск', 'луганск', 'бердянск', 'житомир', 'горловка', 'луцк', 'никополь', 'киевская', 'закарпатье'])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cityDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b222af2f-f719-49b3-b97a-dc271be70438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gostomel\n",
      "Dnieper\n",
      "Donetsk\n",
      "Zhitomir\n",
      "Transcarpathia\n",
      "Zaporozhye\n",
      "Irpin\n",
      "Kerch\n",
      "Kyiv/Kyiv/Kiev\n",
      "Kramatorsk\n",
      "Kremenchug\n",
      "Kropyvnytskyi\n",
      "Crimea\n",
      "Lisichansk\n",
      "Lugansk\n",
      "Lutsk\n",
      "Lviv\n",
      "Mariupol\n",
      "Melitopol\n",
      "Nikolaev\n",
      "Nikopol\n",
      "Odessa\n",
      "Poltava\n",
      "Severodonetsk\n",
      "Slavyansk\n",
      "Sumy\n",
      "Kharkiv/Kharkov\n",
      "Kherson\n",
      "Chernihiv\n",
      "Chernivtsi\n"
     ]
    }
   ],
   "source": [
    "cs = '''Gostomel\n",
    "Dnieper\n",
    "Donetsk\n",
    "Zhitomir\n",
    "Transcarpathia\n",
    "Zaporozhye\n",
    "Irpin\n",
    "Kerch\n",
    "Kyiv/Kyiv/Kiev\n",
    "Kramatorsk\n",
    "Kremenchug\n",
    "Kropyvnytskyi\n",
    "Crimea\n",
    "Lisichansk\n",
    "Lugansk\n",
    "Lutsk\n",
    "Lviv\n",
    "Mariupol\n",
    "Melitopol\n",
    "Nikolaev\n",
    "Nikopol\n",
    "Odessa\n",
    "Poltava\n",
    "Severodonetsk\n",
    "Slavyansk\n",
    "Sumy\n",
    "Kharkiv/Kharkov\n",
    "Kherson\n",
    "Chernihiv\n",
    "Chernivtsi'''.split('\\n')\n",
    "for c in cs:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17506dec-bb0c-4b4b-85a0-07e7f46ba5e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Looking at most labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d02c1eee-e4f9-49ad-bd2a-8bf83a1986ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.sqrt(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "79c98133-4834-41d5-a8ce-a51fe3516be6",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jj/_szc94p56q91q_7c209d1d9w0000gn/T/ipykernel_17918/1359293570.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetworkJson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Russia'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'links'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# keyword = 'мариуполь'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0;31m# value = math.sqrt(link['linkCtAfter']) - math.sqrt(link['linkCtBefore'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0;31m# lst.append({'value' : value, 'info' : link})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# linkedWords = set()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/random.py\u001b[0m in \u001b[0;36mchoice\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;34m\"\"\"Choose a random element from a non-empty sequence.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;31m# raises IndexError if seq is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(random.choice(networkJson['Russia']['links']))\n",
    "# keyword = 'мариуполь'\n",
    "            # value = math.sqrt(link['linkCtAfter']) - math.sqrt(link['linkCtBefore'])\n",
    "            # lst.append({'value' : value, 'info' : link})\n",
    "# linkedWords = set()\n",
    "# linkUps = {'Before' : [], 'After' : []}\n",
    "lst = []\n",
    "\n",
    "city = 'надежда'\n",
    "for where in networkJson:\n",
    "    ct = 0\n",
    "    for link in tqdm(networkJson[where]['links']):\n",
    "        if city in [link['sourceLemma'],link['targetLemma']] and (link['sourceLemma'] not in stopwords) and (link['targetLemma'] not in stopwords):\n",
    "            ct += 1\n",
    "            # if (link['sourceLemma'] not in stopwords) and (link['targetLemma'] not in stopwords):\n",
    "            # if (len(link['sourceLemma']) > 2) and (len(link['targetLemma']) > 2):\n",
    "            value = link['linkCtAfter'] + link['linkCtBefore']\n",
    "            lst.append({'value' : value, 'info' : link})\n",
    "    print(where, ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a20372-7de1-42e8-aa92-5fa2f1560792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for d in sorted(lst, key=lambda x: x['value'],reverse=True)[:20]:\n",
    "    print(d['info']['sourceLemma'], d['info']['targetLemma']) \n",
    "    print(d['info']['linkCtBefore'],d['info']['linkCtAfter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "eb0402b2-e3cf-4960-ae60-0ad006cdfb58",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'linkCtBefore'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jj/_szc94p56q91q_7c209d1d9w0000gn/T/ipykernel_17918/3712497561.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'linkCtBefore'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'linkCtAfter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# if d['linkCtBefore'] + d['linkCtAfter'] > 4:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'linkCtAfter'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'linkCtBefore'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'linkCtBefore'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'linkCtAfter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;31m# print(d['linkCtAfter'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/jj/_szc94p56q91q_7c209d1d9w0000gn/T/ipykernel_17918/3712497561.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'linkCtBefore'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'linkCtAfter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# if d['linkCtBefore'] + d['linkCtAfter'] > 4:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'linkCtAfter'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'linkCtBefore'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'linkCtBefore'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'linkCtAfter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;31m# print(d['linkCtAfter'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'linkCtBefore'"
     ]
    }
   ],
   "source": [
    "# for d in sorted(lst, key=lambda x: (x['linkCtBefore'] + x['linkCtAfter']),reverse=True):\n",
    "#     # if d['linkCtBefore'] + d['linkCtAfter'] > 4:\n",
    "#     if d['linkCtAfter'] - d['linkCtBefore'] > 3:\n",
    "#         if d['linkCtBefore'] < d['linkCtAfter']:\n",
    "#             # print(d['linkCtAfter'])\n",
    "#             print(d['sourceLemma'], d['targetLemma']) \n",
    "#             print(d['linkCtBefore'],d['linkCtAfter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "7f20fbba-6190-4e93-b3b4-47748ed3d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in sorted(linkUps['After'], key=lambda x: x['value'],reverse=True)[]:\n",
    "#     print(d['info']['sourceLemma'], d['info']['targetLemma']) \n",
    "#     print(d['info']['linkCtBefore'],d['info']['linkCtAfter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c26466c-1b62-4a16-9dd4-f516e5441565",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Checking specific labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a3b4acd5-8405-466b-b332-36b15a76ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../../label2lines_3-3.json', 'r', encoding='utf-8') as f:\n",
    "    linedata = label2lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b079e3dd-8db6-46f6-b70e-585e25329774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'порождатьANDсуществовать'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(list(linedata.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b33e71-a1b1-49eb-aa12-6f41cab0fcf9",
   "metadata": {},
   "source": [
    "### How often are two words used together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558199e3-5de4-48d4-b120-31687cfb5de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rec in tqdm(records):\n",
    "        \n",
    "    if rec['Before or after'] != period:\n",
    "        continue\n",
    "\n",
    "    doc = rec['spacydoc']\n",
    "    newdoc = [t for t in doc if (t.text.isalpha() or t.text == '\\n')]\n",
    "    doclen = len(newdoc)\n",
    "    # # line jumping\n",
    "    allLines = []\n",
    "    newLine = []\n",
    "    for i, t in enumerate(newdoc):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "018e50ce-91af-4597-a44b-d83cfadaa860",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'западANDкиев'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jj/_szc94p56q91q_7c209d1d9w0000gn/T/ipykernel_61286/2338696909.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'киев'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'AND'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinedata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'period'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'excerpt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'западANDкиев'"
     ]
    }
   ],
   "source": [
    "w1 = 'запад'\n",
    "w2 = 'киев'\n",
    "key ='AND'.join(sorted([w1,w2]))\n",
    "for d in linedata[key]:\n",
    "    print(d['period'], '\\n', d['excerpt'],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fac76d1-ab27-4756-9d0f-b1b62d7f3bc9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## nearest neighbors of cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a713a43-8640-4dea-97aa-55e6e2745d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../../files2big/before-after-average-BERT-PROPN_0.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e63db0b4-be2b-4987-8cd5-5d87f48d82f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../../files2big/before-after-average-BERT-1.json', 'r', encoding='utf-8') as f:\n",
    "    newdata = json.load(f)\n",
    "data.update(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "250538d0-229a-404c-83f5-d614e7bedca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for place in t.split('\\n'):\n",
    "#     newdata[place] = data[place]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "152a1d70-ff09-4bd6-98de-c9cda780b89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(798, 1047)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newdata), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2c7063df-257a-4672-b906-42c85a0fa6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'../../files2big/all-BERT.json', 'w') as json_file:\n",
    "#     json.dump(newdata, json_file, ensure_ascii = False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "668a4d58-5d2c-45e6-aeb7-f1517d68eb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../averageTSNE/pnouns.txt','r') as f:\n",
    "#     pns = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f6c5b570-491b-4070-af07-58f9686ade3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'../averageTSNE/places.json', 'w') as json_file:\n",
    "#     json.dump(t.split('\\n'), json_file, ensure_ascii = False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9cec9d9-12bd-47cc-ae9e-09250250e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosim(a,b):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    return dot(a, b)/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "36d25a17-2bea-429d-add6-e9a2a1fa7943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'бердянск'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities = ['крым', 'мариуполь', 'харьков', 'киев', 'буча', 'винница', 'одесса', 'запорожье', 'херсон', 'николаев', 'лисичанск', 'мелитополь', 'северодонецк', 'полтава', 'донецк', 'днепр', 'чернигов', 'львов', 'сумы', 'ирпень', 'гостомель', 'керчь', 'кременчуг', 'кропивницкий', 'славянск', 'черновцы', 'харків', 'київ', 'краматорск', 'луганск', 'бердянск', 'житомир', 'горловка', 'луцк', 'никополь', 'киевская', 'закарпатье']\n",
    "random.choice(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bab2dffd-c329-4947-83ec-7aa229933df7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1047/1047 [00:01<00:00, 992.22it/s]\n"
     ]
    }
   ],
   "source": [
    "keyword = 'буча'\n",
    "periods = ['Average','Before','After']\n",
    "\n",
    "cosinesims = dict()\n",
    "for d in tqdm(data):\n",
    "    for p in periods:\n",
    "        cosinesims.setdefault(p, [])\n",
    "        if not data[d][p]==np.zeros(768).tolist() and not data[keyword][p]==np.zeros(768).tolist():\n",
    "            cosinesims[p].append({'cosim' : cosim(data[d][p],data[keyword][p]), 'word' : d})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "06c4c024-bb7c-45ea-95af-1a1810c89eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cosim': 1.0, 'word': 'буча'},\n",
       " {'cosim': 0.9086308734617394, 'word': 'буче'},\n",
       " {'cosim': 0.8982766065857158, 'word': 'бучу'},\n",
       " {'cosim': 0.5940954032209228, 'word': 'буратино'},\n",
       " {'cosim': 0.5156366073879157, 'word': 'саша'},\n",
       " {'cosim': 0.508578160103435, 'word': 'луцк'},\n",
       " {'cosim': 0.48154723321623044, 'word': 'киев'},\n",
       " {'cosim': 0.4710904695285041, 'word': 'град'},\n",
       " {'cosim': 0.4703535255279665, 'word': 'ирпень'},\n",
       " {'cosim': 0.4700514796340463, 'word': 'польша'}]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(cosinesims['After'], key=lambda x: x['cosim'],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "44c7c495-a909-4162-87d2-8eb088fd576c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['бумага', 'разговор', 'зуб', 'поэт', 'народ', 'граница', 'сложный', 'песня', 'общий', 'страна', 'берег', 'сторона', 'корень', 'знак', 'звук', 'рука', 'ребёнок', 'предмет', 'лодка', 'слово', 'крик', 'говорить', 'речь', 'губа', 'корабль', 'враг', 'книга', 'стих', 'кожа', 'кость', 'лист', 'земля', 'русский', 'голос', 'взгляд', 'язык', 'дух']\n"
     ]
    }
   ],
   "source": [
    "[{'cosim': 1.0, 'word': 'ирпень'},\n",
    " {'cosim': 0.874249479937607, 'word': 'ирпене'},\n",
    " {'cosim': 0.5093010577205944, 'word': 'луцк'},\n",
    " {'cosim': 0.5038240634210285, 'word': 'чернигов'},\n",
    " {'cosim': 0.4933369825133888, 'word': 'чижик'},\n",
    " {'cosim': 0.48220810231405437, 'word': 'гостомель'},\n",
    " {'cosim': 0.47376990802902696, 'word': 'киев'},\n",
    " {'cosim': 0.4703535255279665, 'word': 'буча'},\n",
    " {'cosim': 0.4684321289865723, 'word': 'рязань'},\n",
    " {'cosim': 0.46359688429203494, 'word': 'и'}]\n",
    "\n",
    "[{'cosim': 1.0, 'word': 'мариуполь'},\n",
    " {'cosim': 0.6187862678638423, 'word': 'донецк'},\n",
    " {'cosim': 0.5945884674497959, 'word': 'харьков'},\n",
    " {'cosim': 0.5671606218504281, 'word': 'чернигов'},\n",
    " {'cosim': 0.5318473334960235, 'word': 'луцк'},\n",
    " {'cosim': 0.5266546988120171, 'word': 'херсон'},\n",
    " {'cosim': 0.49026229317379005, 'word': 'киев'},\n",
    " {'cosim': 0.4542774967366994, 'word': 'мандельштам'},\n",
    " {'cosim': 0.4534011455908419, 'word': 'петрович'},\n",
    " {'cosim': 0.453060231378015, 'word': 'донбасс'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3b9229-bc58-4f3e-a0ae-28a37789f49f",
   "metadata": {},
   "source": [
    "## Word Co-occurrence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b227b56-aeef-4944-aff5-1235b96ad4ec",
   "metadata": {},
   "source": [
    "### Initialize Spacy models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "371f9312-6a74-41ee-aa5e-21f121b3be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc2dcde1-6e44-45a8-9608-4fab8aeafbcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download uk_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52702e34-a4ff-4035-a28a-2d0c84216d42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download ru_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b3b5557-9ce4-4537-8499-a02eda62f099",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ru_core_news_lg\", disable=['attribute_ruler','ner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942516f5-328e-43c1-bbe7-7569aaafc87f",
   "metadata": {},
   "source": [
    "### Generate Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1efa21f-a33d-4adb-9c00-b8f280d09221",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 3222/3222 [03:56<00:00, 13.65it/s]\n"
     ]
    }
   ],
   "source": [
    "for rec in tqdm(records):\n",
    "    recTxt = rec['Text']\n",
    "    # if not isinstance(recTxt,str):\n",
    "    #     recTxt = str(recTxt)\n",
    "    doc = nlp(recTxt)\n",
    "    rec['spacydoc'] = doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64b179b-158c-4d4e-a97b-897dee35c264",
   "metadata": {},
   "source": [
    "### Run cooc parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05b78a34-0444-4d3d-93a0-9a06e49006b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "140544ad-c44a-4e92-81e1-0da4761dfc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.ru import stop_words\n",
    "ru_stops = stop_words.STOP_WORDS\n",
    "\n",
    "from spacy.lang.en import stop_words\n",
    "en_stops = stop_words.STOP_WORDS\n",
    "\n",
    "from spacy.lang.uk import stop_words\n",
    "uk_stops = stop_words.STOP_WORDS\n",
    "\n",
    "from spacy.lang.es import stop_words\n",
    "es_stops = stop_words.STOP_WORDS\n",
    "\n",
    "from spacy.lang.pl import stop_words\n",
    "pl_stops = stop_words.STOP_WORDS\n",
    "\n",
    "stopwords = list(ru_stops)+list(uk_stops)\n",
    "foreign_stops = list(en_stops)+list(es_stops)+list(pl_stops)\n",
    "short_stops = [s for s in stopwords if len(s) < 3]\n",
    "short_ru_stops = [s for s in ru_stops if len(s) < 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e983f2f6-8b37-4ea4-8973-2a4965df02e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isLemma(txt):\n",
    "    if txt in ['быть','бывать','будет','будем','буду','будут']:\n",
    "        return True\n",
    "    for p in string.punctuation+'—'+'–':\n",
    "        if p in txt:\n",
    "            return False\n",
    "    if txt.isspace():\n",
    "        return False\n",
    "    # if txt in foreign_stops:\n",
    "        return False\n",
    "    # if txt in short_stops:\n",
    "    #     return False\n",
    "    if txt in stopwords:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8995008-9391-4d6c-96cd-28eee8c64428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isLemma('он')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c46ccf2-92dd-48a4-a059-550c1b6002fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isLemma('сказать')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2202d39e-5e2f-44de-95d0-f0e0811d1b62",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Before and after separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed635a2f-dc8d-4b57-b0d5-2fdea3c2ca6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding sufficient nodes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 3222/3222 [00:07<00:00, 458.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 3222/3222 [00:18<00:00, 172.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote the jsons!\n"
     ]
    }
   ],
   "source": [
    "for period in ['Before','After'][1:]:\n",
    "    \n",
    "    lens=set()\n",
    "    lenCts = dict()\n",
    "\n",
    "    networkJson = dict()\n",
    "    networkJson['nodes'] = []\n",
    "    networkJson['links'] = []\n",
    "\n",
    "    curatedNodes = set()\n",
    "    linkCounter = dict()\n",
    "    lemmaCounter = dict()\n",
    "\n",
    "    print('finding sufficient nodes...')\n",
    "\n",
    "    for rec in tqdm(records):\n",
    "        # if rec['Before or after'] != period:\n",
    "            # continue\n",
    "            \n",
    "        recTxt = rec['Text']\n",
    "\n",
    "        doc = rec['spacydoc']\n",
    "        for t1 in doc:\n",
    "            l1 = t1.lemma_.lower()\n",
    "            lemmaCounter.setdefault(l1, 0)\n",
    "            lemmaCounter[l1] += 1\n",
    "\n",
    "    # find those nodes which occur enough times\n",
    "    sufficientNodes = set()\n",
    "    for lemma in lemmaCounter:\n",
    "        if lemmaCounter[lemma] >= 5 and isLemma(lemma):\n",
    "            sufficientNodes.add(lemma.lower())\n",
    "\n",
    "\n",
    "    label2lines = dict()\n",
    "    # label2recs = dict()\n",
    "    label2authors = dict()\n",
    "\n",
    "    print('parsing links...')\n",
    "    for rec in tqdm(records):\n",
    "        \n",
    "        if rec['Before or after'] != period:\n",
    "            continue\n",
    "        \n",
    "        doc = rec['spacydoc']\n",
    "        newdoc = [t for t in doc if (t.text.isalpha() or t.text == '\\n')]\n",
    "        doclen = len(newdoc)\n",
    "        # # line jumping\n",
    "        allLines = []\n",
    "        newLine = []\n",
    "        for i, t in enumerate(newdoc):\n",
    "            if t.text == '\\n':\n",
    "                allLines.append(newLine)\n",
    "                newLine = []\n",
    "            elif i == doclen-1:\n",
    "                allLines.append(newLine)\n",
    "            else:\n",
    "                newLine.append(t)\n",
    "        numLines = len(allLines)\n",
    "        windowlength = 4\n",
    "\n",
    "        labelFoundFromLine = dict()\n",
    "        for i1 in range(numLines-windowlength):\n",
    "            # all tokens in the desired range\n",
    "            tokensInWindow = []\n",
    "            excerptLines = []\n",
    "            for line in allLines[i1:i1+windowlength]:\n",
    "                excerptLines.append(' '.join([t.text for t in line]))\n",
    "                for token in line:\n",
    "                    tokensInWindow.append(token)\n",
    "            tiw = len(tokensInWindow)\n",
    "            lens.add(tiw)\n",
    "            lenCts.setdefault(tiw,0)\n",
    "            lenCts[tiw] += 1\n",
    "            if tiw > 50:\n",
    "                continue\n",
    "\n",
    "            for ic, (t1, t2) in enumerate(itertools.combinations(tokensInWindow,2)):\n",
    "                l1 = t1.lemma_.lower()\n",
    "                l2 = t2.lemma_.lower()\n",
    "                if l1 != l2 and l1 in sufficientNodes and l2 in sufficientNodes:\n",
    "                    label = 'AND'.join(sorted([l1, l2]))\n",
    "\n",
    "                    ### label already found in line?\n",
    "                    repeatedInstance = False\n",
    "                    for line in excerptLines:\n",
    "                        labelFoundFromLine.setdefault((label, line), False)\n",
    "                        if labelFoundFromLine[(label, line)]:\n",
    "                            repeatedInstance = True\n",
    "                        else:\n",
    "                            labelFoundFromLine[(label, line)] = True\n",
    "                    if repeatedInstance:\n",
    "                        continue\n",
    "\n",
    "                    label2authors.setdefault(label, set())\n",
    "                    label2authors[label].add(rec['Author'])\n",
    "#                     label2recs.setdefault(label, [])\n",
    "#                     if rec not in label2recs[label]:\n",
    "#                         label2recs[label].append(rec)\n",
    "\n",
    "                    excerpt = '\\n'.join(excerptLines)\n",
    "                    label2lines.setdefault(label, [])\n",
    "                    if excerpt not in [e['excerpt'] for e in label2lines[label]]:\n",
    "                        # increase link Ct\n",
    "                        linkCounter.setdefault(label, 0)\n",
    "                        linkCounter[label] += 1\n",
    "                        period = rec['Before or after']\n",
    "                        if pd.isna(period):\n",
    "                            period = ''\n",
    "                        author = rec['Author']\n",
    "                        if pd.isna(author):\n",
    "                            author = 'Unknown'\n",
    "                        label2lines[label].append({\n",
    "                            'excerpt' : excerpt,\n",
    "                            'author' : author,\n",
    "                            'period' : period,\n",
    "                            'uniqueIndex' : rec['UniqueIndex']\n",
    "                        })\n",
    "\n",
    "    node2id = dict()\n",
    "    for i, node in enumerate(sufficientNodes):\n",
    "        networkJson['nodes'].append({\n",
    "            'id' : node,\n",
    "            'totalinstances' : lemmaCounter[node]\n",
    "        })\n",
    "        node2id[node] = i\n",
    "\n",
    "    for label in linkCounter:\n",
    "        source = label.split('AND')[0]\n",
    "        target = label.split('AND')[1]\n",
    "        if lemmaCounter[source] > 9 and lemmaCounter[target] > 9:\n",
    "            networkJson['links'].append({\n",
    "                'source' : node2id[source],\n",
    "                'target' : node2id[target],\n",
    "                'sourceLemma' : source,\n",
    "                'targetLemma' : target,\n",
    "                'linkCt' : linkCounter[label],\n",
    "                'authorCt' : list(label2authors[label])\n",
    "            })\n",
    "\n",
    "    # with open(f'../wordnet/data/{period}-wordnet2lines_allstops_2-21.json', 'w') as json_file:\n",
    "    #     json.dump(networkJson, json_file, ensure_ascii = False, indent=4)\n",
    "    # with open(f'../wordnet/data/{period}-label2lines_2-21.json', 'w') as json_file:\n",
    "    #     json.dump(label2lines, json_file, ensure_ascii=False, indent=4)\n",
    "    print('wrote the jsons!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2670699f-75ad-4e1c-97f6-75c6b8e33071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 6397,\n",
       " 'target': 1554,\n",
       " 'sourceLemma': 'воздух',\n",
       " 'targetLemma': 'тьма',\n",
       " 'linkCt': 2,\n",
       " 'authorCt': ['Михаил Айзенберг', 'Геннадий Каневский']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(networkJson['links'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b04c4952-fc28-43ac-8f98-f50fb11fbb0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'западANDкиев'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jj/_szc94p56q91q_7c209d1d9w0000gn/T/ipykernel_24052/1458494273.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'киев'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'AND'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel2lines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'period'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'excerpt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'западANDкиев'"
     ]
    }
   ],
   "source": [
    "w1 = 'запад'\n",
    "w2 = 'киев'\n",
    "key ='AND'.join(sorted([w1,w2]))\n",
    "for d in label2lines[key]:\n",
    "    print(d['period'], '\\n', d['excerpt'],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7eea5d-5a9a-4791-9cbd-1f0341b0fa4f",
   "metadata": {},
   "source": [
    "## Before and After Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a418a4a-6b71-47f8-9dac-0ad641c9c322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a59e609-2957-475c-8007-50ef556c8723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Poems</th>\n",
       "      <th>Author</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Identification</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Link to bio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Виген Аракелян</td>\n",
       "      <td>Razdan</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>https://polutona.ru/?show=arakelian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Герман Лукомников</td>\n",
       "      <td>Baku</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>https://ru.wikipedia.org/wiki/%D0%9B%D1%83%D0%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Александр Иличевский</td>\n",
       "      <td>Sumgait</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>https://ru.wikipedia.org/wiki/%D0%98%D0%BB%D0%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Леонид Шваб</td>\n",
       "      <td>Babruysk</td>\n",
       "      <td>Belarus</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>http://www.litkarta.ru/world/israel/persons/sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Ирина Валерина</td>\n",
       "      <td>Babruysk</td>\n",
       "      <td>Belarus</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Poems                Author      City     Country Identification  \\\n",
       "0                3        Виген Аракелян    Razdan     Armenia            N/A   \n",
       "1                1     Герман Лукомников      Baku  Azerbaijan            N/A   \n",
       "2                1  Александр Иличевский   Sumgait  Azerbaijan            N/A   \n",
       "3                7           Леонид Шваб  Babruysk     Belarus            N/A   \n",
       "4                6        Ирина Валерина  Babruysk     Belarus            N/A   \n",
       "\n",
       "  Notes                                        Link to bio  \n",
       "0   N/A                https://polutona.ru/?show=arakelian  \n",
       "1   N/A  https://ru.wikipedia.org/wiki/%D0%9B%D1%83%D0%...  \n",
       "2   N/A  https://ru.wikipedia.org/wiki/%D0%98%D0%BB%D0%...  \n",
       "3   N/A  http://www.litkarta.ru/world/israel/persons/sh...  \n",
       "4   N/A                                                N/A  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authorsDf = pd.read_excel('../Excel_files/Thesis Authors.xlsx')\n",
    "authorsDf = authorsDf.fillna('N/A')\n",
    "aRecs = authorsDf.to_dict('records')\n",
    "authorDict = dict()\n",
    "for a in aRecs:\n",
    "    authorDict[a['Author']] = a\n",
    "authorsDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "514d5773-5ca3-4732-8714-3ece47e6d6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N/A'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authorDict[rec['Author']]['Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfc7f9c6-1b6a-446f-9e0d-683086b20ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding sufficient nodes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 3222/3222 [00:01<00:00, 1904.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing links...\n",
      "all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 3222/3222 [00:17<00:00, 179.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47, 34, 33, 27, 26, 25, 24, 24, 23, 23]\n",
      "wrote the json!\n"
     ]
    }
   ],
   "source": [
    "lens=set()\n",
    "lenCts = dict()\n",
    "\n",
    "# networkJson = {'Non-Russia' : dict(), 'Russia' : dict(), 'Unknown' : dict()}\n",
    "# for aff in networkJson:\n",
    "for aff in ['all']:\n",
    "    networkJson.setdefault(aff, dict())\n",
    "    networkJson[aff]['nodes'] = []\n",
    "    networkJson[aff]['links'] = []\n",
    "\n",
    "lemmaCounter = dict()\n",
    "\n",
    "print('finding sufficient nodes...')\n",
    "\n",
    "for rec in tqdm(records):\n",
    "    # if rec['Before or after'] != period:\n",
    "        # continue\n",
    "\n",
    "    recTxt = rec['Text']\n",
    "\n",
    "    doc = rec['spacydoc']\n",
    "    for t1 in doc:\n",
    "        l1 = t1.lemma_.lower()\n",
    "        lemmaCounter.setdefault(l1, 0)\n",
    "        lemmaCounter[l1] += 1\n",
    "\n",
    "# find those nodes which occur enough times\n",
    "sufficientNodes = set()\n",
    "for lemma in lemmaCounter:\n",
    "    if lemmaCounter[lemma] >= 5 and isLemma(lemma):\n",
    "        sufficientNodes.add(lemma.lower())\n",
    "\n",
    "print('parsing links...')\n",
    "for aff in ['all']:\n",
    "    print(aff)\n",
    "    \n",
    "    allLabels = set()\n",
    "    label2lines = dict()\n",
    "    # label2recs = dict()\n",
    "    label2authors = dict()\n",
    "    linkCounter = {'Before' : dict(), 'After' : dict()}\n",
    "    \n",
    "    for rec in tqdm(records):\n",
    "        \n",
    "#         if rec['Author'] not in authorDict:\n",
    "#             continue\n",
    "#         if authorDict[rec['Author']]['Country'] == 'Russia':\n",
    "#             thisaff = 'Russia'\n",
    "#         elif authorDict[rec['Author']]['Country'] == 'N/A':\n",
    "#             thisaff = 'Unknown'\n",
    "#         else:\n",
    "#             thisaff = 'Non-Russia'\n",
    "            \n",
    "#         if thisaff != aff:\n",
    "#             continue\n",
    "        \n",
    "        period = rec['Before or after']\n",
    "        doc = rec['spacydoc']\n",
    "        newdoc = [t for t in doc if (t.text.isalpha() or t.text == '\\n')]\n",
    "        doclen = len(newdoc)\n",
    "        # # line jumping\n",
    "        allLines = []\n",
    "        newLine = []\n",
    "        for i, t in enumerate(newdoc):\n",
    "            if t.text == '\\n':\n",
    "                allLines.append(newLine)\n",
    "                newLine = []\n",
    "            elif i == doclen-1:\n",
    "                allLines.append(newLine)\n",
    "            else:\n",
    "                newLine.append(t)\n",
    "        numLines = len(allLines)\n",
    "        windowlength = 2\n",
    "\n",
    "        labelFoundFromLine = dict()\n",
    "        for i1 in range(numLines-windowlength):\n",
    "            # all tokens in the desired range\n",
    "            tokensInWindow = []\n",
    "            excerptLines = []\n",
    "            for line in allLines[i1:i1+windowlength]:\n",
    "                excerptLines.append(' '.join([t.text for t in line]))\n",
    "                for token in line:\n",
    "                    tokensInWindow.append(token)\n",
    "            tiw = len(tokensInWindow)\n",
    "            lens.add(tiw)\n",
    "            lenCts.setdefault(tiw,0)\n",
    "            lenCts[tiw] += 1\n",
    "            if tiw > 50:\n",
    "                continue\n",
    "\n",
    "            for ic, (t1, t2) in enumerate(itertools.combinations(tokensInWindow,2)):\n",
    "                l1 = t1.lemma_.lower()\n",
    "                l2 = t2.lemma_.lower()\n",
    "                if l1 != l2 and l1 in sufficientNodes and l2 in sufficientNodes:\n",
    "                    label = 'AND'.join(sorted([l1, l2]))\n",
    "\n",
    "                    ### label already found in line?\n",
    "                    repeatedInstance = False\n",
    "                    for line in excerptLines:\n",
    "                        labelFoundFromLine.setdefault((label, line), False)\n",
    "                        if labelFoundFromLine[(label, line)]:\n",
    "                            repeatedInstance = True\n",
    "                        else:\n",
    "                            labelFoundFromLine[(label, line)] = True\n",
    "                    if repeatedInstance:\n",
    "                        continue\n",
    "\n",
    "                    label2authors.setdefault(label, {'Before' : set(), 'After' : set()})\n",
    "                    label2authors[label][period].add(rec['Author'])\n",
    "\n",
    "\n",
    "                    # label2recs.setdefault(label, [])\n",
    "                    # if rec not in label2recs[label]:\n",
    "                    #     label2recs[label].append(rec)\n",
    "\n",
    "                    excerpt = '\\n'.join(excerptLines)\n",
    "                    label2lines.setdefault(label, [])\n",
    "                    if excerpt not in [e['excerpt'] for e in label2lines[label]]:\n",
    "                        # increase link Ct\n",
    "                        for p in ['Before','After']:\n",
    "                            linkCounter[p].setdefault(label, 0)\n",
    "                        linkCounter[period][label] += 1\n",
    "                        allLabels.add(label)\n",
    "\n",
    "                        if pd.isna(period):\n",
    "                            period = ''\n",
    "                        author = rec['Author']\n",
    "                        if pd.isna(author):\n",
    "                            author = 'Unknown'\n",
    "                        label2lines[label].append({\n",
    "                            'excerpt' : excerpt,\n",
    "                            'author' : author,\n",
    "                            'period' : period,\n",
    "                            'uniqueIndex' : rec['UniqueIndex']\n",
    "                        })\n",
    "\n",
    "    node2id = dict()\n",
    "    for i, node in enumerate(sufficientNodes):\n",
    "        networkJson[aff]['nodes'].append({\n",
    "            'id' : node,\n",
    "            'totalinstances' : lemmaCounter[node],\n",
    "            'pos' : nlp(node)[0].pos_\n",
    "        })\n",
    "        node2id[node] = i\n",
    "\n",
    "    for label in allLabels:\n",
    "        source = label.split('AND')[0]\n",
    "        target = label.split('AND')[1]\n",
    "        if lemmaCounter[source] > 9 and lemmaCounter[target] > 9:\n",
    "            label2authors[label]['Before'] = list(label2authors[label]['Before'])\n",
    "            label2authors[label]['After'] = list(label2authors[label]['After'])\n",
    "\n",
    "            networkJson[aff]['links'].append({\n",
    "                'source' : node2id[source],\n",
    "                'target' : node2id[target],\n",
    "                'label' : label,\n",
    "                'sourceLemma' : source,\n",
    "                'targetLemma' : target,\n",
    "                'linkCtBefore' : linkCounter['Before'][label],\n",
    "                'linkCtAfter' : linkCounter['After'][label],\n",
    "                'authors' : label2authors[label],\n",
    "            })\n",
    "    print(sorted([l['linkCtAfter'] for l in networkJson[aff]['links']],reverse=True)[:10])\n",
    "    # print(len(networkJson['links']))\n",
    "    # with open(f'../../allLinkData3-3_21.json', 'w') as json_file:\n",
    "    #     json.dump(networkJson, json_file, ensure_ascii = False, indent=4)\n",
    "    # with open(f'../../label2lines_3-21.json', 'w') as json_file:\n",
    "    #     json.dump(label2lines, json_file, ensure_ascii=False, indent=4)\n",
    "    print('wrote the json!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "24fed7d2-8390-4f5b-8fa4-3d2e1443c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # with open(f'../../allLinkData3-3_22.json', 'w') as json_file:\n",
    "    #     json.dump(networkJson, json_file, ensure_ascii = False, indent=4)\n",
    "    # with open(f'../../label2lines_3-22.json', 'w') as json_file:\n",
    "    #     json.dump(label2lines, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73d52542-126e-4e71-a577-df273111fc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "w1, w2 = ('язык','ты')\n",
    "label = 'AND'.join(sorted([w1, w2]))\n",
    "for who in ['all']:\n",
    "    for l in networkJson[who]['links']:\n",
    "        if l['label'] == label:\n",
    "            print(who,l)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b63d9fe4-a59b-442c-80aa-b94b8b079d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Russia {'source': 7588, 'target': 7382, 'label': 'ониANDязык', 'sourceLemma': 'они', 'targetLemma': 'язык', 'linkCtBefore': 4, 'linkCtAfter': 1, 'authors': {'Before': ['Улад Клавкин', 'Игорь Булатовский', 'Андрей Черкасов', 'Екатерина Перченкова'], 'After': ['Юлия Пикалова']}}\n",
    "\n",
    "# Non-Russia {'source': 7588, 'target': 7382, 'label': 'ониANDязык', 'sourceLemma': 'они', 'targetLemma': 'язык', 'linkCtBefore': 0, 'linkCtAfter': 3, 'authors': {'Before': [], 'After': ['Анна Стреминская', 'Таня Скарынкина', 'Вадим Гройсман']}}\n",
    "\n",
    "# Unknown {'source': 7588, 'target': 7382, 'label': 'ониANDязык', 'sourceLemma': 'они', 'targetLemma': 'язык', 'linkCtBefore': 0, 'linkCtAfter': 1, 'authors': {'Before': [], 'After': ['Марина Охримовская']}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d377af3f-b5fe-47aa-b41e-81ce5887bc29",
   "metadata": {},
   "source": [
    "### Connections, translations, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cceca441-2d9b-4f2b-a372-0f4f573a97a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  occur the most with the propns\n",
    "counter = dict()\n",
    "for pn in pns.split('\\n'):\n",
    "    for link in networkJson['links']:\n",
    "        if pn == link['sourceLemma']:\n",
    "            targetWord = link['targetLemma']\n",
    "        elif pn == link['targetLemma']:\n",
    "            targetWord = link['sourceLemma']\n",
    "        else:\n",
    "            targetWord = ''\n",
    "        if targetWord != '':\n",
    "            counter.setdefault(targetWord, 0)\n",
    "            counter[targetWord] += link['linkCtAfter']\n",
    "lst = []\n",
    "for c in counter:\n",
    "    lst.append({'ct' : counter[c], 'word' : c})\n",
    "srted = sorted(lst, key=lambda x: x['ct'],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d225456f-8e40-47d5-a0e3-435326a58ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../averageTSNE/sortedConnections.json', 'w') as json_file:\n",
    "    json.dump(srted, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2baeb160-897d-49d6-8bc3-2b3da16ef9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using United States server backend.\n"
     ]
    }
   ],
   "source": [
    "import translators as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "42676a30-d695-46a8-9fd2-bff219f3cca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bucha'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.google('буча')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b38d995b-55b2-40ed-be64-d1b5fe61afdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 851/851 [20:28<00:00,  1.44s/it]\n"
     ]
    }
   ],
   "source": [
    "translations = dict()\n",
    "for k in tqdm(newdata):\n",
    "    translations[k] = ts.google(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1342a53e-1907-4724-99ed-03bfb89b6418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(851, 851)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newdata), len(translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ff9acc35-7a1f-4de5-b9cd-66be6e4a49a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kherson'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations['херсон']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3c30de51-ff2a-44df-8790-7a29e27ddbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'../averageTSNE/translationsBERT.json', 'w') as json_file:\n",
    "#     json.dump(translations, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a1dae1a7-0624-48bc-b4eb-37f9a3cd9cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'../averageTSNE/lemmaCounter.json', 'w') as json_file:\n",
    "#     json.dump(lemmaCounter, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e2379250-8c15-41b7-a9ed-bc3e54be85b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmaCounter['египет']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45cac06-c397-4abc-aee3-8f5c14694c7f",
   "metadata": {},
   "source": [
    "### Rossiya Budet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d523d4-9ce9-4281-bc94-e9b3c13ff18a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd688f5-1629-4ce3-87c3-0a83d56270f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
