{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4b0a7fa-7794-4640-af80-5a5a645361c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using United States server backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Text': '* * * *\\nЯ сдерживал себя в чистилище, в метро и\\nв хрустальной башне с огненной водой,\\nкогда я умирал — меня держали трое:\\nотец и сын, мятежный дух святой.\\n\\nИ если ты — любовь, побудь со мной немножко,\\nзайди на порнохаб — поставь за всех свечу,\\nя — кофе или чай, собака или кошка,\\nя сдерживал себя, но больше — не хочу.\\n\\nБетховен или бах, чайковский или верди,\\nхранитель белых слов, вершитель черных дел,\\nи не благодари меня за опыт смерти:\\nактёр играл врача и вскоре — заболел.\\n\\nВ чём логика, когда — мы говорим о чуде,\\nзвучит бессвязный свет из флейты золотой,\\nя — память о вине в раздвоенном сосуде,\\nкоторый — переполнен пустотой.\\n\\nЕщё я состою из самых чёрствых крошек —\\nсмахни меня в ладонь, спасая и губя,\\nя мог не воскрешать: детей, собак и кошек,\\nя склеил старый мир и сдерживал себя.\\n\\nСмотрю на пикассо, читаю, бл@дь, неруду,\\nопять мятежный дух витает над толпой:\\nи всякий — устрашись, когда я снова буду —\\nединственным собой, единственным тобой.\\n\\n2021.',\n",
       " 'Author': 'Александр Кабанов',\n",
       " 'Before or after': 'Before',\n",
       " 'Source': 'Personal Telegram',\n",
       " 'Date posted': datetime.datetime(2022, 12, 17, 0, 0),\n",
       " 'UniqueIndex': 800}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import random\n",
    "import json\n",
    "import spacy\n",
    "import translators as ts\n",
    "import scipy\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_excel('../Excel_files/Full_Poem_Dataset_12-17.xlsx')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "records = df.to_dict('records')\n",
    "random.choice(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb322aeb-fb65-4f06-9103-59b03b04f447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Poems</th>\n",
       "      <th>Author</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Identification</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Link to bio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Виген Аракелян</td>\n",
       "      <td>Razdan</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>https://polutona.ru/?show=arakelian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Герман Лукомников</td>\n",
       "      <td>Baku</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>https://ru.wikipedia.org/wiki/%D0%9B%D1%83%D0%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Александр Иличевский</td>\n",
       "      <td>Sumgait</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>https://ru.wikipedia.org/wiki/%D0%98%D0%BB%D0%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Леонид Шваб</td>\n",
       "      <td>Babruysk</td>\n",
       "      <td>Belarus</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>http://www.litkarta.ru/world/israel/persons/sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Ирина Валерина</td>\n",
       "      <td>Babruysk</td>\n",
       "      <td>Belarus</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Poems                Author      City     Country Identification  \\\n",
       "0                3        Виген Аракелян    Razdan     Armenia            N/A   \n",
       "1                1     Герман Лукомников      Baku  Azerbaijan            N/A   \n",
       "2                1  Александр Иличевский   Sumgait  Azerbaijan            N/A   \n",
       "3                7           Леонид Шваб  Babruysk     Belarus            N/A   \n",
       "4                6        Ирина Валерина  Babruysk     Belarus            N/A   \n",
       "\n",
       "  Notes                                        Link to bio  \n",
       "0   N/A                https://polutona.ru/?show=arakelian  \n",
       "1   N/A  https://ru.wikipedia.org/wiki/%D0%9B%D1%83%D0%...  \n",
       "2   N/A  https://ru.wikipedia.org/wiki/%D0%98%D0%BB%D0%...  \n",
       "3   N/A  http://www.litkarta.ru/world/israel/persons/sh...  \n",
       "4   N/A                                                N/A  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authorsDf = pd.read_excel('../Excel_files/Thesis Authors.xlsx')\n",
    "authorsDf = authorsDf.fillna('N/A')\n",
    "aRecs = authorsDf.to_dict('records')\n",
    "authorDict = dict()\n",
    "for a in aRecs:\n",
    "    authorDict[a['Author']] = a\n",
    "authorsDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a62a1e34-4b53-40f0-9d63-19fd4f27d726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f'Thesis_Authors16.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(aRecs, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5492c2fa-7198-4890-9efb-1caf70067e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "authorsDf.to_json('Thesis_Authors.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eac03a90-c051-4937-8f28-bda0f736a6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Number of Poems': 5,\n",
       " 'Author': 'Игорь Сатановский',\n",
       " 'City': 'Kyiv',\n",
       " 'Country': 'Ukraine',\n",
       " 'Identification': 'N/A',\n",
       " 'Notes': '1969, lived in usa since 1989',\n",
       " 'Link to bio': 'http://www.litkarta.ru/world/usa/persons/satanovsky-i/'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authorDict['Игорь Сатановский']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b6de68b-b94f-4d50-8483-fecfa670186e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'aaaaaasdfsdf'.count('df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "673f98e5-b7e4-41fb-baa1-aa24675cd17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Text': '* * *\\n\\neслибыеслибыеслибыеслибы\\nеслибыеслибыеслепыеслепы\\nеслепыеслепыеслепыеслепы\\nеслепыеслепыеслибыеслибы\\neслибыеслибыеслибыеслибы\\n\\n**Пушкин и война**\\n\\nВойна идёт, а Пушкин пишет \\nВойна идёт, а Пушкин пишет \\nВойна идёт, а Пушкин пишет \\nВойна идёт идёт идёт\\n \\nА Пушкин пишет пишет пишет \\nА Пушкин пишет пишет пишет \\nА Пушкин пишет пишет пишет \\nВойна идёт идёт идёт', 'Author': 'Игорь Сатановский', 'Before or after': 'After', 'Source': 'ROAR V3', 'Date posted': 'None', 'UniqueIndex': 380}\n"
     ]
    }
   ],
   "source": [
    "### Find repetition\n",
    "# for rec in records:\n",
    "#     if rec['Text'].lower().count('война') > 5:\n",
    "#         print(rec['UniqueIndex'])\n",
    "#         print(rec['Text'])\n",
    "#         print()\n",
    "#         print()\n",
    "rec = [r for r in records if r['UniqueIndex'] == 380][0]\n",
    "print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69117285-6db8-4e20-87de-245861ff0d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('textDict.pickle', 'rb') as handle:\n",
    "#     textDict = pickle.load(handle)\n",
    "# textDict['двадцать']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec6f7cb-c0c5-4b15-9450-4f937570b1a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Statistics for Methods section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ba8494c-bccb-4c27-8e57-f767a25c3ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ru_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "478ff900-c9c2-4651-a35f-8415151f8f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3222/3222 [03:44<00:00, 14.35it/s]\n"
     ]
    }
   ],
   "source": [
    "for rec in tqdm(records):\n",
    "    doc = nlp(rec['Text'])\n",
    "    rec['doc'] = doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c619263b-6eb8-410a-8df2-16221df9e5a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 3222/3222 [00:00<00:00, 4979.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Before': 291769, 'After': 266511}\n",
      "{'Before': 1661, 'After': 1561}\n",
      "0 43565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# look at lemma counts\n",
    "tokenCt = dict()\n",
    "poemCt = dict()\n",
    "tokenLemmas = dict()\n",
    "\n",
    "for p in ['Before','After']:\n",
    "    tokenCt.setdefault(p, 0)\n",
    "    poemCt.setdefault(p, 0)\n",
    "    tokenLemmas.setdefault(p, set())\n",
    "for rec in tqdm(records):\n",
    "    poemCt[rec['Before or after']] += 1\n",
    "\n",
    "    for t in rec['doc']:\n",
    "        tokenCt[rec['Before or after']] += 1 \n",
    "        tokenLemmas[p].add(t.lemma_)\n",
    "        \n",
    "print(tokenCt)\n",
    "print(poemCt)\n",
    "print(len(tokenLemmas['Before']),len(tokenLemmas['After']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25279c80-4991-460a-858d-ca314ad42816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenLemmas['Before']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "361c4fe1-fa8a-432a-9567-af9d2fce02df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 3222/3222 [00:01<00:00, 3187.59it/s]\n"
     ]
    }
   ],
   "source": [
    "### Tense breakdown each time period\n",
    "tenseDict = {'Before' : dict(), 'After' : dict()}\n",
    "for p in tenseDict:\n",
    "    for t in ['Past','Pres','Fut']:\n",
    "        tenseDict[p][t] = 0\n",
    "for r in tqdm(records):\n",
    "    p = r['Before or after']\n",
    "    for t in r['doc']:\n",
    "        if t.pos_ == 'VERB' and 'Tense' in t.morph.to_dict():\n",
    "            tense = t.morph.to_dict()['Tense']\n",
    "            m = t.morph\n",
    "            tenseDict[p].setdefault(tense, 0)\n",
    "            tenseDict[p][tense]+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ca2b6f03-924f-4440-a488-6398f3ee98d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "Past 0.4044048395276389\n",
      "Pres 0.5074983699195827\n",
      "Fut 0.08809679055277839\n",
      "\n",
      "After\n",
      "Past 0.4118027224623339\n",
      "Pres 0.48103566668013087\n",
      "Fut 0.10716161085753524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p in tenseDict:\n",
    "    print(p)\n",
    "    for t in tenseDict[p]:\n",
    "        print(t,tenseDict[p][t]/(tenseDict[p]['Past']+tenseDict[p]['Pres']+tenseDict[p]['Fut']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f5ad799f-8393-45da-b0ab-64a889b46c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=6.0487816625211215, pvalue=1.4693138352414718e-09)\n"
     ]
    }
   ],
   "source": [
    "a1 = tenseDict['Before']['Pres']*[1]+ tenseDict[\"Before\"]['Past']*[0] + tenseDict['Before']['Fut']*[0]\n",
    "a2 = tenseDict['After']['Pres']*[1]+ tenseDict[\"After\"]['Past']*[0] + tenseDict['After']['Fut']*[0]\n",
    "test = scipy.stats.ttest_ind(a1, a2, axis=0, equal_var=True, nan_policy='propagate', \n",
    "                          permutations=None, random_state=None, alternative='two-sided', trim=0)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5d282d3b-7744-4da7-83b3-946702c60fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fut : Ttest_indResult(statistic=-7.359306571050845, pvalue=1.8756963438929145e-13)\n",
    "# Pres: Ttest_indResult(statistic=6.0487816625211215, pvalue=1.4693138352414718e-09)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10e46f8-10d4-4663-a55e-75b5db55542a",
   "metadata": {},
   "source": [
    "#### Calculating two sample one sided t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc15ac32-9d2f-47a5-9583-919907bddab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 3222/3222 [00:03<00:00, 1003.07it/s]\n",
      "100%|███████████████████████████████████████| 3222/3222 [00:55<00:00, 58.27it/s]\n"
     ]
    }
   ],
   "source": [
    "textDict = dict()\n",
    "lemmaCts = dict()\n",
    "totalPoemCts = dict()\n",
    "scipyArray = dict()\n",
    "countryBreakdowns = dict()\n",
    "\n",
    "for r in tqdm(records):\n",
    "    p = r['Before or after']\n",
    "    totalPoemCts.setdefault(p, 0)\n",
    "    lemmasFound = set()\n",
    "    totalPoemCts[p] += 1\n",
    "    for t in r['doc']:\n",
    "        if t.lemma_ not in lemmasFound:\n",
    "            # lemmaCts.setdefault(t.lemma_, {'Before' : 0, 'After' : 0})\n",
    "            lemmaCts.setdefault(t.lemma_, {'Before' : 0, 'After' : 0, 'nlpToken' : t})\n",
    "            lemmaCts[t.lemma_][p] += 1\n",
    "            \n",
    "            textDict.setdefault(t.lemma_, {'Before' : [], 'After' : []})\n",
    "            textDict[t.lemma_][p].append({'ID' : r['UniqueIndex'], 'tokenText' : t.text})\n",
    "            \n",
    "            countryBreakdowns.setdefault(t.lemma_, {'Before' : dict(), 'After' : dict()})\n",
    "            try:\n",
    "                country = authorDict[r['Author']]['Country']\n",
    "            except:\n",
    "                country = 'Unknown'\n",
    "            if pd.isna(country):\n",
    "                country = 'Unknown'\n",
    "                \n",
    "            countryBreakdowns[t.lemma_][p].setdefault(country, 0)\n",
    "            countryBreakdowns[t.lemma_][p][country] += 1\n",
    "            \n",
    "            lemmasFound.add(t.lemma_)\n",
    "        else:\n",
    "            continue\n",
    "lemmaFreqs = dict()\n",
    "for word in lemmaCts:\n",
    "    lemmaFreqs.setdefault(word, {'Before' : 0, 'After' : 0})\n",
    "    for p in ['Before','After']:\n",
    "        lemmaFreqs[word][p] = lemmaCts[word][p]/totalPoemCts[p]\n",
    "        lemmaFreqs[word][p+'Ct'] = lemmaCts[word][p]\n",
    "        lemmaFreqs[word]['nlp'] = lemmaCts[word]['nlpToken']\n",
    "        \n",
    "# create arrays for scipy\n",
    "scipyArray = dict()\n",
    "for lem in lemmaCts:\n",
    "    scipyArray.setdefault(lem, {'Before' : [], 'After' : []})\n",
    "\n",
    "for r in tqdm(records):\n",
    "    p = r['Before or after']\n",
    "    recLemmas = set([t.lemma_ for t in r['doc']])\n",
    "    for rl in recLemmas:\n",
    "        scipyArray[rl][p].append(1)\n",
    "    for lem in lemmaCts:\n",
    "        if lem not in recLemmas:\n",
    "            scipyArray[lem][p].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "deecf977-8c33-4238-8023-3e1b84f70736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 43565/43565 [00:00<00:00, 199301.13it/s]\n"
     ]
    }
   ],
   "source": [
    "for l in tqdm(lemmaFreqs):\n",
    "    for p in ['Before','After']:\n",
    "        lemmaFreqs[l]['countryInfo'] = countryBreakdowns[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0b5d1d3-1b6f-4b64-917c-abe1a476b460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Before': 0.059000602046959665,\n",
       " 'After': 0.29276105060858426,\n",
       " 'BeforeCt': 98,\n",
       " 'nlp': война,\n",
       " 'AfterCt': 457,\n",
       " 'countryInfo': {'Before': {'Ukraine': 22,\n",
       "   'Russia': 53,\n",
       "   'Kazakhstan': 2,\n",
       "   'Latvia': 1,\n",
       "   'N/A': 9,\n",
       "   'Belarus': 6,\n",
       "   'Moldova': 4,\n",
       "   'Uzbekistan': 1},\n",
       "  'After': {'Russia': 190,\n",
       "   'Ukraine': 126,\n",
       "   'Moldova': 13,\n",
       "   'N/A': 79,\n",
       "   'Lithuania': 2,\n",
       "   'Unknown': 1,\n",
       "   'Belarus': 36,\n",
       "   'Georgia': 2,\n",
       "   'Latvia': 3,\n",
       "   'Kazakhstan': 1,\n",
       "   'Uzbekistan': 4}}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmaFreqs['война']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a995fe8c-b66b-4b3e-998e-fe5f99053bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('textDict.pickle', 'wb') as handle:\n",
    "#     pickle.dump(textDict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b9da5a7-8124-4e7f-9ae2-0ecfe3b35527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 43565/43565 [00:02<00:00, 17848.52it/s]\n"
     ]
    }
   ],
   "source": [
    "jsonData = []\n",
    "theselemmas = set()\n",
    "for keyword in tqdm(lemmaCts):\n",
    "    if lemmaCts[keyword]['Before'] + lemmaCts[keyword]['After'] >= 25:\n",
    "        theselemmas.add(keyword)\n",
    "        a1 = scipyArray[keyword]['Before']\n",
    "        a2 = scipyArray[keyword]['After']\n",
    "        test = scipy.stats.ttest_ind(a1, a2, axis=0, equal_var=True, nan_policy='propagate', \n",
    "                              permutations=None, random_state=None, alternative='two-sided', trim=0)\n",
    "        lemmaFreqs[keyword]['stats'] = {'statistic' : test.statistic, 'pvalue' : test.pvalue}\n",
    "        jsonData.append({\n",
    "            'keyword' : keyword,\n",
    "            'info' : lemmaFreqs[keyword]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93397c59-763e-44ce-8b75-0806a395aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'frequencyData2-3_1.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(jsonData, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846d8d60-3eff-4653-b67d-e4ea9880956e",
   "metadata": {},
   "source": [
    "#### Significant word breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "893042ed-a326-48f5-9670-95456e8dc523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1626 421\n"
     ]
    }
   ],
   "source": [
    "# filter data\n",
    "data = [d for d in jsonData if not d['info']['Before']*d['info']['After']==0 ]\n",
    "data = [d for d in data if d['info']['stats']['pvalue'] < .05]\n",
    "data = [d for d in data if d['keyword'].isalpha()]\n",
    "irrelevantWords = ['авторский', 'блог', 'личный', 'источник','автор']\n",
    "data = [d for d in data if d['keyword'] not in irrelevantWords]\n",
    "print(len(jsonData), len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "963187bd-2877-4937-85ac-b5583164f253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemsForPCA = [d['keyword'] for d in data]\n",
    "len(lemsForPCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a8de114-cb60-4d54-93d4-cd36388613f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('word4map.txt', 'w') as f:\n",
    "#     f.write('\\n'.join(lemsForPCA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4fab126-9602-4b94-984f-7545d663c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "posDict = {'increase' : dict(), 'decrease' : dict()}\n",
    "for d in data:\n",
    "    which = ''\n",
    "    if d['info']['After'] - d['info']['Before'] > 0:\n",
    "        which = 'increase'\n",
    "    else:\n",
    "        which = 'decrease'\n",
    "    pos = d['info']['nlp'].pos_\n",
    "    posDict[which].setdefault(pos, [])\n",
    "    posDict[which][pos].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "241a0a4a-fb2a-492d-a1e2-b3c79cced1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADJ',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'AUX',\n",
       " 'CCONJ',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'NUM',\n",
       " 'PART',\n",
       " 'PRON',\n",
       " 'PROPN',\n",
       " 'SCONJ',\n",
       " 'VERB']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([p for p in set(list(posDict['increase'].keys()) + list(posDict['decrease'].keys()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fd0edf06-efdb-4892-a140-662b7784162b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "мир\n",
      "эпоха\n",
      "год\n",
      "кровь\n",
      "сын\n",
      "надежда\n",
      "век\n",
      "взрыв\n",
      "город\n",
      "страна\n",
      "ад\n",
      "ужас\n",
      "ребёнок\n",
      "слава\n",
      "список\n",
      "беда\n",
      "народ\n",
      "день\n",
      "смерть\n",
      "войско\n",
      "пепел\n",
      "выстрел\n",
      "приказ\n",
      "бог\n",
      "дом\n",
      "карта\n",
      "зло\n",
      "весна\n",
      "сотня\n",
      "страх\n",
      "вина\n",
      "герой\n",
      "солдат\n",
      "буква\n",
      "пуля\n",
      "подвал\n",
      "война\n",
      "ложь\n",
      "молитва\n",
      "совесть\n",
      "град\n",
      "осколок\n",
      "ракета\n",
      "танк\n",
      "мозг\n",
      "стыд\n",
      "февраль\n",
      "вера\n",
      "цель\n",
      "март\n",
      "корабль\n",
      "туча\n",
      "бой\n",
      "чёрт\n",
      "труп\n",
      "металл\n",
      "добро\n",
      "победа\n",
      "честь\n",
      "стон\n",
      "оружие\n",
      "крест\n",
      "ров\n",
      "новость\n",
      "марш\n",
      "строй\n",
      "враг\n",
      "колонна\n",
      "боль\n",
      "фронт\n",
      "вой\n",
      "слёзы\n",
      "село\n",
      "мрак\n",
      "сирена\n",
      "убийца\n",
      "самолёт\n",
      "рана\n",
      "армия\n",
      "ненависть\n",
      "крик\n",
      "обломок\n",
      "руина\n",
      "бомба\n",
      "очередь\n",
      "снаряд\n",
      "фотография\n",
      "днём\n",
      "лента\n",
      "железо\n",
      "действие\n",
      "парад\n",
      "сейчас\n",
      "теперь\n",
      "вперёд\n",
      "скоро\n",
      "также\n",
      "нынче\n",
      "ваш\n",
      "наш\n",
      "злой\n",
      "чужой\n",
      "страшный\n",
      "военный\n",
      "божий\n",
      "вечный\n",
      "русский\n",
      "виноватый\n",
      "российский\n",
      "родный\n",
      "святой\n",
      "ядерный\n",
      "весенний\n",
      "мирный\n",
      "кровавый\n",
      "безумный\n",
      "мировой\n",
      "убивать\n",
      "нет\n",
      "писать\n",
      "разрушить\n",
      "воевать\n",
      "прийти\n",
      "начаться\n",
      "убить\n",
      "идти\n",
      "выжить\n",
      "орать\n",
      "взять\n",
      "надеяться\n",
      "закончиться\n",
      "молиться\n",
      "ползти\n",
      "выть\n",
      "рыдать\n",
      "плакать\n",
      "спасти\n",
      "победить\n",
      "погибнуть\n",
      "кричать\n",
      "стрелять\n",
      "ненавидеть\n",
      "отправить\n",
      "суметь\n",
      "бомбить\n",
      "мешать\n",
      "прощать\n",
      "послать\n",
      "разорвать\n",
      "рваться\n",
      "ж\n",
      "разве\n",
      "ведь\n",
      "будет\n",
      "будут\n",
      "будем\n",
      "им\n",
      "нам\n",
      "вас\n",
      "вы\n",
      "вам\n",
      "всем\n",
      "ль\n",
      "мать\n",
      "украина\n",
      "россия\n",
      "господи\n",
      "мариуполь\n",
      "харьков\n",
      "родина\n",
      "киев\n",
      "запад\n",
      "одесса\n",
      "путин\n",
      "пред\n",
      "про\n",
      "против\n",
      "сто\n",
      "двадцать\n"
     ]
    }
   ],
   "source": [
    "for pos in posDict['increase']:\n",
    "    for n in posDict['increase'][pos]:\n",
    "        print(n['keyword'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c55a89-8393-48cf-aaa1-73ae1f28e782",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1cea1aa9-97b2-4f94-9c1a-965c763b3768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os.path\n",
    "\n",
    "from django.conf import settings\n",
    "\n",
    "from navec import Navec\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "\n",
    "NAVEC_PATH = \"data4notebooks/navec_hudlit_v1_12B_500K_300d_100q.tar\"\n",
    "# ANNOY_INDEX_PATH = os.path.join(settings.ROOT_DIR, \"parser_tool\", \"data\", \"ANNOY_tree.ann\")\n",
    "\n",
    "navec = Navec.load(NAVEC_PATH)\n",
    "vocabulary = navec.vocab.words\n",
    "word_to_index = dict()\n",
    "for i, word in enumerate(vocabulary):\n",
    "    word_to_index[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b11e26de-4885-4a7f-8da2-7f004d2fd9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD JSON WITH AVERAGE VALS\n",
    "with open(f'../../files2big/beforeandafter768D0', 'r', encoding='utf-8') as f:\n",
    "    jsonVecs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ef386daf-336f-452c-9599-5a9d945e9323",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = dict()\n",
    "for v in jsonVecs:\n",
    "    if 'Average' in v['word']:\n",
    "        word2vec[v['word'].replace('_Average','')] = v['vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1b443857-c2da-417e-ae28-2f45ccb2c0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOUN'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(word)[0].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae4348b5-bb67-4d08-8202-eead152f272f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 92/92 [01:30<00:00,  1.01it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:04<00:00,  1.25it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:01<00:00,  1.04it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:16<00:00,  1.03it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:30<00:00,  1.07it/s]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:03<00:00,  1.31s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:02<00:00,  1.25it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:05<00:00,  1.20it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:09<00:00,  1.13it/s]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:02<00:00,  1.11it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.04s/it]\n",
      "100%|█████████████████████████████████████████| 102/102 [01:33<00:00,  1.09it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:16<00:00,  1.01it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:01<00:00,  1.43it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:01<00:00,  1.15it/s]\n",
      "100%|███████████████████████████████████████████| 45/45 [00:44<00:00,  1.02it/s]\n",
      "100%|███████████████████████████████████████████| 40/40 [00:37<00:00,  1.05it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:01<00:00,  1.27it/s]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:15<00:00,  1.05it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:04<00:00,  1.41it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.69s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:04<00:00,  1.52s/it]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.24s/it]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "vecDict = dict()\n",
    "for direction in posDict:\n",
    "    vecDict.setdefault(direction, dict())\n",
    "    for pos in posDict[direction]:\n",
    "        vecDict[direction].setdefault(pos, [])\n",
    "        keywords = [d['keyword'] for d in posDict[direction][pos]]\n",
    "        for word in tqdm(keywords):\n",
    "            try:\n",
    "                navector = navec[word].tolist()\n",
    "            except:\n",
    "                print('not in navec dictionary')\n",
    "                navector = np.zeros(300).tolist()\n",
    "            vecDict[direction][pos].append({\n",
    "                \"word\" : word,\n",
    "                \"translatedword\" : ts.google(word),\n",
    "                \"bertvector\" : word2vec[word],\n",
    "                'navecvector' : navector,\n",
    "                'countryInfo' : countryBreakdowns[word]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4481858e-3bc6-4274-89fb-a076dfce93fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a6428ae3-08cb-475d-b803-0596fdb222b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../significantPCA/sigMeanDiffVecsTranslated4.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(vecDict, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1f7d1a-0520-48ba-ad58-0baaa14958f0",
   "metadata": {},
   "source": [
    "## Synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c236b897-c785-4776-a097-260366e5b425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading a ruwordnet model from https://github.com/avidale/python-ruwordnet/releases/download/0.0.4/ruwordnet-2021.db\n"
     ]
    }
   ],
   "source": [
    "!ruwordnet download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f69e8feb-3435-4df0-805f-98311e05b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ruwordnet import RuWordNet\n",
    "wn = RuWordNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92a775f1-b44a-4ebc-9482-34f6cc60a712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вселенная, мироздание, мир\n",
      "сообщество (совокупность людей)\n",
      "мир, отсутствие конфликтов\n",
      "мир, отсутствие войны\n"
     ]
    }
   ],
   "source": [
    "lemma = 'мир'\n",
    "for sense in wn.get_senses(lemma):\n",
    "    print(sense.synset.title.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b03ed04-7e97-4c3a-8632-4d0346c7355e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jj/_szc94p56q91q_7c209d1d9w0000gn/T/ipykernel_37206/3289863467.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscipyArray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Before or after'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtotalPoemCts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "lemmaCts = dict()\n",
    "totalPoemCts = dict()\n",
    "scipyArray = dict()\n",
    "sense2lemmas = dict()\n",
    "\n",
    "for r in tqdm(records):\n",
    "    p = r['Before or after']\n",
    "    totalPoemCts.setdefault(p, 0)\n",
    "    lemmasFound = set()\n",
    "    totalPoemCts[p] += 1\n",
    "    for t in r['doc']:\n",
    "        if t.lemma_ not in lemmasFound:\n",
    "            for sense in wn.get_senses(t.lemma_):\n",
    "                title = sense.synset.title.lower()\n",
    "                sense2lemmas.setdefault(sense, set())\n",
    "                sense2lemmas[sense].add(t.lemma_)\n",
    "                lemmaCts.setdefault(title, {'Before' : 0, 'After' : 0})\n",
    "                lemmaCts[title][p] += 1\n",
    "            lemmasFound.add(t.lemma_)\n",
    "        else:\n",
    "            continue\n",
    "lemmaFreqs = dict()\n",
    "for word in lemmaCts:\n",
    "    lemmaFreqs.setdefault(word, {'Before' : 0, 'After' : 0})\n",
    "    for p in lemmaCts[word]:\n",
    "        lemmaFreqs[word][p] = lemmaCts[word][p]/totalPoemCts[p]\n",
    "        lemmaFreqs[word][p+'Ct'] = lemmaCts[word][p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321d3059-5609-4daf-9921-e93a51e69fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # check if title already added\n",
    "    title = synset.title\n",
    "    # change synset label to lemma label if only one lemma mentioned\n",
    "    if len(synsetTokens[synset]) == 1:\n",
    "        title = list(synsetTokens[synset].keys())[0]\n",
    "        \n",
    "    # if title already added, skip entry, else continue\n",
    "    if title in titleAddedAlready:\n",
    "        print('OLD:',title, synset.title)\n",
    "        print('NEW:',title, lemma2synset[title])\n",
    "        continue\n",
    "    else:\n",
    "        lemma2synset[title] = synset.title\n",
    "        titleAddedAlready.add(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf879051-5847-438d-a466-f2af261db046",
   "metadata": {},
   "source": [
    "#### Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edb75491-056f-43e8-a145-664f3fbd5f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install spacy-language-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "884388b5-1ebe-4511-8702-9edc84ee6575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "\n",
    "from spacy_language_detection import LanguageDetector\n",
    "\n",
    "\n",
    "def get_lang_detector(nlp, name):\n",
    "    return LanguageDetector(seed=42)  # We use the seed 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "272c3975-501c-4392-b081-d04994c26dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is English text. {'language': 'en', 'score': 0.9999987929307774}\n",
      "Er lebt mit seinen Eltern und seiner Schwester in Berlin. {'language': 'de', 'score': 0.999996045846908}\n",
      "Yo me divierto todos los días en el parque. {'language': 'es', 'score': 0.9999960751128256}\n",
      "Je m'appelle Angélica Summer, j'ai 12 ans et je suis canadienne. {'language': 'fr', 'score': 0.9999960488878062}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlp_model = spacy.load(\"ru_core_news_lg\")\n",
    "Language.factory(\"language_detector\", func=get_lang_detector)\n",
    "nlp_model.add_pipe('language_detector', last=True)\n",
    "\n",
    "# Sentence level language detection\n",
    "text = \"This is English text. Er lebt mit seinen Eltern und seiner Schwester in Berlin. Yo me divierto todos los días en el parque. Je m'appelle Angélica Summer, j'ai 12 ans et je suis canadienne.\"\n",
    "doc = nlp_model(text)\n",
    "for i, sent in enumerate(doc.sents):\n",
    "    print(sent, sent._.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c1f7ef-df29-4312-93b6-a0dcf643fb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3252/3252 [05:13<00:00, 10.36it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "random.shuffle(records)\n",
    "for rec in tqdm(records):\n",
    "    rec['Doc'] = nlp_model(rec['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1e528cc4-6006-4c68-b988-686bd6284d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3252/3252 [07:47<00:00,  6.96it/s]\n"
     ]
    }
   ],
   "source": [
    "langDict = dict()\n",
    "for rec in tqdm(records):\n",
    "    for sent in rec['Doc'].sents:\n",
    "        langDict.setdefault(sent._.language['language'], [])\n",
    "        langDict[sent._.language['language']].append((sent, rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b5433fd8-683d-45c8-ad1e-4fe98799425a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ru', 'UNKNOWN', 'bg', 'mk', 'uk', 'en', 'et', 'hr', 'tl', 'ro', 'lt', 'de', 'id', 'ca', 'sk'])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "83050af3-a197-497e-96ce-daa71020c7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Unique index: 1652 \n",
      " Како добро живети…\n",
      "…Ako žiť dobre…\n",
      "…Kako dobro živeti. \n",
      "--\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = 'sk'\n",
    "print(len(langDict[lg]))\n",
    "[print('Unique index:',d[1]['UniqueIndex'],'\\n', d[0],'\\n--') for d in random.sample(langDict[lg],1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fb4c074a-563a-4e41-8cab-5f5efe8d05b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 523\n",
    "r = [r for r in records if r['UniqueIndex'] == 3239][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e200825a-0ec6-4e29-8e79-95615c954c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('essentialpoetry', 'Линор Горалик', datetime.datetime(2018, 5, 9, 0, 0))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['Source'], r['Author'], r['Date posted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c3b2e6f1-ad1d-4d9b-a8c4-c947b8e96022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вот красным лесом красная лиса, – \n",
      "а он лежит, смешавшись с автоматом, \n",
      "в осеннем красном буром чернозёме, \n",
      "неглубоко, – \n",
      "и вот лиса несётся, \n",
      "пересекая сердце, горло, сердце, – \n",
      "подскакивает, лапой влезши в душу, \n",
      "отряхивает лапу, мчится дальше, – \n",
      "И он кричит распавшейся гортанью: \n",
      " \n",
      "КАКОГО ХУЯ, ГОСПОДИ, – ЗА ЧТО?! \n",
      " \n",
      "Я не успел – я инвалид по зренью, – \n",
      "я не успел, – они меня в апреле, \n",
      "когда уже исход и всё понятно, \n",
      "когда таких, как я, – едва одетых, \n",
      "полуслепых, хромых или безусых, – \n",
      "от киндер, кирхе, запаха из кюхен, – \n",
      "в зелёный их апрельский красный лес, \n",
      "где я от крови ничего не видел, \n",
      "и красный зверь, и горло, сердце, горло – \n",
      "а я ни разу даже не пальнул, \n",
      "я не успел – \n",
      "какого хуя, Боже?! \n",
      " \n",
      "ТАК ДАЙ МНЕ, ДАЙ МНЕ, ДАЙ МНЕ ЧТО-НИБУДЬ!!! \n",
      " \n",
      "И тут лиса упала и лежит.\n"
     ]
    }
   ],
   "source": [
    "print(r['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "82fe5a12-30ce-49a7-afec-f10006a906c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c45ad1-eab7-47f0-ab50-bbce7c6ef8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342235"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "for rec in records:\n",
    "    total += len(str(rec['Text']).split(' '))\n",
    "# 345043\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59684869-7272-46f4-9bd3-9ffb0bc61a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "essentialpoetry      945\n",
       "No War Poetry        724\n",
       "metajournal          662\n",
       "ROAR V3              350\n",
       "Facebook             253\n",
       "ROAR V2              234\n",
       "Personal Telegram     54\n",
       "Name: Source, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "502f5129-2b51-4d5c-891e-464349b9151f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Before    1661\n",
       "After     1561\n",
       "Name: Before or after, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Before or after'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d17f1d-0be3-4ec0-9139-77b515159b64",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Remove duplicates from corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "889570ec-6a8e-442f-973d-e049b3705224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Развивая Бродского\n",
      "1\n",
      "Я хотел бы жить, Иосиф, как можно дольше, пока\n",
      "ритмично дыханье и тянется на бумаге строка,\n",
      "жизнь - гостиный двор, мы временные постояльцы,\n",
      "и какое мне дело до того городка,\n",
      "где и\n"
     ]
    }
   ],
   "source": [
    "print(random.choice(records)['Text'][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "55a779f7-c1ca-40a8-9bc6-8b49a281df61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3502it [00:08, 406.86it/s] \n"
     ]
    }
   ],
   "source": [
    "longStringCts = dict()\n",
    "string2Recs = dict()\n",
    "string2RecIdx = dict()\n",
    "\n",
    "windowSize = 100\n",
    "for i, rec in tqdm(enumerate(records)):\n",
    "    text = rec['Text']\n",
    "    rec['UniqueIndex'] = i\n",
    "    if isinstance(text, str):\n",
    "        for j in range(len(text)-windowSize):\n",
    "            windowText = text[j:j+windowSize]\n",
    "            longStringCts.setdefault(windowText, 0)\n",
    "            longStringCts[windowText] += 1\n",
    "            string2Recs.setdefault(windowText, [])\n",
    "            string2Recs[windowText].append(rec)\n",
    "            # string2RecIdx.setdefault(windowText, set())\n",
    "            # string2RecIdx[windowText].add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5eab9b6f-d205-4ed6-9065-bebc1495077e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 2284719/2284719 [00:01<00:00, 1186974.80it/s]\n"
     ]
    }
   ],
   "source": [
    "relevantCts = dict()\n",
    "for s in tqdm(longStringCts):\n",
    "    if longStringCts[s] > 1:\n",
    "        relevantCts[s] = longStringCts[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ba4a1fb8-ce5a-4e8d-935b-f6a2a8a24a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 64074/64074 [00:00<00:00, 133374.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "228"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlappingRecs = []\n",
    "for s in tqdm(relevantCts):\n",
    "    shareString = string2Recs[s]\n",
    "    if shareString not in overlappingRecs:\n",
    "        # ids = [r['UniqueIndex'] for r in shareString]\n",
    "        # if set(ids) \n",
    "        overlappingRecs.append(shareString)\n",
    "len(overlappingRecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4c84ec3a-910c-4f17-bf2f-c646f8b04368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "6f9bfe16-d370-4ab1-a9c1-2bd294941f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decideRec(recList):\n",
    "    # if just one, return rec\n",
    "    if len(recList) == 1:\n",
    "        return recList[0:]\n",
    "    # convert to datetimes\n",
    "    for r in recList:\n",
    "        if not isinstance(r['Date posted'], datetime.datetime):\n",
    "            # essentialpoetry      1023\n",
    "            # No War Poetry         793\n",
    "            # metajournal           713\n",
    "            # ROAR V3               357\n",
    "            # Facebook              281\n",
    "            # ROAR V2               269\n",
    "            # Personal Telegram      66\n",
    "            if r['Source'] == 'ROAR V2':\n",
    "                r['Date posted'] = datetime.datetime(2022, 6, 24, 0, 0)\n",
    "            elif r['Source'] == 'ROAR V3':\n",
    "                r['Date posted'] = datetime.datetime(2022, 8, 24, 0, 0)\n",
    "            else:\n",
    "                r['Date posted'] = datetime.datetime(2022,12,17,0,0)\n",
    "    # compare date\n",
    "    sortedByDate = []\n",
    "    for i, rec in enumerate(recList):\n",
    "        sortedByDate.append((rec['Date posted'], i))\n",
    "    sortedByDate = sorted(sortedByDate)\n",
    "    # check types\n",
    "    if isinstance(sortedByDate[0], datetime.datetime) and isinstance(sortedByDate[1], datetime.datetime):\n",
    "        if sortedByDate[0] != sortedByDate[1]:\n",
    "            return recList[sortedByDate[0][1]]\n",
    "    else:\n",
    "        idxs = [s[1] for s in sortedByDate[1:]]\n",
    "        return [recList[j] for j in idxs]\n",
    "    \n",
    "    # compare length of text\n",
    "    sortedByLen = []\n",
    "    for i, rec in enumerate(recList):\n",
    "        sortedByLen.append((len(rec['Text']), i))\n",
    "    sortedByLen = sorted(sortedByLen)\n",
    "    idxs = [s[1] for s in sortedByLen[1:]]\n",
    "    return [recList[j] for j in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "696a8941-6cda-4d23-ada2-d4de67de61de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Text': '\\nРевёт жена опальная,\\nв правах поражена.\\nИдёт война двуспальная,\\nгражданская война.\\nПомыты кухня, ванная\\nслезами в три ручья.\\nИдёт война диванная,\\nтрещит по швам семья.\\n+\\nБудущему малышу,\\nптицам небесным пища?\\nСижу в уголке, пишу\\nугольком пепелища\\nродного. Роднее нет.\\nМай. Четвёртое мая.\\nВ окне кабинета свет:\\nне выключила, убегая.\\n+\\nВсе страны, кроме одной.\\nЧто же мы так бездомны?\\nВстречаемся, мой родной,\\nоколо пятой колонны\\nбольшого театра войны —\\nв Эривани, в Тифлисе,\\nкак рыбе зонтик нужны\\nмировой закулисе.\\n+\\nОт грохота, скрежета, лязга\\nсжимается матка.\\nКачает пустую коляску.\\nЦе хлопчик? Дiвчатко.\\nПоёт колыбельную дочке.\\nПечаль непроглядна.\\nВойна. Молока на сорочке\\nрасплывающиеся пятна.\\n+\\nСвидетельств — терабайт,\\nкак мой народ ушёл\\nв искусственный офсайд.\\nНо засчитали гол\\nи торжествует зло,\\nи стадион орёт.\\nМне очень повезло\\nуспеть на самолёт.\\n+\\nМеждународный язык —\\nмладенческий лепет.\\nСпит у груди призывник\\nГолгофы. Колеблет\\nвоздух взрывная волна.\\nПротивник не выбит.\\nПуть отрезает война\\nдля бегства в Египет.\\n+\\nНе говори: я стреляю мимо.\\nПуля не дура — летит до конца.\\nВыстрелишь в небо — убьёшь херувима.\\nВыстрелишь в землю — убьёшь мертвеца.\\nПтицу. Крота. Стрекозу. Полёвку.\\nПуля не дура — найдёт себе цель.\\nНе слушай комбата — бросай винтовку.\\nПослушайся маму — забейся в щель.\\n+\\nПросыпаешься — война.\\nДа какой тут сон,\\nесли спальня спалена,\\nесли дом сожжён,\\nесли город стал золой,\\nпеплом — стар и млад,\\nесли не смолкает бой\\nи творится ад.\\n+\\nЛевый плачет об одном,\\nправый — о другом.\\nЛевый: взорван детский дом.\\nПравый: где мой дом?\\nНе кори слезу, слеза.\\nКолокольный звон,\\nнаучи мои глаза\\nплакать в унисон.\\n+\\nСпросит внучка, спросит внук:\\nКак ты воевала?\\nЯ полку друзей-подруг\\nплакать помогала.\\nСпросит кто-нибудь из них:\\nКак ты победила?\\nЯ любимых-дорогих\\nимена твердила.\\n+\\nапофеоз войны\\nсажи золы бурьяна\\nвсе до одной черны\\nклавиши фортепьяно\\nбудем играть на нём\\nразмазывая копоть\\nпод проливным огнем\\nв чьей-то крови по локоть\\n+\\nтрам-там-там\\nтрам-там-там\\nмаменькин сынок\\nпомещён по частям\\nв мусорный мешок\\nмина взрыв\\nмина взрыв\\nиз отчёта стёрт\\nГосударству — призыв,\\nродине — аборт.\\n+\\nсветомаскировка\\nночи звёздный час\\nприлегла винтовка\\nприкорнул фугас\\nа когда проснутся\\nпо команде пли\\nзвёзды отвернутся\\nот моей Земли\\n+\\nДело мое дрянь.\\nСделана сказка пылью.\\nПлáчу — плачу дань\\nгневу, стыду, бессилью.\\nСилой берут дев,\\n“Мурку” орут орки.\\nТы близорук, гнев.\\nСлёзы, вы дальнозорки.\\n+\\nРадость передышки краткой,\\nшуточки о женской доле\\nпосле схватки, перед схваткой\\nв мариупольском роддоме.\\nСокращайтесь, мышцы матки,\\nвремя дорого: убийца\\nвожделеет — взятки гладки —\\nкровью с молоком упиться.\\n+\\nКто в подвале зачах?\\nКто под землю несёт\\nдевочку на сносях,\\nраненную в живот?\\nКто при свете свечи\\nжизнью должен истечь?\\nВсё, стишок, замолчи.\\nТут кончается речь.\\n+\\nНа фотографии —\\nмаленький мальчик,\\nпод фотографией —\\nплачущий смайлик.\\nЛёгкая лодочка.\\nХраброе бегство.\\nЗоркость наводчика.\\nВечное детство.\\n+\\nДопускать правоту Пилата,\\nпонимать и прощать Иуду\\nне просите меня, не надо, —\\nне хочу, не могу, не буду,\\nпотому что слова-пароли,\\nпотому что отзывы-рифмы\\nтолерантны до первой крови,\\nдо последней непримиримы.\\n+\\nСколько гробов по плечу\\nженскому человеку?\\nПлачу о мёртвых — плачу\\nпожизненную ипотеку,\\nтрачу кап-кап-капитал.\\nМать утешавший “Жено,\\nне плачь”, не Ты ли сказал,\\nчто плачущие блаженны?\\n+\\nНе на митинге, не в неволе,\\nне в убежище, не в бою\\nя беру интервью у боли.\\nГлавный жанр сейчас — интервью.\\nНе под бомбами, не в обозе,\\nне на кладбище, не в строю\\nсокрушительные вопросы\\nя самой себе задаю.\\n+\\nБудем под прицелами плясать\\nна колючей провололке над бездной,\\nбудем русским языком лизать\\nна морозе занавес железный,\\nбудем огороды городить,\\nбудем, позабыв попытку-пытку,\\nв сон, как в самоволку, уходить,\\nв прошлое проситься на побывку.\\n+\\nПеть перестал? Писать перестал?\\nНовости колюще-режущи?\\nПросто представь, что концертный зал\\nэто бомбоубежище,\\nс передовой не звонит жених,\\nнет писем от сына-беженца.\\nПлачущим пой. Пиши о них.\\nИ, может быть, ты утешишься.\\n+\\nТот, Кто один как перст\\nнёс из последних сил\\nсобственной смерти крест,\\nкрестика не носил.\\nПлачущую прости.\\nГосподи, стыдно мне,\\nчто ношу на груди\\nто, что Ты — на спине.\\n+\\nСтала душа могилой,\\nкровавым кошмаром явь.\\nМолю тебя, шестикрылый, —\\nдвуглавого обезглавь.\\nНа волоске над бездной\\nвсё, что люблю, чем живу.\\nАрхистратиг небесный,\\nпомоги ВСУ.\\n+\\nДогорают купель и купол.\\nТы не смотришь в глаза беде?\\nУмирающий Мариуполь:\\nБогородица на кресте.\\nПлачут Иоаким и Анна.\\nСын снимает Её с креста.\\nМежду ног — рваная рана.\\nТы не веришь? Вложи перста.\\n+\\nГоворит (привет И. Б.)\\nсыну мать:\\nКрест пылает — как тебе\\nвоскресать?\\nОтвечает: Бог с тобой,\\nаз есмь путь.\\nМне ведь, мама, не впервой.\\nКак-нибудь.\\n+\\nПо мановению войны\\nполутона отменены —\\nполуслова, полудела,\\nполухвала-полухула.\\nРоссия бедная моя,\\nпрости меня за то, что я\\nне понимаю, хоть убей,\\nкак полюбить полулюдей.\\n+\\nСердце, слезами залей\\nпламя пасхальной свечи.\\nКровью убитых детей\\nВраг окропил куличи.\\nАнгелы сбиты с пути.\\nВ колокол бьёт ПВО.\\nНыне Воскресший, прости:\\nдля радости сердце мертво.\\n+\\nЕдинственный твой сынок,\\nзащитник, помощник, друг,\\nс вокзала придёт без ног,\\nобнимет тебя без рук,\\nнаполнит стакан без дна,\\nбез глаз оглядит подвал\\nи скажет: была война,\\nи я её проиграл.',\n",
       " 'Author': 'Вера Павлова',\n",
       " 'Before or after': 'After',\n",
       " 'Source': 'ROAR V2',\n",
       " 'Date posted': datetime.datetime(2022, 6, 24, 0, 0),\n",
       " 'UniqueIndex': 162}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[162]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c5aeccf9-0eae-4426-bd92-a3765ad2f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = dict()\n",
    "for recList in overlappingRecs:\n",
    "    counts.setdefault(len(recList),0)\n",
    "    counts[len(recList)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "417b61ba-8cd1-4615-852f-a154a133f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new list using only the earliest overlapping rec\n",
    "repeatIdxs = set()\n",
    "for recList in overlappingRecs:\n",
    "    badRecs = decideRec(recList)\n",
    "    badIdxs = [b['UniqueIndex'] for b in badRecs]\n",
    "    for b in badIdxs:\n",
    "        repeatIdxs.add(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "2c99d0f0-224b-4088-9f7e-55fa9931d9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3289"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanRecList = []\n",
    "j = 0\n",
    "for i, rec in enumerate(records):\n",
    "    if rec['UniqueIndex'] not in repeatIdxs:\n",
    "        rec['UniqueIndex'] = j\n",
    "        cleanRecList.append(rec)\n",
    "        j += 1\n",
    "len(cleanRecList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c6571dbf-d37e-4495-9973-91d1835f13a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Text': '***\\n \\n– В Москве – невкусная клубника, бери водку!\\n \\nВ вытянутой трубке сна так тихо,\\n \\nЧто можно услышать\\n \\nНеуловимую чёрную лодку.\\n \\nСпрашиваю:\\n \\n– Это каяк?\\n \\nПтица с ветки:\\n \\n– Каяк, каяк. Что с тобою не так?\\n \\n– Со мною не так носовой платок,\\n \\nКаждое слово.\\n \\nНеба бесформенный носорог\\n \\nОживает в половине шестого.\\n \\nНаблюдаю за ним из окна.\\n \\nУ меня проблема только одна:\\n \\n«Скендербеу», «Хабнарфьордюр» и «Нымме Калью» проиграли свои матчи.\\n \\nИ три любимых, но непростых занятья:\\n \\nСмотреть на осину,\\nСмотреть на берёзу,\\nСмотреть на тополь.\\n \\nМошка умерла у меня на глазах,\\nА что пережил ты?\\n \\n \\n(интернет-журнал ”Literratura”)\\n \\n#выбор_Максима_Дрёмова',\n",
       " 'Author': 'Денис Крюков',\n",
       " 'Before or after': 'Before',\n",
       " 'Source': 'metajournal',\n",
       " 'Date posted': datetime.datetime(2019, 11, 14, 0, 0),\n",
       " 'UniqueIndex': 1000}"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanRecList[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "bf33e461-00f8-483a-941d-f7b9e3607865",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanDf = pd.DataFrame.from_records(cleanRecList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "198114d5-d445-4fd1-b273-5a95c35da5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanDf.to_excel('../Excel_files/Full_Poem_Dataset_12-17.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6d8294-349d-45ef-a720-553d4e664b17",
   "metadata": {},
   "source": [
    "## AUTHOR DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8a5d91f-4c23-4bb0-b35e-cf0e38b8dc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Poems</th>\n",
       "      <th>Author</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Identification</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Link to bio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Виген Аракелян</td>\n",
       "      <td>Razdan</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://polutona.ru/?show=arakelian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Герман Лукомников</td>\n",
       "      <td>Baku</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://ru.wikipedia.org/wiki/%D0%9B%D1%83%D0%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Александр Иличевский</td>\n",
       "      <td>Sumgait</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://ru.wikipedia.org/wiki/%D0%98%D0%BB%D0%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Леонид Шваб</td>\n",
       "      <td>Babruysk</td>\n",
       "      <td>Belarus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.litkarta.ru/world/israel/persons/sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Ирина Валерина</td>\n",
       "      <td>Babruysk</td>\n",
       "      <td>Belarus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Poems                Author      City     Country Identification  \\\n",
       "0                3        Виген Аракелян    Razdan     Armenia            NaN   \n",
       "1                1     Герман Лукомников      Baku  Azerbaijan            NaN   \n",
       "2                1  Александр Иличевский   Sumgait  Azerbaijan            NaN   \n",
       "3                7           Леонид Шваб  Babruysk     Belarus            NaN   \n",
       "4                6        Ирина Валерина  Babruysk     Belarus            NaN   \n",
       "\n",
       "  Notes                                        Link to bio  \n",
       "0   NaN                https://polutona.ru/?show=arakelian  \n",
       "1   NaN  https://ru.wikipedia.org/wiki/%D0%9B%D1%83%D0%...  \n",
       "2   NaN  https://ru.wikipedia.org/wiki/%D0%98%D0%BB%D0%...  \n",
       "3   NaN  http://www.litkarta.ru/world/israel/persons/sh...  \n",
       "4   NaN                                                NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authorInfo = pd.read_excel('../Excel_files/Thesis Authors.xlsx')\n",
    "authorInfo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eb797a3-09fe-4f42-8d44-7910d0aa8b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Russia          370\n",
       "Ukraine          86\n",
       "Kazakhstan       26\n",
       "Belarus          16\n",
       "Uzbekistan        6\n",
       "Moldova           5\n",
       "Latvia            5\n",
       "Estonia           4\n",
       "Kyrgyzstan        2\n",
       "Azerbaijan        2\n",
       "Lithuania         1\n",
       "Iran              1\n",
       "Georgia           1\n",
       "Tajikistan        1\n",
       "Turkmenistan      1\n",
       "USA               1\n",
       "Armenia           1\n",
       "Name: Country, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authorInfo['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcc6def-9189-4237-8b09-2a68fdd95d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
