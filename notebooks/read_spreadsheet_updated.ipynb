{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b4b0a7fa-7794-4640-af80-5a5a645361c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Text': 'Перебивали речь, кивали в такт, брались за струны, выходили вон,\\nменялись, оставались на местах — и вечер наступал со всех сторон.\\n \\nДо встречи в среду, ливеньливень рос, промокнешь навсегда, постой идти. \\nДень уплывал как спасшийся матрос — тогда писал я, господи прости\\n \\nИ так как ты была там редкий гость, и олицетворяла свет извне,\\nи рядом с этим днем стоял другой, казалось все осмысленным вполне.\\nИ открываясь, хлопало окно, которое никто не закрывал,\\nпока один — из старого кино — одну смешную песенку играл.\\n \\nИ смерть, не улыбаясь никому, вставала, выходила в темноту,\\nСмеясь, слова ловили на лету, кружась передавали их в дыму.\\n \\nВставали, уходили без зонтов, и на прощанье кто-то говорил —\\n«до встречи» — и не спрашивал никто, куда они — у тех, кто уходил.\\n \\nИ ливень на незаданный вопрос, не отвечал на разные лады.\\nДень уплывал, кончался, как матрос на плотике без пищи и воды.\\n \\nЧерез плечо смотрящий мне в тетрадь: А в чем сюжет, поэт, теряю нить.\\n— Я знаю в чем, но мне не передать. Но я могу начало повторить:\\n \\nПередавали речь, вставали вон, и вечер оставался на местах,\\nи ливень наступал со всех сторон, и на прощанье смерть кивала в такт.',\n",
       " 'Author': 'Андрей Нитченко',\n",
       " 'Before or after': 'Before',\n",
       " 'Source': 'essentialpoetry',\n",
       " 'Date posted': datetime.datetime(2019, 4, 19, 0, 0),\n",
       " 'UniqueIndex': 2960}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import random\n",
    "import json\n",
    "import spacy\n",
    "import translators as ts\n",
    "import scipy\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_excel('../Excel_files/Full_Poem_Dataset_12-17.xlsx')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "records = df.to_dict('records')\n",
    "random.choice(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f960b8b-5343-4458-80a3-3ec7d3c6b905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Before    1661\n",
       "After     1561\n",
       "Name: Before or after, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Before or after'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "07ab5f23-eb6c-4338-9cd5-20e8186bbef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average lines\n",
    "numLines = []\n",
    "theseRecs = []\n",
    "for rec in records:\n",
    "    # lines = rec['Text'].split('\\n')\n",
    "    lines = [t for t in rec['Text'].split('\\n') if t.replace('*','').strip() not in ['','\\t',' ']]\n",
    "    if len(lines) in [2,3]:\n",
    "        theseRecs.append(rec)\n",
    "    numLines.append(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb85f62d-baae-4fa7-b81e-721dd3ce5871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "677"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many authors\n",
    "authorSet = set()\n",
    "for d in records:\n",
    "    authorSet.add(d['Author'])\n",
    "len(authorSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb322aeb-fb65-4f06-9103-59b03b04f447",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Poems</th>\n",
       "      <th>Author</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Identification</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Link to bio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Виген Аракелян</td>\n",
       "      <td>Razdan</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>https://polutona.ru/?show=arakelian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Герман Лукомников</td>\n",
       "      <td>Baku</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>https://ru.wikipedia.org/wiki/%D0%9B%D1%83%D0%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Александр Иличевский</td>\n",
       "      <td>Sumgait</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>https://ru.wikipedia.org/wiki/%D0%98%D0%BB%D0%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Леонид Шваб</td>\n",
       "      <td>Babruysk</td>\n",
       "      <td>Belarus</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>http://www.litkarta.ru/world/israel/persons/sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Ирина Валерина</td>\n",
       "      <td>Babruysk</td>\n",
       "      <td>Belarus</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Poems                Author      City     Country Identification  \\\n",
       "0                3        Виген Аракелян    Razdan     Armenia            N/A   \n",
       "1                1     Герман Лукомников      Baku  Azerbaijan            N/A   \n",
       "2                1  Александр Иличевский   Sumgait  Azerbaijan            N/A   \n",
       "3                7           Леонид Шваб  Babruysk     Belarus            N/A   \n",
       "4                6        Ирина Валерина  Babruysk     Belarus            N/A   \n",
       "\n",
       "  Notes                                        Link to bio  \n",
       "0   N/A                https://polutona.ru/?show=arakelian  \n",
       "1   N/A  https://ru.wikipedia.org/wiki/%D0%9B%D1%83%D0%...  \n",
       "2   N/A  https://ru.wikipedia.org/wiki/%D0%98%D0%BB%D0%...  \n",
       "3   N/A  http://www.litkarta.ru/world/israel/persons/sh...  \n",
       "4   N/A                                                N/A  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authorsDf = pd.read_json('../notebooks/Thesis_Authors16.json')\n",
    "authorsDf = authorsDf.fillna('N/A')\n",
    "aRecs = authorsDf.to_dict('records')\n",
    "authorDict = dict()\n",
    "for a in aRecs:\n",
    "    authorDict[a['Author']] = a\n",
    "authorsDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44266582-2d1d-4f01-9f98-75c8bc291d54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# places = set()\n",
    "# for rec in aRecs:\n",
    "#     if rec['Author'] in authorSet:\n",
    "#         places.add(rec['City']+', '+rec['Country'])\n",
    "#     else:\n",
    "#         print(rec)\n",
    "# for p in sorted(places):\n",
    "#     print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec6f7cb-c0c5-4b15-9450-4f937570b1a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Statistics for Methods section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ba8494c-bccb-4c27-8e57-f767a25c3ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ru_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "478ff900-c9c2-4651-a35f-8415151f8f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 3222/3222 [02:34<00:00, 20.91it/s]\n"
     ]
    }
   ],
   "source": [
    "for rec in tqdm(records):\n",
    "    doc = nlp(rec['Text'])\n",
    "    rec['doc'] = doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c619263b-6eb8-410a-8df2-16221df9e5a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 3222/3222 [00:00<00:00, 4979.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Before': 291769, 'After': 266511}\n",
      "{'Before': 1661, 'After': 1561}\n",
      "0 43565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# look at lemma counts\n",
    "tokenCt = dict()\n",
    "poemCt = dict()\n",
    "tokenLemmas = dict()\n",
    "\n",
    "for p in ['Before','After']:\n",
    "    tokenCt.setdefault(p, 0)\n",
    "    poemCt.setdefault(p, 0)\n",
    "    tokenLemmas.setdefault(p, set())\n",
    "for rec in tqdm(records):\n",
    "    poemCt[rec['Before or after']] += 1\n",
    "\n",
    "    for t in rec['doc']:\n",
    "        tokenCt[rec['Before or after']] += 1 \n",
    "        tokenLemmas[p].add(t.lemma_)\n",
    "        \n",
    "print(tokenCt)\n",
    "print(poemCt)\n",
    "print(len(tokenLemmas['Before']),len(tokenLemmas['After']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87205d6a-949b-40e9-8591-8aafaa60b84d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Little experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25279c80-4991-460a-858d-ca314ad42816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenLemmas['Before']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "361c4fe1-fa8a-432a-9567-af9d2fce02df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 3222/3222 [00:01<00:00, 3187.59it/s]\n"
     ]
    }
   ],
   "source": [
    "### Tense breakdown each time period\n",
    "tenseDict = {'Before' : dict(), 'After' : dict()}\n",
    "for p in tenseDict:\n",
    "    for t in ['Past','Pres','Fut']:\n",
    "        tenseDict[p][t] = 0\n",
    "for r in tqdm(records):\n",
    "    p = r['Before or after']\n",
    "    for t in r['doc']:\n",
    "        if t.pos_ == 'VERB' and 'Tense' in t.morph.to_dict():\n",
    "            tense = t.morph.to_dict()['Tense']\n",
    "            m = t.morph\n",
    "            tenseDict[p].setdefault(tense, 0)\n",
    "            tenseDict[p][tense]+=1\n",
    "for p in tenseDict:\n",
    "    print(p)\n",
    "    for t in tenseDict[p]:\n",
    "        print(t,tenseDict[p][t]/(tenseDict[p]['Past']+tenseDict[p]['Pres']+tenseDict[p]['Fut']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f5ad799f-8393-45da-b0ab-64a889b46c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=6.0487816625211215, pvalue=1.4693138352414718e-09)\n"
     ]
    }
   ],
   "source": [
    "a1 = tenseDict['Before']['Pres']*[1]+ tenseDict[\"Before\"]['Past']*[0] + tenseDict['Before']['Fut']*[0]\n",
    "a2 = tenseDict['After']['Pres']*[1]+ tenseDict[\"After\"]['Past']*[0] + tenseDict['After']['Fut']*[0]\n",
    "test = scipy.stats.ttest_ind(a1, a2, axis=0, equal_var=True, nan_policy='propagate', \n",
    "                          permutations=None, random_state=None, alternative='two-sided', trim=0)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5d282d3b-7744-4da7-83b3-946702c60fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fut : Ttest_indResult(statistic=-7.359306571050845, pvalue=1.8756963438929145e-13)\n",
    "# Pres: Ttest_indResult(statistic=6.0487816625211215, pvalue=1.4693138352414718e-09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14e945c-dee4-4e68-9d30-216e5383c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "posDict['Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "129f0b45-6a20-4d09-98c5-01a02523f0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 3222/3222 [00:02<00:00, 1462.79it/s]\n"
     ]
    }
   ],
   "source": [
    "### Tense breakdown each time period\n",
    "posDict = {'Before' : dict(), 'After' : dict()}\n",
    "totalDict = {'Before' : 0, 'After' : 0}\n",
    "adjs = set()\n",
    "\n",
    "for r in tqdm(records):\n",
    "    p = r['Before or after']\n",
    "    for t in r['doc']:\n",
    "        if t.pos_:\n",
    "            pos = t.pos_\n",
    "            posDict[p].setdefault(pos, 0)\n",
    "            posDict[p][pos]+=1\n",
    "        if t.pos_ == 'ADJ':\n",
    "            adjs.add(t.lemma_)\n",
    "        if t.pos_ in ['NOUN', 'ADP', 'PROPN', 'ADJ', 'DET', 'SCONJ', 'VERB', 'ADV', 'PRON', 'CCONJ', 'PART', 'AUX', 'NUM', 'INTJ']:\n",
    "            totalDict[p]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0738f2b8-26a9-4b0c-9777-8343fd668aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06345136188070334"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(posDict['After']['ADJ']/totalDict['After']-posDict['Before']['ADJ']/totalDict['Before'])/(posDict['Before']['ADJ']/totalDict['Before'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2395b763-5ea9-4543-8b3a-fab564638772",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "NOUN 0.28718523363407267\n",
      "NOUN 0.2867860716751128\n",
      "\n",
      "After\n",
      "ADP 0.1053998422561222\n",
      "ADP 0.10570928608505333\n",
      "\n",
      "After\n",
      "PROPN 0.03020699074697497\n",
      "PROPN 0.038443632238282024\n",
      "\n",
      "After\n",
      "ADJ 0.09392974626320143\n",
      "ADJ 0.08796977594169239\n",
      "\n",
      "After\n",
      "SPACE 0.1961747109631995\n",
      "SPACE 0.2013849125867577\n",
      "\n",
      "After\n",
      "DET 0.031895042610084065\n",
      "DET 0.0323806262073837\n",
      "\n",
      "After\n",
      "PUNCT 0.2014697112517554\n",
      "PUNCT 0.2213987189023444\n",
      "\n",
      "After\n",
      "SCONJ 0.026551949675855568\n",
      "SCONJ 0.023898839306259398\n",
      "\n",
      "After\n",
      "VERB 0.1590183329165304\n",
      "VERB 0.16362624484269897\n",
      "\n",
      "After\n",
      "ADV 0.06487216974780216\n",
      "ADV 0.06370704924787687\n",
      "\n",
      "After\n",
      "PRON 0.08523940519015832\n",
      "PRON 0.08046192293079182\n",
      "\n",
      "After\n",
      "CCONJ 0.055017986649481564\n",
      "CCONJ 0.053395122838749726\n",
      "\n",
      "After\n",
      "PART 0.04244656907065771\n",
      "PART 0.04711806540340663\n",
      "\n",
      "After\n",
      "AUX 0.007401458169016794\n",
      "AUX 0.007598824857789599\n",
      "\n",
      "After\n",
      "NUM 0.010402439258988516\n",
      "NUM 0.00852459718201326\n",
      "\n",
      "After\n",
      "INTJ 0.0004328338110536137\n",
      "INTJ 0.0003799412428894799\n",
      "\n",
      "After\n",
      "X 0.00498239809168382\n",
      "X 0.003242878777338378\n",
      "\n",
      "After\n",
      "SYM 0.0005674932189369601\n",
      "SYM 0.0001498359831113442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in posDict['Before']:\n",
    "    print(p)\n",
    "    for p in ['Before','After']:\n",
    "        print(t,posDict[p][t]/totalDict[p])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1b5273fc-0614-438d-89b8-b1b111ab3816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROPN Ttest_indResult(statistic=-13.759636313472408, pvalue=4.557583688404265e-43)\n",
      "ADJ Ttest_indResult(statistic=5.93134393655854, pvalue=3.0069309691234293e-09)\n",
      "SCONJ Ttest_indResult(statistic=5.168783539064797, pvalue=2.35734161794761e-07)\n",
      "VERB Ttest_indResult(statistic=-3.340947962508741, pvalue=0.0008349953358985565)\n",
      "PRON Ttest_indResult(statistic=5.000492327496617, pvalue=5.720666020345868e-07)\n",
      "CCONJ Ttest_indResult(statistic=2.1289808190481043, pvalue=0.033256432733142285)\n",
      "PART Ttest_indResult(statistic=-6.784762061190034, pvalue=1.1643386677297055e-11)\n",
      "NUM Ttest_indResult(statistic=6.011905477380559, pvalue=1.8351374845103045e-09)\n"
     ]
    }
   ],
   "source": [
    "for pos in ['NOUN', 'ADP', 'PROPN', 'ADJ', 'DET', 'SCONJ', 'VERB', 'ADV', 'PRON', 'CCONJ', 'PART', 'AUX', 'NUM', 'INTJ']:\n",
    "    a1 = posDict['Before'][pos]*[1]+ totalDict[\"Before\"]*[0]\n",
    "    a2 = posDict['After'][pos]*[1]+ totalDict[\"After\"]*[0]\n",
    "    test = scipy.stats.ttest_ind(a1, a2, axis=0, equal_var=True, nan_policy='propagate', \n",
    "                              permutations=None, random_state=None, alternative='two-sided', trim=0)\n",
    "    if test.pvalue < .05:\n",
    "        print(pos, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10e46f8-10d4-4663-a55e-75b5db55542a",
   "metadata": {},
   "source": [
    "### Calculating two sample one sided t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc15ac32-9d2f-47a5-9583-919907bddab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 3222/3222 [00:04<00:00, 679.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Russia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 3222/3222 [00:51<00:00, 62.70it/s]\n",
      "100%|██████████████████████████| 43565/43565 [00:10<00:00, 3973.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "923\n",
      "Non-Russia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 3222/3222 [00:44<00:00, 72.92it/s]\n",
      "100%|█████████████████████████| 43565/43565 [00:00<00:00, 68916.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "textDict = dict()\n",
    "lemmaCts = dict()\n",
    "totalPoemCts = dict()\n",
    "allLemmas = set()\n",
    "scipyArray = dict()\n",
    "bigData = dict()\n",
    "for r in tqdm(records):\n",
    "    for t in r['doc']:\n",
    "        lemmaCts.setdefault(t.lemma_, {'Before' : 0, 'After' : 0, 'nlpToken' : t})\n",
    "        textDict.setdefault(t.lemma_, {'Before' : [], 'After' : []})\n",
    "        scipyArray.setdefault(t.lemma_, {'Before' : [], 'After' : []})\n",
    "        allLemmas.add(t.lemma_)\n",
    "        \n",
    "for aff in ['Russia','Non-Russia']:\n",
    "    print(aff)\n",
    "    for r in tqdm(records):\n",
    "        if r['Author'] not in authorDict:\n",
    "            continue\n",
    "        if authorDict[r['Author']]['Country'] == 'Russia':\n",
    "            thisaff = 'Russia'\n",
    "        elif authorDict[r['Author']]['Country'] == 'N/A':\n",
    "            continue\n",
    "        else:\n",
    "            thisaff = 'Non-Russia'\n",
    "        if thisaff != aff:\n",
    "            continue\n",
    "            \n",
    "        p = r['Before or after']\n",
    "        totalPoemCts.setdefault(p, 0)\n",
    "        lemmasFound = set()\n",
    "        totalPoemCts[p] += 1\n",
    "        for t in r['doc']:\n",
    "            if t.lemma_ not in lemmasFound:\n",
    "                # lemmaCts.setdefault(t.lemma_, {'Before' : 0, 'After' : 0})\n",
    "                lemmaCts[t.lemma_][p] += 1\n",
    "                textDict[t.lemma_][p].append({'ID' : r['UniqueIndex'], 'tokenText' : t.text})\n",
    "                lemmasFound.add(t.lemma_)\n",
    "                \n",
    "            else:\n",
    "                continue\n",
    "        # create arrays for scipy\n",
    "        recLemmas = set([t.lemma_ for t in r['doc']])\n",
    "        for rl in recLemmas:\n",
    "            scipyArray[rl][p].append(1)\n",
    "        for lem in allLemmas:\n",
    "            if lem not in recLemmas:\n",
    "                scipyArray[lem][p].append(0)\n",
    "                \n",
    "    lemmaFreqs = dict()\n",
    "    for word in allLemmas:\n",
    "        lemmaFreqs.setdefault(word, {'Before' : 0, 'After' : 0})\n",
    "        for p in ['Before','After']:\n",
    "            lemmaFreqs[word][p] = lemmaCts[word][p]/totalPoemCts[p]\n",
    "            lemmaFreqs[word][p+'Ct'] = lemmaCts[word][p]\n",
    "            lemmaFreqs[word]['nlp'] = lemmaCts[word]['nlpToken']\n",
    "\n",
    "    jsonData = []\n",
    "    theselemmas = set()\n",
    "    for keyword in tqdm(allLemmas):\n",
    "        if lemmaCts[keyword]['Before'] + lemmaCts[keyword]['After'] >= 25:\n",
    "            theselemmas.add(keyword)\n",
    "            a1 = scipyArray[keyword]['Before']\n",
    "            a2 = scipyArray[keyword]['After']\n",
    "            test = scipy.stats.ttest_ind(a1, a2, axis=0, equal_var=True, nan_policy='propagate', \n",
    "                                  permutations=None, random_state=None, alternative='two-sided', trim=0)\n",
    "            lemmaFreqs[keyword]['stats'] = {'statistic' : test.statistic, 'pvalue' : test.pvalue}\n",
    "            pos = lemmaFreqs[keyword]['nlp'].pos_\n",
    "            del lemmaFreqs[keyword]['nlp']\n",
    "            jsonData.append({\n",
    "                'keyword' : keyword,\n",
    "                'pos' : pos,\n",
    "                'info' : lemmaFreqs[keyword]\n",
    "            })\n",
    "    print(len(jsonData))\n",
    "    bigData[aff] = jsonData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c2579ddd-8d72-449d-b70f-d1f50eb47c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keyword': 'назад',\n",
       " 'pos': 'ADV',\n",
       " 'info': {'Before': 0.031818181818181815,\n",
       "  'After': 0.038834951456310676,\n",
       "  'BeforeCt': 35,\n",
       "  'AfterCt': 28,\n",
       "  'stats': {'statistic': -0.8009665987099532, 'pvalue': 0.42325558830164767}}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(bigData['Russia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "93397c59-763e-44ce-8b75-0806a395aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../sigFreqTables/frequencyData3-26.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(bigData, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a967527b-bad6-497a-9cf9-4575da596b6e",
   "metadata": {},
   "source": [
    "### Diff between Rus/Non-Rus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9592878b-6221-4602-961b-84cc93ec91a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.proportion import proportions_ztest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5b7242e0-9c3f-49fd-9e94-c7bbb91af6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keyword': 'них',\n",
       " 'pos': 'PRON',\n",
       " 'info': {'Before': 0.06909090909090909,\n",
       "  'After': 0.0651872399445215,\n",
       "  'BeforeCt': 76,\n",
       "  'AfterCt': 47,\n",
       "  'stats': {'statistic': 0.3244475462185382, 'pvalue': 0.7456365332324566}}}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(bigData['Russia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1b8f80c9-91a9-4bae-9ed6-fb0072d66a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Russia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 3222/3222 [00:00<00:00, 328337.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Russia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 3222/3222 [00:00<00:00, 911264.16it/s]\n"
     ]
    }
   ],
   "source": [
    "ctDict = dict()\n",
    "for aff in ['Russia','Non-Russia']:\n",
    "    \n",
    "    print(aff)\n",
    "    for r in tqdm(records):\n",
    "        p = r['Before or after']\n",
    "        if r['Author'] not in authorDict:\n",
    "            continue\n",
    "        if authorDict[r['Author']]['Country'] == 'Russia':\n",
    "            thisaff = 'Russia'\n",
    "        elif authorDict[r['Author']]['Country'] == 'N/A':\n",
    "            continue\n",
    "        else:\n",
    "            thisaff = 'Non-Russia'\n",
    "\n",
    "        if thisaff != aff:\n",
    "            continue\n",
    "            \n",
    "        ctDict.setdefault(aff, {'Before' : 0,'After' : 0})\n",
    "        ctDict[aff][p]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "af8f938f-a94c-4673-8c95-ababb6b0d892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Russia': {'Before': 1100, 'After': 721},\n",
       " 'Non-Russia': {'Before': 405, 'After': 550}}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d7fd93ef-5315-4a71-8a51-6f5d28116cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 923/923 [00:00<00:00, 2546.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffBtwn = []\n",
    "for d in tqdm(bigData['Russia']):\n",
    "    for e in bigData['Non-Russia']:\n",
    "        if d['keyword'] == e['keyword']:\n",
    "            # Russian group proportions and sample sizes\n",
    "            russian_before = d['info']['Before']  # Example: 15% of words in the \"Before\" period\n",
    "            russian_after = d['info']['After']   # Example: 25% of words in the \"After\" period\n",
    "            n_russian_before = 1100  # Example: 1000 words in the Russian group before\n",
    "            n_russian_after = 721   # Example: 1000 words in the Russian group after\n",
    "\n",
    "            # Non-Russian group proportions and sample sizes\n",
    "            non_russian_before = e['info']['Before']  # Example: 12% of words in the \"Before\" period\n",
    "            non_russian_after = e['info']['After']  # Example: 22% of words in the \"After\" period\n",
    "            n_non_russian_before = 405  # Example: 1000 words in the non-Russian group before\n",
    "            n_non_russian_after = 550   # Example: 1000 words in the non-Russian group after\n",
    "            \n",
    "            russian_diff = russian_after - russian_before\n",
    "            non_russian_diff = non_russian_after - non_russian_before\n",
    "            \n",
    "            pooled_prop = ((russian_before * n_russian_before + non_russian_before * n_non_russian_before) +\n",
    "              (russian_after * n_russian_after + non_russian_after * n_non_russian_after)) / \\\n",
    "              (n_russian_before + n_russian_after + n_non_russian_before + n_non_russian_after)\n",
    "            \n",
    "            \n",
    "            count = np.array([russian_after * n_russian_after - russian_before * n_russian_before,\n",
    "                              non_russian_after * n_non_russian_after - non_russian_before * n_non_russian_before])\n",
    "            nobs = np.array([n_russian_before + n_russian_after, n_non_russian_before + n_non_russian_after])\n",
    "\n",
    "            z_stat, p_value = proportions_ztest(count, nobs, alternative='two-sided')\n",
    "\n",
    "            alpha = 0.05  # Example: significance level of 0.05\n",
    "            if p_value < alpha:\n",
    "                diffBtwn.append({'Russia' : d, 'Non-Russia' : e, 'p_value' : p_value})\n",
    "                # print(\"The difference in frequency changes between the Russian and non-Russian groups is statistically significant.\")\n",
    "            else:\n",
    "                # print(\"The difference in frequency changes between the Russian and non-Russian groups is not statistically significant.\")\n",
    "                continue\n",
    "len(diffBtwn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3d46a89f-f4ec-4154-845e-1cc2b55e7b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in the notaligned, are there any that go in opposite directions?\n",
    "oppDirs = []\n",
    "for pair in diffBtwn:\n",
    "    dirR = pair['Russia']['info']['After'] - pair['Russia']['info']['Before']\n",
    "    dirNR = pair['Non-Russia']['info']['After'] - pair['Non-Russia']['info']['Before']\n",
    "    if np.sign(dirR) != np.sign(dirNR):\n",
    "        oppDirs.append(pair)\n",
    "len(oppDirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e3593b07-277b-44b0-a7a5-9fbcfa8d1a3f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Russia': {'keyword': 'ужас',\n",
       "   'pos': 'NOUN',\n",
       "   'info': {'Before': 0.02,\n",
       "    'After': 0.019417475728155338,\n",
       "    'BeforeCt': 22,\n",
       "    'AfterCt': 14,\n",
       "    'stats': {'statistic': 0.08728204215536717,\n",
       "     'pvalue': 0.9304569347396332}}},\n",
       "  'Non-Russia': {'keyword': 'ужас',\n",
       "   'pos': 'NOUN',\n",
       "   'info': {'Before': 0.017940199335548173,\n",
       "    'After': 0.02989771833202203,\n",
       "    'BeforeCt': 27,\n",
       "    'AfterCt': 38,\n",
       "    'stats': {'statistic': -2.076592080070808, 'pvalue': 0.0379310826006974}}},\n",
       "  'p_value': 5.980813705380458e-65},\n",
       " {'Russia': {'keyword': 'число',\n",
       "   'pos': 'NOUN',\n",
       "   'info': {'Before': 0.014545454545454545,\n",
       "    'After': 0.020804438280166437,\n",
       "    'BeforeCt': 16,\n",
       "    'AfterCt': 15,\n",
       "    'stats': {'statistic': -1.0094815891374527,\n",
       "     'pvalue': 0.31287798753851914}}},\n",
       "  'Non-Russia': {'keyword': 'число',\n",
       "   'pos': 'NOUN',\n",
       "   'info': {'Before': 0.013953488372093023,\n",
       "    'After': 0.013375295043273014,\n",
       "    'BeforeCt': 21,\n",
       "    'AfterCt': 17,\n",
       "    'stats': {'statistic': 0.13057503308078147,\n",
       "     'pvalue': 0.8961209622179747}}},\n",
       "  'p_value': 0.00024565601521912714},\n",
       " {'Russia': {'keyword': 'звучать',\n",
       "   'pos': 'VERB',\n",
       "   'info': {'Before': 0.015454545454545455,\n",
       "    'After': 0.020804438280166437,\n",
       "    'BeforeCt': 17,\n",
       "    'AfterCt': 15,\n",
       "    'stats': {'statistic': -0.8494373747252888,\n",
       "     'pvalue': 0.3957497433537108}}},\n",
       "  'Non-Russia': {'keyword': 'звучать',\n",
       "   'pos': 'VERB',\n",
       "   'info': {'Before': 0.01727574750830565,\n",
       "    'After': 0.016522423288749016,\n",
       "    'BeforeCt': 26,\n",
       "    'AfterCt': 21,\n",
       "    'stats': {'statistic': 0.15322418673999094,\n",
       "     'pvalue': 0.8782326291425924}}},\n",
       "  'p_value': 5.258466977747568e-47},\n",
       " {'Russia': {'keyword': 'хватить',\n",
       "   'pos': 'VERB',\n",
       "   'info': {'Before': 0.017272727272727273,\n",
       "    'After': 0.024965325936199722,\n",
       "    'BeforeCt': 19,\n",
       "    'AfterCt': 18,\n",
       "    'stats': {'statistic': -1.1376523334753994,\n",
       "     'pvalue': 0.2554155120113583}}},\n",
       "  'Non-Russia': {'keyword': 'хватить',\n",
       "   'pos': 'VERB',\n",
       "   'info': {'Before': 0.020598006644518274,\n",
       "    'After': 0.01966955153422502,\n",
       "    'BeforeCt': 31,\n",
       "    'AfterCt': 25,\n",
       "    'stats': {'statistic': 0.17329221377434784,\n",
       "     'pvalue': 0.8624343869475191}}},\n",
       "  'p_value': 0.0006467240641735788}]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oppDirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ba007238-edc2-404e-ac08-f7cf9fd91c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Russia': {'keyword': 'молчать',\n",
       "  'pos': 'VERB',\n",
       "  'info': {'Before': 0.034545454545454546,\n",
       "   'After': 0.05131761442441054,\n",
       "   'BeforeCt': 38,\n",
       "   'AfterCt': 37,\n",
       "   'stats': {'statistic': -1.7619226647406203, 'pvalue': 0.07825031630214}}},\n",
       " 'non-Russia': {'keyword': 'молчать',\n",
       "  'pos': 'VERB',\n",
       "  'info': {'Before': 0.03122923588039867,\n",
       "   'After': 0.043273013375295044,\n",
       "   'BeforeCt': 47,\n",
       "   'AfterCt': 55,\n",
       "   'stats': {'statistic': -1.6807271068920744,\n",
       "    'pvalue': 0.09292851473192604}}},\n",
       " 'p_value': 3.9829236795424123e-07}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(diffBtwn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b8c3b9d5-44c7-4bab-8545-544c3ac922d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 923/923 [00:00<00:00, 4556.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# find the words which changed for one but not the other\n",
    "notaligned = []\n",
    "alignedSig = []\n",
    "alignedNotSig = []\n",
    "for d in tqdm(bigData['Russia']):\n",
    "    for e in bigData['Non-Russia']:\n",
    "        if d['keyword'] == e['keyword']:\n",
    "            if d['info']['stats']['pvalue'] < .05 and e['info']['stats']['pvalue'] > .05:\n",
    "                notaligned.append({'Russia':d, 'Non-Russia':e})\n",
    "            elif d['info']['stats']['pvalue'] > .05 and e['info']['stats']['pvalue'] < .05:\n",
    "                notaligned.append({'Russia':d, 'Non-Russia':e})\n",
    "            elif d['info']['stats']['pvalue'] < .05 and e['info']['stats']['pvalue'] < .05:\n",
    "                alignedSig.append({'Russia':d, 'Non-Russia':e})\n",
    "            else:\n",
    "                alignedNotSig.append({'Russia':d, 'Non-Russia':e})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8e8c2cb8-30fa-44f2-a9ed-fa8f59e6e876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139, 204, 580)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(notaligned), len(alignedSig), len(alignedNotSig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8d4cb3db-691c-4cc7-ba74-41171054197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words =['язык', 'речь', 'слово', 'словарь', 'говорить', 'сказать',\n",
    "                    'значение', 'смысл', 'разговор','тишина','молчать','замолчать','погорвоить','сказывать',\n",
    "                'беседа','беседовать','произношение','произносить','тема','значение','значить']\n",
    "for a in notaligned:\n",
    "    if a['Russia']['keyword'] == 'любить':\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "146ff585-91c5-4890-bae4-bf5a457e3370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in the notaligned, are there any that go in opposite directions?\n",
    "oppDirs = []\n",
    "for pair in notaligned:\n",
    "    dirR = pair['Russia']['info']['After'] - pair['Russia']['info']['Before']\n",
    "    dirNR = pair['Non-Russia']['info']['After'] - pair['Non-Russia']['info']['Before']\n",
    "    if np.sign(dirR) != np.sign(dirNR):\n",
    "        oppDirs.append(pair)\n",
    "len(oppDirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e98114df-1848-4417-94f7-b967a81441d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Russia': {'keyword': 'ужас',\n",
       "   'pos': 'NOUN',\n",
       "   'info': {'Before': 0.02,\n",
       "    'After': 0.019417475728155338,\n",
       "    'BeforeCt': 22,\n",
       "    'AfterCt': 14,\n",
       "    'stats': {'statistic': 0.08728204215536717,\n",
       "     'pvalue': 0.9304569347396332}}},\n",
       "  'Non-Russia': {'keyword': 'ужас',\n",
       "   'pos': 'NOUN',\n",
       "   'info': {'Before': 0.017940199335548173,\n",
       "    'After': 0.02989771833202203,\n",
       "    'BeforeCt': 27,\n",
       "    'AfterCt': 38,\n",
       "    'stats': {'statistic': -2.076592080070808,\n",
       "     'pvalue': 0.0379310826006974}}}},\n",
       " {'Russia': {'keyword': 'пока',\n",
       "   'pos': 'ADV',\n",
       "   'info': {'Before': 0.11545454545454545,\n",
       "    'After': 0.08599167822468794,\n",
       "    'BeforeCt': 127,\n",
       "    'AfterCt': 62,\n",
       "    'stats': {'statistic': 2.0172028367794943,\n",
       "     'pvalue': 0.04382099141501074}}},\n",
       "  'Non-Russia': {'keyword': 'пока',\n",
       "   'pos': 'ADV',\n",
       "   'info': {'Before': 0.11029900332225914,\n",
       "    'After': 0.1109362706530291,\n",
       "    'BeforeCt': 166,\n",
       "    'AfterCt': 141,\n",
       "    'stats': {'statistic': -0.053319540563253234,\n",
       "     'pvalue': 0.9574811505631675}}}}]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oppDirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8876b1a5-b258-4ca5-be05-b7636e61b51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interesting = []\n",
    "for r in records:\n",
    "    docLemmas = set([t.lemma_ for t in r['doc']])\n",
    "    if 'язык' in docLemmas and 'ужас' in docLemmas:\n",
    "        interesting.append(r)\n",
    "len(interesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2342ac0c-2055-46c1-bc1f-4141b24b7d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1523, 1273, 523, 1174]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i['UniqueIndex'] for i in interesting]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846d8d60-3eff-4653-b67d-e4ea9880956e",
   "metadata": {},
   "source": [
    "#### Significant word breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "893042ed-a326-48f5-9670-95456e8dc523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1626 421\n"
     ]
    }
   ],
   "source": [
    "# filter data\n",
    "data = [d for d in jsonData if not d['info']['Before']*d['info']['After']==0 ]\n",
    "data = [d for d in data if d['info']['stats']['pvalue'] < .05]\n",
    "data = [d for d in data if d['keyword'].isalpha()]\n",
    "irrelevantWords = ['авторский', 'блог', 'личный', 'источник','автор']\n",
    "data = [d for d in data if d['keyword'] not in irrelevantWords]\n",
    "print(len(jsonData), len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "963187bd-2877-4937-85ac-b5583164f253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemsForPCA = [d['keyword'] for d in data]\n",
    "len(lemsForPCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a8de114-cb60-4d54-93d4-cd36388613f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('word4map.txt', 'w') as f:\n",
    "#     f.write('\\n'.join(lemsForPCA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c4fab126-9602-4b94-984f-7545d663c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "posDict = {'increase' : dict(), 'decrease' : dict()}\n",
    "for d in data:\n",
    "    which = ''\n",
    "    if d['info']['After'] - d['info']['Before'] > 0:\n",
    "        which = 'increase'\n",
    "    else:\n",
    "        which = 'decrease'\n",
    "    pos = d['info']['nlp'].pos_\n",
    "    posDict[which].setdefault(pos, [])\n",
    "    posDict[which][pos].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "241a0a4a-fb2a-492d-a1e2-b3c79cced1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADJ',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'AUX',\n",
       " 'CCONJ',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'NUM',\n",
       " 'PART',\n",
       " 'PRON',\n",
       " 'PROPN',\n",
       " 'SCONJ',\n",
       " 'VERB']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([p for p in set(list(posDict['increase'].keys()) + list(posDict['decrease'].keys()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ed7d18aa-7d59-4e07-a1f9-a01a11569127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jj/_szc94p56q91q_7c209d1d9w0000gn/T/ipykernel_1438/3898841191.py:1: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  random.sample((adjs - iodAdjs),5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['скушно', 'крутой', 'цветущий', 'обычный', 'отъявленный']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample((adjs - iodAdjs),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fd0edf06-efdb-4892-a140-662b7784162b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADJ 17\n",
      "безумный\n",
      "божий\n",
      "весенний\n",
      "вечный\n",
      "виноватый\n",
      "военный\n",
      "злой\n",
      "кровавый\n",
      "мирный\n",
      "мировой\n",
      "родный\n",
      "российский\n",
      "русский\n",
      "святой\n",
      "страшный\n",
      "чужой\n",
      "ядерный\n",
      "\n",
      "ADJ 45\n",
      "белый\n",
      "высоко\n",
      "глубокий\n",
      "голубой\n",
      "горячий\n",
      "дикий\n",
      "длинный\n",
      "долгий\n",
      "другой\n",
      "жаркий\n",
      "зелёный\n",
      "красивый\n",
      "круглый\n",
      "ледяной\n",
      "летний\n",
      "лёгкий\n",
      "медленный\n",
      "милый\n",
      "мокрый\n",
      "молодой\n",
      "мягкий\n",
      "небольшой\n",
      "невидимый\n",
      "нежный\n",
      "непонятный\n",
      "ночной\n",
      "осенний\n",
      "полный\n",
      "прозрачный\n",
      "пустой\n",
      "светлый\n",
      "слабый\n",
      "сложный\n",
      "случайный\n",
      "смешной\n",
      "собачий\n",
      "сплошной\n",
      "стальной\n",
      "стеклянный\n",
      "странный\n",
      "сырой\n",
      "тёмный\n",
      "тёплый\n",
      "узкий\n",
      "школьный\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iodAdjs = set()\n",
    "for iod in ['increase','decrease']:\n",
    "    for pos in posDict[iod]:\n",
    "        if pos == 'ADJ':\n",
    "            print(pos,len(sorted(posDict[iod][pos], key=lambda x:x['keyword'])))\n",
    "            for n in sorted(posDict[iod][pos], key=lambda x:x['keyword']):\n",
    "                print(n['keyword'])\n",
    "                iodAdjs.add(n['keyword'])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c55a89-8393-48cf-aaa1-73ae1f28e782",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1cea1aa9-97b2-4f94-9c1a-965c763b3768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os.path\n",
    "\n",
    "from django.conf import settings\n",
    "\n",
    "from navec import Navec\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "\n",
    "NAVEC_PATH = \"data4notebooks/navec_hudlit_v1_12B_500K_300d_100q.tar\"\n",
    "# ANNOY_INDEX_PATH = os.path.join(settings.ROOT_DIR, \"parser_tool\", \"data\", \"ANNOY_tree.ann\")\n",
    "\n",
    "navec = Navec.load(NAVEC_PATH)\n",
    "vocabulary = navec.vocab.words\n",
    "word_to_index = dict()\n",
    "for i, word in enumerate(vocabulary):\n",
    "    word_to_index[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b11e26de-4885-4a7f-8da2-7f004d2fd9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD JSON WITH AVERAGE VALS\n",
    "with open(f'../../files2big/beforeandafter768D0', 'r', encoding='utf-8') as f:\n",
    "    jsonVecs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ef386daf-336f-452c-9599-5a9d945e9323",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = dict()\n",
    "for v in jsonVecs:\n",
    "    if 'Average' in v['word']:\n",
    "        word2vec[v['word'].replace('_Average','')] = v['vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1b443857-c2da-417e-ae28-2f45ccb2c0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOUN'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(word)[0].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae4348b5-bb67-4d08-8202-eead152f272f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 92/92 [01:30<00:00,  1.01it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:04<00:00,  1.25it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:01<00:00,  1.04it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:16<00:00,  1.03it/s]\n",
      "100%|███████████████████████████████████████████| 33/33 [00:30<00:00,  1.07it/s]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:03<00:00,  1.31s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:02<00:00,  1.25it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:05<00:00,  1.20it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:09<00:00,  1.13it/s]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:02<00:00,  1.11it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.04s/it]\n",
      "100%|█████████████████████████████████████████| 102/102 [01:33<00:00,  1.09it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:16<00:00,  1.01it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:01<00:00,  1.43it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:01<00:00,  1.15it/s]\n",
      "100%|███████████████████████████████████████████| 45/45 [00:44<00:00,  1.02it/s]\n",
      "100%|███████████████████████████████████████████| 40/40 [00:37<00:00,  1.05it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:01<00:00,  1.27it/s]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:15<00:00,  1.05it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:04<00:00,  1.41it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.69s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:04<00:00,  1.52s/it]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.24s/it]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "vecDict = dict()\n",
    "for direction in posDict:\n",
    "    vecDict.setdefault(direction, dict())\n",
    "    for pos in posDict[direction]:\n",
    "        vecDict[direction].setdefault(pos, [])\n",
    "        keywords = [d['keyword'] for d in posDict[direction][pos]]\n",
    "        for word in tqdm(keywords):\n",
    "            try:\n",
    "                navector = navec[word].tolist()\n",
    "            except:\n",
    "                print('not in navec dictionary')\n",
    "                navector = np.zeros(300).tolist()\n",
    "            vecDict[direction][pos].append({\n",
    "                \"word\" : word,\n",
    "                \"translatedword\" : ts.google(word),\n",
    "                \"bertvector\" : word2vec[word],\n",
    "                'navecvector' : navector,\n",
    "                'countryInfo' : countryBreakdowns[word]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4481858e-3bc6-4274-89fb-a076dfce93fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a6428ae3-08cb-475d-b803-0596fdb222b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../significantPCA/sigMeanDiffVecsTranslated4.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(vecDict, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2c557702-19fa-406e-bba3-321881891979",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../significantPCA/sigMeanDiffVecsTranslated4.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "541764cf-cc49-4202-a696-6b99b6d59062",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = dict()\n",
    "for iod in data:\n",
    "    for pos in data[iod]:\n",
    "        for word in data[iod][pos]:\n",
    "            tdata[word['word']] = word['translatedword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a6655433-bc63-4a10-afb4-36b81fe4cfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../sigFreqTables//translations.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(tdata, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b636b9-470c-4dad-b599-db3bcbc0d91a",
   "metadata": {},
   "source": [
    "### Create word category datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4febf3fb-7ab0-40e2-9cf4-76f659166f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('untitled.txt','r') as f:\n",
    "    txt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "cce88ae6-794b-420f-8fed-db62104d39d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sDict = dict()\n",
    "for subject in txt.split('\\n'):\n",
    "    split = subject.split(' - ')\n",
    "    sDict[split[0]] = [d.strip() for d in split[1].split(',') if d.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b43bc0bf-7884-44dd-9ff4-79b46331b4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../averagePCA/categories.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(sDict, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1f7d1a-0520-48ba-ad58-0baaa14958f0",
   "metadata": {},
   "source": [
    "## Synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c236b897-c785-4776-a097-260366e5b425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading a ruwordnet model from https://github.com/avidale/python-ruwordnet/releases/download/0.0.4/ruwordnet-2021.db\n"
     ]
    }
   ],
   "source": [
    "!ruwordnet download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f69e8feb-3435-4df0-805f-98311e05b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ruwordnet import RuWordNet\n",
    "wn = RuWordNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92a775f1-b44a-4ebc-9482-34f6cc60a712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вселенная, мироздание, мир\n",
      "сообщество (совокупность людей)\n",
      "мир, отсутствие конфликтов\n",
      "мир, отсутствие войны\n"
     ]
    }
   ],
   "source": [
    "lemma = 'мир'\n",
    "for sense in wn.get_senses(lemma):\n",
    "    print(sense.synset.title.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b03ed04-7e97-4c3a-8632-4d0346c7355e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jj/_szc94p56q91q_7c209d1d9w0000gn/T/ipykernel_37206/3289863467.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscipyArray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Before or after'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtotalPoemCts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "lemmaCts = dict()\n",
    "totalPoemCts = dict()\n",
    "scipyArray = dict()\n",
    "sense2lemmas = dict()\n",
    "\n",
    "for r in tqdm(records):\n",
    "    p = r['Before or after']\n",
    "    totalPoemCts.setdefault(p, 0)\n",
    "    lemmasFound = set()\n",
    "    totalPoemCts[p] += 1\n",
    "    for t in r['doc']:\n",
    "        if t.lemma_ not in lemmasFound:\n",
    "            for sense in wn.get_senses(t.lemma_):\n",
    "                title = sense.synset.title.lower()\n",
    "                sense2lemmas.setdefault(sense, set())\n",
    "                sense2lemmas[sense].add(t.lemma_)\n",
    "                lemmaCts.setdefault(title, {'Before' : 0, 'After' : 0})\n",
    "                lemmaCts[title][p] += 1\n",
    "            lemmasFound.add(t.lemma_)\n",
    "        else:\n",
    "            continue\n",
    "lemmaFreqs = dict()\n",
    "for word in lemmaCts:\n",
    "    lemmaFreqs.setdefault(word, {'Before' : 0, 'After' : 0})\n",
    "    for p in lemmaCts[word]:\n",
    "        lemmaFreqs[word][p] = lemmaCts[word][p]/totalPoemCts[p]\n",
    "        lemmaFreqs[word][p+'Ct'] = lemmaCts[word][p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321d3059-5609-4daf-9921-e93a51e69fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # check if title already added\n",
    "    title = synset.title\n",
    "    # change synset label to lemma label if only one lemma mentioned\n",
    "    if len(synsetTokens[synset]) == 1:\n",
    "        title = list(synsetTokens[synset].keys())[0]\n",
    "        \n",
    "    # if title already added, skip entry, else continue\n",
    "    if title in titleAddedAlready:\n",
    "        print('OLD:',title, synset.title)\n",
    "        print('NEW:',title, lemma2synset[title])\n",
    "        continue\n",
    "    else:\n",
    "        lemma2synset[title] = synset.title\n",
    "        titleAddedAlready.add(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf879051-5847-438d-a466-f2af261db046",
   "metadata": {},
   "source": [
    "#### Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edb75491-056f-43e8-a145-664f3fbd5f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install spacy-language-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "884388b5-1ebe-4511-8702-9edc84ee6575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "\n",
    "from spacy_language_detection import LanguageDetector\n",
    "\n",
    "\n",
    "def get_lang_detector(nlp, name):\n",
    "    return LanguageDetector(seed=42)  # We use the seed 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "272c3975-501c-4392-b081-d04994c26dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is English text. {'language': 'en', 'score': 0.9999987929307774}\n",
      "Er lebt mit seinen Eltern und seiner Schwester in Berlin. {'language': 'de', 'score': 0.999996045846908}\n",
      "Yo me divierto todos los días en el parque. {'language': 'es', 'score': 0.9999960751128256}\n",
      "Je m'appelle Angélica Summer, j'ai 12 ans et je suis canadienne. {'language': 'fr', 'score': 0.9999960488878062}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlp_model = spacy.load(\"ru_core_news_lg\")\n",
    "Language.factory(\"language_detector\", func=get_lang_detector)\n",
    "nlp_model.add_pipe('language_detector', last=True)\n",
    "\n",
    "# Sentence level language detection\n",
    "text = \"This is English text. Er lebt mit seinen Eltern und seiner Schwester in Berlin. Yo me divierto todos los días en el parque. Je m'appelle Angélica Summer, j'ai 12 ans et je suis canadienne.\"\n",
    "doc = nlp_model(text)\n",
    "for i, sent in enumerate(doc.sents):\n",
    "    print(sent, sent._.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c1f7ef-df29-4312-93b6-a0dcf643fb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3252/3252 [05:13<00:00, 10.36it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "random.shuffle(records)\n",
    "for rec in tqdm(records):\n",
    "    rec['Doc'] = nlp_model(rec['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1e528cc4-6006-4c68-b988-686bd6284d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3252/3252 [07:47<00:00,  6.96it/s]\n"
     ]
    }
   ],
   "source": [
    "langDict = dict()\n",
    "for rec in tqdm(records):\n",
    "    for sent in rec['Doc'].sents:\n",
    "        langDict.setdefault(sent._.language['language'], [])\n",
    "        langDict[sent._.language['language']].append((sent, rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b5433fd8-683d-45c8-ad1e-4fe98799425a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ru', 'UNKNOWN', 'bg', 'mk', 'uk', 'en', 'et', 'hr', 'tl', 'ro', 'lt', 'de', 'id', 'ca', 'sk'])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "83050af3-a197-497e-96ce-daa71020c7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Unique index: 1652 \n",
      " Како добро живети…\n",
      "…Ako žiť dobre…\n",
      "…Kako dobro živeti. \n",
      "--\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = 'sk'\n",
    "print(len(langDict[lg]))\n",
    "[print('Unique index:',d[1]['UniqueIndex'],'\\n', d[0],'\\n--') for d in random.sample(langDict[lg],1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fb4c074a-563a-4e41-8cab-5f5efe8d05b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 523\n",
    "r = [r for r in records if r['UniqueIndex'] == 3239][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e200825a-0ec6-4e29-8e79-95615c954c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('essentialpoetry', 'Линор Горалик', datetime.datetime(2018, 5, 9, 0, 0))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['Source'], r['Author'], r['Date posted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c3b2e6f1-ad1d-4d9b-a8c4-c947b8e96022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вот красным лесом красная лиса, – \n",
      "а он лежит, смешавшись с автоматом, \n",
      "в осеннем красном буром чернозёме, \n",
      "неглубоко, – \n",
      "и вот лиса несётся, \n",
      "пересекая сердце, горло, сердце, – \n",
      "подскакивает, лапой влезши в душу, \n",
      "отряхивает лапу, мчится дальше, – \n",
      "И он кричит распавшейся гортанью: \n",
      " \n",
      "КАКОГО ХУЯ, ГОСПОДИ, – ЗА ЧТО?! \n",
      " \n",
      "Я не успел – я инвалид по зренью, – \n",
      "я не успел, – они меня в апреле, \n",
      "когда уже исход и всё понятно, \n",
      "когда таких, как я, – едва одетых, \n",
      "полуслепых, хромых или безусых, – \n",
      "от киндер, кирхе, запаха из кюхен, – \n",
      "в зелёный их апрельский красный лес, \n",
      "где я от крови ничего не видел, \n",
      "и красный зверь, и горло, сердце, горло – \n",
      "а я ни разу даже не пальнул, \n",
      "я не успел – \n",
      "какого хуя, Боже?! \n",
      " \n",
      "ТАК ДАЙ МНЕ, ДАЙ МНЕ, ДАЙ МНЕ ЧТО-НИБУДЬ!!! \n",
      " \n",
      "И тут лиса упала и лежит.\n"
     ]
    }
   ],
   "source": [
    "print(r['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "82fe5a12-30ce-49a7-afec-f10006a906c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c45ad1-eab7-47f0-ab50-bbce7c6ef8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342235"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "for rec in records:\n",
    "    total += len(str(rec['Text']).split(' '))\n",
    "# 345043\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59684869-7272-46f4-9bd3-9ffb0bc61a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "essentialpoetry      945\n",
       "No War Poetry        724\n",
       "metajournal          662\n",
       "ROAR V3              350\n",
       "Facebook             253\n",
       "ROAR V2              234\n",
       "Personal Telegram     54\n",
       "Name: Source, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "502f5129-2b51-4d5c-891e-464349b9151f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Before    1661\n",
       "After     1561\n",
       "Name: Before or after, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Before or after'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d17f1d-0be3-4ec0-9139-77b515159b64",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Remove duplicates from corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "889570ec-6a8e-442f-973d-e049b3705224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Развивая Бродского\n",
      "1\n",
      "Я хотел бы жить, Иосиф, как можно дольше, пока\n",
      "ритмично дыханье и тянется на бумаге строка,\n",
      "жизнь - гостиный двор, мы временные постояльцы,\n",
      "и какое мне дело до того городка,\n",
      "где и\n"
     ]
    }
   ],
   "source": [
    "print(random.choice(records)['Text'][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "55a779f7-c1ca-40a8-9bc6-8b49a281df61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3502it [00:08, 406.86it/s] \n"
     ]
    }
   ],
   "source": [
    "longStringCts = dict()\n",
    "string2Recs = dict()\n",
    "string2RecIdx = dict()\n",
    "\n",
    "windowSize = 100\n",
    "for i, rec in tqdm(enumerate(records)):\n",
    "    text = rec['Text']\n",
    "    rec['UniqueIndex'] = i\n",
    "    if isinstance(text, str):\n",
    "        for j in range(len(text)-windowSize):\n",
    "            windowText = text[j:j+windowSize]\n",
    "            longStringCts.setdefault(windowText, 0)\n",
    "            longStringCts[windowText] += 1\n",
    "            string2Recs.setdefault(windowText, [])\n",
    "            string2Recs[windowText].append(rec)\n",
    "            # string2RecIdx.setdefault(windowText, set())\n",
    "            # string2RecIdx[windowText].add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5eab9b6f-d205-4ed6-9065-bebc1495077e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 2284719/2284719 [00:01<00:00, 1186974.80it/s]\n"
     ]
    }
   ],
   "source": [
    "relevantCts = dict()\n",
    "for s in tqdm(longStringCts):\n",
    "    if longStringCts[s] > 1:\n",
    "        relevantCts[s] = longStringCts[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ba4a1fb8-ce5a-4e8d-935b-f6a2a8a24a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 64074/64074 [00:00<00:00, 133374.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "228"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlappingRecs = []\n",
    "for s in tqdm(relevantCts):\n",
    "    shareString = string2Recs[s]\n",
    "    if shareString not in overlappingRecs:\n",
    "        # ids = [r['UniqueIndex'] for r in shareString]\n",
    "        # if set(ids) \n",
    "        overlappingRecs.append(shareString)\n",
    "len(overlappingRecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4c84ec3a-910c-4f17-bf2f-c646f8b04368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "6f9bfe16-d370-4ab1-a9c1-2bd294941f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decideRec(recList):\n",
    "    # if just one, return rec\n",
    "    if len(recList) == 1:\n",
    "        return recList[0:]\n",
    "    # convert to datetimes\n",
    "    for r in recList:\n",
    "        if not isinstance(r['Date posted'], datetime.datetime):\n",
    "            # essentialpoetry      1023\n",
    "            # No War Poetry         793\n",
    "            # metajournal           713\n",
    "            # ROAR V3               357\n",
    "            # Facebook              281\n",
    "            # ROAR V2               269\n",
    "            # Personal Telegram      66\n",
    "            if r['Source'] == 'ROAR V2':\n",
    "                r['Date posted'] = datetime.datetime(2022, 6, 24, 0, 0)\n",
    "            elif r['Source'] == 'ROAR V3':\n",
    "                r['Date posted'] = datetime.datetime(2022, 8, 24, 0, 0)\n",
    "            else:\n",
    "                r['Date posted'] = datetime.datetime(2022,12,17,0,0)\n",
    "    # compare date\n",
    "    sortedByDate = []\n",
    "    for i, rec in enumerate(recList):\n",
    "        sortedByDate.append((rec['Date posted'], i))\n",
    "    sortedByDate = sorted(sortedByDate)\n",
    "    # check types\n",
    "    if isinstance(sortedByDate[0], datetime.datetime) and isinstance(sortedByDate[1], datetime.datetime):\n",
    "        if sortedByDate[0] != sortedByDate[1]:\n",
    "            return recList[sortedByDate[0][1]]\n",
    "    else:\n",
    "        idxs = [s[1] for s in sortedByDate[1:]]\n",
    "        return [recList[j] for j in idxs]\n",
    "    \n",
    "    # compare length of text\n",
    "    sortedByLen = []\n",
    "    for i, rec in enumerate(recList):\n",
    "        sortedByLen.append((len(rec['Text']), i))\n",
    "    sortedByLen = sorted(sortedByLen)\n",
    "    idxs = [s[1] for s in sortedByLen[1:]]\n",
    "    return [recList[j] for j in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "696a8941-6cda-4d23-ada2-d4de67de61de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Text': '\\nРевёт жена опальная,\\nв правах поражена.\\nИдёт война двуспальная,\\nгражданская война.\\nПомыты кухня, ванная\\nслезами в три ручья.\\nИдёт война диванная,\\nтрещит по швам семья.\\n+\\nБудущему малышу,\\nптицам небесным пища?\\nСижу в уголке, пишу\\nугольком пепелища\\nродного. Роднее нет.\\nМай. Четвёртое мая.\\nВ окне кабинета свет:\\nне выключила, убегая.\\n+\\nВсе страны, кроме одной.\\nЧто же мы так бездомны?\\nВстречаемся, мой родной,\\nоколо пятой колонны\\nбольшого театра войны —\\nв Эривани, в Тифлисе,\\nкак рыбе зонтик нужны\\nмировой закулисе.\\n+\\nОт грохота, скрежета, лязга\\nсжимается матка.\\nКачает пустую коляску.\\nЦе хлопчик? Дiвчатко.\\nПоёт колыбельную дочке.\\nПечаль непроглядна.\\nВойна. Молока на сорочке\\nрасплывающиеся пятна.\\n+\\nСвидетельств — терабайт,\\nкак мой народ ушёл\\nв искусственный офсайд.\\nНо засчитали гол\\nи торжествует зло,\\nи стадион орёт.\\nМне очень повезло\\nуспеть на самолёт.\\n+\\nМеждународный язык —\\nмладенческий лепет.\\nСпит у груди призывник\\nГолгофы. Колеблет\\nвоздух взрывная волна.\\nПротивник не выбит.\\nПуть отрезает война\\nдля бегства в Египет.\\n+\\nНе говори: я стреляю мимо.\\nПуля не дура — летит до конца.\\nВыстрелишь в небо — убьёшь херувима.\\nВыстрелишь в землю — убьёшь мертвеца.\\nПтицу. Крота. Стрекозу. Полёвку.\\nПуля не дура — найдёт себе цель.\\nНе слушай комбата — бросай винтовку.\\nПослушайся маму — забейся в щель.\\n+\\nПросыпаешься — война.\\nДа какой тут сон,\\nесли спальня спалена,\\nесли дом сожжён,\\nесли город стал золой,\\nпеплом — стар и млад,\\nесли не смолкает бой\\nи творится ад.\\n+\\nЛевый плачет об одном,\\nправый — о другом.\\nЛевый: взорван детский дом.\\nПравый: где мой дом?\\nНе кори слезу, слеза.\\nКолокольный звон,\\nнаучи мои глаза\\nплакать в унисон.\\n+\\nСпросит внучка, спросит внук:\\nКак ты воевала?\\nЯ полку друзей-подруг\\nплакать помогала.\\nСпросит кто-нибудь из них:\\nКак ты победила?\\nЯ любимых-дорогих\\nимена твердила.\\n+\\nапофеоз войны\\nсажи золы бурьяна\\nвсе до одной черны\\nклавиши фортепьяно\\nбудем играть на нём\\nразмазывая копоть\\nпод проливным огнем\\nв чьей-то крови по локоть\\n+\\nтрам-там-там\\nтрам-там-там\\nмаменькин сынок\\nпомещён по частям\\nв мусорный мешок\\nмина взрыв\\nмина взрыв\\nиз отчёта стёрт\\nГосударству — призыв,\\nродине — аборт.\\n+\\nсветомаскировка\\nночи звёздный час\\nприлегла винтовка\\nприкорнул фугас\\nа когда проснутся\\nпо команде пли\\nзвёзды отвернутся\\nот моей Земли\\n+\\nДело мое дрянь.\\nСделана сказка пылью.\\nПлáчу — плачу дань\\nгневу, стыду, бессилью.\\nСилой берут дев,\\n“Мурку” орут орки.\\nТы близорук, гнев.\\nСлёзы, вы дальнозорки.\\n+\\nРадость передышки краткой,\\nшуточки о женской доле\\nпосле схватки, перед схваткой\\nв мариупольском роддоме.\\nСокращайтесь, мышцы матки,\\nвремя дорого: убийца\\nвожделеет — взятки гладки —\\nкровью с молоком упиться.\\n+\\nКто в подвале зачах?\\nКто под землю несёт\\nдевочку на сносях,\\nраненную в живот?\\nКто при свете свечи\\nжизнью должен истечь?\\nВсё, стишок, замолчи.\\nТут кончается речь.\\n+\\nНа фотографии —\\nмаленький мальчик,\\nпод фотографией —\\nплачущий смайлик.\\nЛёгкая лодочка.\\nХраброе бегство.\\nЗоркость наводчика.\\nВечное детство.\\n+\\nДопускать правоту Пилата,\\nпонимать и прощать Иуду\\nне просите меня, не надо, —\\nне хочу, не могу, не буду,\\nпотому что слова-пароли,\\nпотому что отзывы-рифмы\\nтолерантны до первой крови,\\nдо последней непримиримы.\\n+\\nСколько гробов по плечу\\nженскому человеку?\\nПлачу о мёртвых — плачу\\nпожизненную ипотеку,\\nтрачу кап-кап-капитал.\\nМать утешавший “Жено,\\nне плачь”, не Ты ли сказал,\\nчто плачущие блаженны?\\n+\\nНе на митинге, не в неволе,\\nне в убежище, не в бою\\nя беру интервью у боли.\\nГлавный жанр сейчас — интервью.\\nНе под бомбами, не в обозе,\\nне на кладбище, не в строю\\nсокрушительные вопросы\\nя самой себе задаю.\\n+\\nБудем под прицелами плясать\\nна колючей провололке над бездной,\\nбудем русским языком лизать\\nна морозе занавес железный,\\nбудем огороды городить,\\nбудем, позабыв попытку-пытку,\\nв сон, как в самоволку, уходить,\\nв прошлое проситься на побывку.\\n+\\nПеть перестал? Писать перестал?\\nНовости колюще-режущи?\\nПросто представь, что концертный зал\\nэто бомбоубежище,\\nс передовой не звонит жених,\\nнет писем от сына-беженца.\\nПлачущим пой. Пиши о них.\\nИ, может быть, ты утешишься.\\n+\\nТот, Кто один как перст\\nнёс из последних сил\\nсобственной смерти крест,\\nкрестика не носил.\\nПлачущую прости.\\nГосподи, стыдно мне,\\nчто ношу на груди\\nто, что Ты — на спине.\\n+\\nСтала душа могилой,\\nкровавым кошмаром явь.\\nМолю тебя, шестикрылый, —\\nдвуглавого обезглавь.\\nНа волоске над бездной\\nвсё, что люблю, чем живу.\\nАрхистратиг небесный,\\nпомоги ВСУ.\\n+\\nДогорают купель и купол.\\nТы не смотришь в глаза беде?\\nУмирающий Мариуполь:\\nБогородица на кресте.\\nПлачут Иоаким и Анна.\\nСын снимает Её с креста.\\nМежду ног — рваная рана.\\nТы не веришь? Вложи перста.\\n+\\nГоворит (привет И. Б.)\\nсыну мать:\\nКрест пылает — как тебе\\nвоскресать?\\nОтвечает: Бог с тобой,\\nаз есмь путь.\\nМне ведь, мама, не впервой.\\nКак-нибудь.\\n+\\nПо мановению войны\\nполутона отменены —\\nполуслова, полудела,\\nполухвала-полухула.\\nРоссия бедная моя,\\nпрости меня за то, что я\\nне понимаю, хоть убей,\\nкак полюбить полулюдей.\\n+\\nСердце, слезами залей\\nпламя пасхальной свечи.\\nКровью убитых детей\\nВраг окропил куличи.\\nАнгелы сбиты с пути.\\nВ колокол бьёт ПВО.\\nНыне Воскресший, прости:\\nдля радости сердце мертво.\\n+\\nЕдинственный твой сынок,\\nзащитник, помощник, друг,\\nс вокзала придёт без ног,\\nобнимет тебя без рук,\\nнаполнит стакан без дна,\\nбез глаз оглядит подвал\\nи скажет: была война,\\nи я её проиграл.',\n",
       " 'Author': 'Вера Павлова',\n",
       " 'Before or after': 'After',\n",
       " 'Source': 'ROAR V2',\n",
       " 'Date posted': datetime.datetime(2022, 6, 24, 0, 0),\n",
       " 'UniqueIndex': 162}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[162]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c5aeccf9-0eae-4426-bd92-a3765ad2f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = dict()\n",
    "for recList in overlappingRecs:\n",
    "    counts.setdefault(len(recList),0)\n",
    "    counts[len(recList)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "417b61ba-8cd1-4615-852f-a154a133f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new list using only the earliest overlapping rec\n",
    "repeatIdxs = set()\n",
    "for recList in overlappingRecs:\n",
    "    badRecs = decideRec(recList)\n",
    "    badIdxs = [b['UniqueIndex'] for b in badRecs]\n",
    "    for b in badIdxs:\n",
    "        repeatIdxs.add(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "2c99d0f0-224b-4088-9f7e-55fa9931d9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3289"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanRecList = []\n",
    "j = 0\n",
    "for i, rec in enumerate(records):\n",
    "    if rec['UniqueIndex'] not in repeatIdxs:\n",
    "        rec['UniqueIndex'] = j\n",
    "        cleanRecList.append(rec)\n",
    "        j += 1\n",
    "len(cleanRecList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c6571dbf-d37e-4495-9973-91d1835f13a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Text': '***\\n \\n– В Москве – невкусная клубника, бери водку!\\n \\nВ вытянутой трубке сна так тихо,\\n \\nЧто можно услышать\\n \\nНеуловимую чёрную лодку.\\n \\nСпрашиваю:\\n \\n– Это каяк?\\n \\nПтица с ветки:\\n \\n– Каяк, каяк. Что с тобою не так?\\n \\n– Со мною не так носовой платок,\\n \\nКаждое слово.\\n \\nНеба бесформенный носорог\\n \\nОживает в половине шестого.\\n \\nНаблюдаю за ним из окна.\\n \\nУ меня проблема только одна:\\n \\n«Скендербеу», «Хабнарфьордюр» и «Нымме Калью» проиграли свои матчи.\\n \\nИ три любимых, но непростых занятья:\\n \\nСмотреть на осину,\\nСмотреть на берёзу,\\nСмотреть на тополь.\\n \\nМошка умерла у меня на глазах,\\nА что пережил ты?\\n \\n \\n(интернет-журнал ”Literratura”)\\n \\n#выбор_Максима_Дрёмова',\n",
       " 'Author': 'Денис Крюков',\n",
       " 'Before or after': 'Before',\n",
       " 'Source': 'metajournal',\n",
       " 'Date posted': datetime.datetime(2019, 11, 14, 0, 0),\n",
       " 'UniqueIndex': 1000}"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanRecList[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "bf33e461-00f8-483a-941d-f7b9e3607865",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanDf = pd.DataFrame.from_records(cleanRecList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "198114d5-d445-4fd1-b273-5a95c35da5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanDf.to_excel('../Excel_files/Full_Poem_Dataset_12-17.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6d8294-349d-45ef-a720-553d4e664b17",
   "metadata": {},
   "source": [
    "## AUTHOR DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8a5d91f-4c23-4bb0-b35e-cf0e38b8dc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Poems</th>\n",
       "      <th>Author</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Identification</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Link to bio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Виген Аракелян</td>\n",
       "      <td>Razdan</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://polutona.ru/?show=arakelian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Герман Лукомников</td>\n",
       "      <td>Baku</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://ru.wikipedia.org/wiki/%D0%9B%D1%83%D0%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Александр Иличевский</td>\n",
       "      <td>Sumgait</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://ru.wikipedia.org/wiki/%D0%98%D0%BB%D0%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Леонид Шваб</td>\n",
       "      <td>Babruysk</td>\n",
       "      <td>Belarus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.litkarta.ru/world/israel/persons/sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Ирина Валерина</td>\n",
       "      <td>Babruysk</td>\n",
       "      <td>Belarus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Poems                Author      City     Country Identification  \\\n",
       "0                3        Виген Аракелян    Razdan     Armenia            NaN   \n",
       "1                1     Герман Лукомников      Baku  Azerbaijan            NaN   \n",
       "2                1  Александр Иличевский   Sumgait  Azerbaijan            NaN   \n",
       "3                7           Леонид Шваб  Babruysk     Belarus            NaN   \n",
       "4                6        Ирина Валерина  Babruysk     Belarus            NaN   \n",
       "\n",
       "  Notes                                        Link to bio  \n",
       "0   NaN                https://polutona.ru/?show=arakelian  \n",
       "1   NaN  https://ru.wikipedia.org/wiki/%D0%9B%D1%83%D0%...  \n",
       "2   NaN  https://ru.wikipedia.org/wiki/%D0%98%D0%BB%D0%...  \n",
       "3   NaN  http://www.litkarta.ru/world/israel/persons/sh...  \n",
       "4   NaN                                                NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authorInfo = pd.read_excel('../Excel_files/Thesis Authors.xlsx')\n",
    "authorInfo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eb797a3-09fe-4f42-8d44-7910d0aa8b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Russia          370\n",
       "Ukraine          86\n",
       "Kazakhstan       26\n",
       "Belarus          16\n",
       "Uzbekistan        6\n",
       "Moldova           5\n",
       "Latvia            5\n",
       "Estonia           4\n",
       "Kyrgyzstan        2\n",
       "Azerbaijan        2\n",
       "Lithuania         1\n",
       "Iran              1\n",
       "Georgia           1\n",
       "Tajikistan        1\n",
       "Turkmenistan      1\n",
       "USA               1\n",
       "Armenia           1\n",
       "Name: Country, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authorInfo['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcc6def-9189-4237-8b09-2a68fdd95d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
